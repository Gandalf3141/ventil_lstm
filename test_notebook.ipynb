{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from matplotlib import legend\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from get_data import *\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise(get_data(path = \"save_data_test3.csv\", timesteps_from_data=0, skip_steps_start = 0, skip_steps_end = 0, drop_half_timesteps = False, normalise_s_w=False, rescale_p=False, num_inits=0), num_inits=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Define the LSTM model with two hidden layers\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "class LSTMmodel(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model class for derivative estimation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, out_size, layers):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM model.\n",
    "\n",
    "        Args:\n",
    "        - input_size: Size of input\n",
    "        - hidden_size: Size of hidden layer\n",
    "        - out_size: Size of output\n",
    "        - layers: Number of layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Define LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=layers, batch_first=True)\n",
    "\n",
    "        # Define linear layer\n",
    "        self.linear = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        \"\"\"\n",
    "        Forward pass through the LSTM model.\n",
    "\n",
    "        Args:\n",
    "        - seq: Input sequence\n",
    "\n",
    "        Returns:\n",
    "        - pred: Model prediction\n",
    "        - hidden: Hidden state\n",
    "        \"\"\"\n",
    "        lstm_out, hidden = self.lstm(seq)\n",
    "        pred = self.linear(lstm_out)\n",
    "\n",
    "        return pred, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data, model, steps=600, ws=10, plot_opt=False):\n",
    "\n",
    "    #test_data = test_dataloader.get_all_data() \n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    test_loss = 0\n",
    "    test_loss_deriv = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, x in enumerate(test_data):\n",
    "        x=x.to(device)\n",
    "        if i > 5:\n",
    "            break\n",
    "\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            pred = torch.zeros((steps, 3), device=device)\n",
    "            pred_next_step = torch.zeros((steps, 3), device=device)\n",
    "\n",
    "            if ws > 1:\n",
    "                pred[0:ws, :] = x[0:ws, :]\n",
    "                pred[:, 0] = x[:, 0]\n",
    "                pred_next_step[0:ws, :] = x[0:ws, :]\n",
    "                pred_next_step[:, 0] = x[:, 0]\n",
    "            else:\n",
    "                pred[0, :] = x[0, :]\n",
    "                pred[:, 0] = x[:, 0]\n",
    "                pred_next_step[0, :] = x[0, :]\n",
    "                pred_next_step[:, 0] = x[:, 0]\n",
    "\n",
    "            for i in range(len(x) - ws):\n",
    "\n",
    "                out, _ = model(pred[i:i+ws, :])\n",
    "                pred[i+ws, 1:] = pred[i+ws-1, 1:] + out[-1, :]\n",
    "                pred_next_step[i+ws, 1:] = x[i+ws-1, 1:] + out[-1, :]\n",
    "            \n",
    "            test_loss += loss_fn(pred[:, 1], x[:, 1]).detach().cpu().numpy()\n",
    "            test_loss_deriv += loss_fn(pred[:, 2], x[:, 2]).detach().cpu().numpy()\n",
    "\n",
    "            total_loss += loss_fn(pred[:, 1:], x[:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "            if plot_opt:\n",
    "                figure , axs = plt.subplots(1,3,figsize=(16,9))\n",
    "            \n",
    "                axs[0].plot(pred.detach().cpu().numpy()[:, 1], color=\"red\", label=\"pred\")\n",
    "                axs[0].plot(pred_next_step.detach().cpu().numpy()[:, 1], color=\"green\", label=\"next step from data\")\n",
    "                axs[0].plot(x.detach().cpu().numpy()[:, 1], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "                axs[0].set_title(\"position\")\n",
    "                axs[0].grid()\n",
    "                axs[0].legend()\n",
    "\n",
    "                axs[1].plot(pred.detach().cpu().numpy()[:, 2], color=\"red\", label=\"pred\")\n",
    "                axs[1].plot(pred_next_step.detach().cpu().numpy()[:, 2], color=\"green\", label=\"next step from data\")\n",
    "                axs[1].plot(x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "                axs[1].set_title(\"speed\")\n",
    "                axs[1].grid()\n",
    "                axs[1].legend()\n",
    "\n",
    "                axs[2].plot(x.detach().cpu().numpy()[:,0], label=\"pressure\")\n",
    "                axs[2].set_title(\"pressure\")\n",
    "                axs[2].grid()\n",
    "                axs[2].legend()\n",
    "\n",
    "                plt.grid()\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            \n",
    "    return np.mean(test_loss), np.mean(test_loss_deriv), np.mean(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(path = \"ventil_lstm\\save_data_test.csv\", timesteps_from_data=100, skip_steps_start = 1, skip_steps_end = 1, drop_half_timesteps = True, normalise_s_w=False, rescale_p=False, num_inits=0):\n",
    "    \n",
    "    if timesteps_from_data>1:\n",
    "     df = pd.read_csv(path, header=0, nrows=timesteps_from_data, skiprows=skip_steps_start)\n",
    "    else:\n",
    "     df = pd.read_csv(path, header=0, skiprows=skip_steps_start)\n",
    "\n",
    "    if skip_steps_end>1:\n",
    "       df = df.iloc[0:len(df)-skip_steps_end]\n",
    "\n",
    "    #drop even more timesteps\n",
    "    if drop_half_timesteps:\n",
    "     df = df.iloc[::2]\n",
    "\n",
    "    if num_inits>1:\n",
    "       df = df.iloc[:,0:4*num_inits]\n",
    "    #Reorder columns for familiar setup (t,u,x) here (t, p_b, s_b, w_b)\n",
    "    L = df.columns.to_list()\n",
    "    time_cols = L[0::4]\n",
    "    sb_cols = L[1::4]\n",
    "    pb_cols = L[2::4]\n",
    "    wb_cols = L[3::4]\n",
    "    new_col_order = [x for sub in list(zip(time_cols, pb_cols, sb_cols, wb_cols)) for x in sub]\n",
    "    df= df[new_col_order]\n",
    "    df = df.drop(time_cols, axis=1)\n",
    "\n",
    "    #normalise each column of the dataframe\n",
    "    #mean normalization\n",
    "    #df=(df-df.mean())/df.std()\n",
    "    \n",
    "    #Can't normalize p_b because then a[i]*X+b[i] becomes cX+d for all i.. same with mean normal. \n",
    "    \n",
    "    # Normalise / Rescale\n",
    "    if normalise_s_w:\n",
    "        tmp=pb_cols+sb_cols+wb_cols\n",
    "        df[tmp]=(df[tmp]-df[tmp].min())/(df[tmp].max()-df[tmp].min())\n",
    "    if rescale_p:\n",
    "        df[pb_cols] = df[pb_cols] / 1e5\n",
    "\n",
    "    tensor = torch.tensor(df.values)\n",
    "\n",
    "    #tensor with t=0:600, 500 different input and the 3 outputs [s_b, p_b, w_b]\n",
    "    a = num_inits if num_inits>0 else 500\n",
    "    tensor = tensor.view(len(df),a,3).permute(1,0,2)\n",
    "\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Generate input data\n",
    "input_data = get_data(path = \"save_data_test3.csv\", \n",
    "                                timesteps_from_data=0, \n",
    "                                skip_steps_start = 0,\n",
    "                                skip_steps_end = 0, \n",
    "                                drop_half_timesteps = True,\n",
    "                                normalise_s_w=True,\n",
    "                                rescale_p=False,\n",
    "                                num_inits=100)\n",
    "\n",
    "\n",
    "percentage_of_data = 0.3\n",
    "\n",
    "input_data=input_data.to(device)\n",
    "# Split data into train and test sets\n",
    "        #Split data into train and test sets\n",
    "\n",
    "num_of_inits_train = int(len(input_data)*percentage_of_data)\n",
    "train_inits = np.random.randint(0,len(input_data), num_of_inits_train)\n",
    "train_inits = np.unique(train_inits)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "\n",
    "# make sure we really get the specified percentage of training data..\n",
    "if percentage_of_data < 0.99: \n",
    "         while len(train_inits) < num_of_inits_train * percentage_of_data:\n",
    "                i = np.random.randint(0,len(test_inits),1)[0]\n",
    "                train_inits = np.append(train_inits,test_inits[i])\n",
    "                test_inits = np.delete(test_inits, i)\n",
    "\n",
    "\n",
    "train_data = input_data[train_inits,:,:]\n",
    "test_data = input_data[test_inits,:,:]\n",
    "model = LSTMmodel(input_size=3, hidden_size=5, out_size=2, layers=1).to(device)\n",
    "\n",
    "window_size = 4\n",
    "h_size= 5\n",
    "l_num=1\n",
    "model = LSTMmodel(input_size=3, hidden_size=h_size, out_size=2, layers=l_num).to(device)\n",
    "\n",
    "path = \"Ventil_trained_NNs\\lstm_ws4hs5layer1_nummer157_decay0.3.pth\"#f\"Ventil_trained_NNs\\lstm_ws{window_size}hs{h_size}layer{l_num}_nummer8.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "a,b = test(train_data, model, steps=input_data.size(dim=1), ws=window_size, plot_opt=True)\n",
    "ic(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

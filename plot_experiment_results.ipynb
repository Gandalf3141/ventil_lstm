{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data import *\n",
    "from dataloader import *\n",
    "#from NN_classes import *\n",
    "#from experiments import *\n",
    "from NN_classes_NEW import *\n",
    "import numpy as np\n",
    "from test_function_exp_NEW import *\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " #trigger for pop out plots\n",
    "%matplotlib qt\n",
    " #trigger for plots in cells\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {  \"lstm_or_nextstep\" : \"red\" ,\n",
    "            \"mlp_or_nextstep\" : \"green\" ,\n",
    "            \"tcn_or_nextstep\" : \"orange\" ,\n",
    "            \"lstm_no_or_nextstep\" : \"green\" ,\n",
    "            \"mlp_no_or_nextstep\" : \"red\" ,\n",
    "            \"tcn_no_or_nextstep\" : \"orange\" ,\n",
    "            \"lstm_derivative\" : \"orange\" ,\n",
    "            \"mlp_derivative\" : \"red\" ,\n",
    "            \"tcn_derivative\" : \"green\" ,\n",
    "            \"or_lstm\" : \"yellow\" ,\n",
    "            \"lstm\" : \"red\" ,\n",
    "            \"mlp\" : \"red\" ,\n",
    "            \"gru\" : \"red\" ,\n",
    "            \"tcn\" : \"red\" ,\n",
    "            \"or_tcn\" : \"darkgreen\" ,\n",
    "            \"neural_cde\" : \"red\" ,\n",
    "            \"or_mlp\" : \"tomato\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the experiments to compare the trained models \n",
    "import numpy as np\n",
    "\n",
    "def exp1(models: dict, data, window_sizes, plot_errs=False, set_random=False, bins=10):\n",
    "    \n",
    "    if set_random:\n",
    "         np.seed(1234)\n",
    "    \n",
    "    # if plot_errs==False:\n",
    "    #     index = np.random.randint(0, data.size(dim=0),1)[0]\n",
    "    #     data = data[index:index+1,:,:]\n",
    "\n",
    "    device = \"cpu\" if data.get_device() == -1 else \"cuda:0\"\n",
    "    timesteps = data.size(dim=1)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    predictionary = {}\n",
    "    error_dict = {model_type : [] for model_type in list(models.keys())}\n",
    "    with torch.inference_mode():\n",
    "        for model_type, model in models.items():\n",
    "        \n",
    "            model.eval()\n",
    "            if plot_errs:\n",
    "                for i , x in enumerate(data):\n",
    "                    pred, error = test(x.unsqueeze(0), model, model_type, window_size=window_sizes[model_type], set_rand_seed=True)\n",
    "                    predictionary[model_type] = pred\n",
    "                    error_dict[model_type].append(error)  \n",
    "            else:\n",
    "                    pred, error = test(data, model, model_type, window_size=window_sizes[model_type], set_rand_seed=True)\n",
    "                    predictionary[model_type] = pred\n",
    "                        \n",
    "        if plot_errs:\n",
    "                plot_errors(error_dict, bins)\n",
    "                \n",
    "        else:\n",
    "                #phase_plot_predictions(predictionary, data.clone())\n",
    "                plot_predictions(predictionary, data.clone())\n",
    "\n",
    "def plot_predictions(predictionary, x):\n",
    "    \n",
    "    data_dic = {x : y.clone() for x, y in predictionary.items()}\n",
    "\n",
    "    p_max = 3.5*1e5 #Druck in [bar]         ... [1 , 3.5]\n",
    "    s_max = 0.6*1e-3 #Position [m]          ... [0, 0.0006]\n",
    "    w_max = 1.7 #Geschwindigkeit in [m/s]   ... [-1.7, 1.7]\n",
    "    p_min = 1.0\n",
    "    s_min = 0.0\n",
    "    w_min = -1.7\n",
    "    physics_rescaling = [p_max, s_max, w_max, p_min, s_min, w_min]\n",
    "\n",
    "    colors = {  \"lstm_or_nextstep\" : \"red\" ,\n",
    "            \"mlp_or_nextstep\" : \"green\" ,\n",
    "            \"tcn_or_nextstep\" : \"orange\" ,\n",
    "            \"lstm_no_or_nextstep\" : \"green\" ,\n",
    "            \"mlp_no_or_nextstep\" : \"red\" ,\n",
    "            \"tcn_no_or_nextstep\" : \"orange\" ,\n",
    "            \"lstm_derivative\" : \"orange\" ,\n",
    "            \"mlp_derivative\" : \"red\" ,\n",
    "            \"tcn_derivative\" : \"green\" ,\n",
    "            \"or_lstm\" : \"yellow\" ,\n",
    "            \"lstm\" : \"red\" ,\n",
    "            \"mlp\" : \"red\" ,\n",
    "            \"gru\" : \"red\" ,\n",
    "            \"tcn\" : \"red\" ,\n",
    "            \"or_tcn\" : \"darkgreen\" ,\n",
    "            \"neural_cde\" : \"red\" ,\n",
    "            \"or_mlp\" : \"tomato\"}\n",
    "    \n",
    "    if \"or_lstm\" in list(data_dic.keys()) and \"lstm_or_nextstep\" in list(predictionary.keys()):\n",
    "        colors = {\"or_lstm\" : \"red\", \"lstm_or_nextstep\" : \"yellow\", \"lstm_no_or_nextstep\" : \"green\", \"lstm_derivative\" : \"purple\"}\n",
    "\n",
    "    figure , axs = plt.subplots(3,1, figsize=(16,9))\n",
    "    figure.tight_layout(pad=5.0)    \n",
    "\n",
    "    if x.dim() == 3:\n",
    "        x = x.view(x.size(dim=1), x.size(dim=2))\n",
    "    \n",
    "        #scale back:    \n",
    "    if physics_rescaling != None:\n",
    "\n",
    "        x[:,0] = x[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "        x[:,1] = x[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        x[:,2] = x[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    greek_letterz=[chr(code) for code in range(945,970)]\n",
    "    mu = greek_letterz[11]\n",
    "\n",
    "    stepsize = 2e-5\n",
    "    time = np.linspace(0,x.size(dim=0)* stepsize, x.size(dim=0))\n",
    "\n",
    "    #data\n",
    "    axs[0].plot(time, x.detach().cpu().numpy()[:, 1], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    axs[1].plot(time, x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    axs[2].plot(time, x.detach().cpu().numpy()[:,0], label=\"pressure\")\n",
    "\n",
    "    #predictions\n",
    "    for key, pred in data_dic.items():\n",
    "\n",
    "        if physics_rescaling != None:\n",
    "\n",
    "            # we invert:\n",
    "            # x = (x - xmin)/(xmax - xmin)\n",
    "            # x * (xmax - xmin) + xmin\n",
    "\n",
    "            pred[:,0] = pred[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "            pred[:,1] = pred[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "            pred[:,2] = pred[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.view(pred.size(dim=1), pred.size(dim=2))\n",
    "\n",
    "        axs[0].plot(time, pred.detach().cpu().numpy()[:, 1], color=colors[key], label=f\"{key}-prediciton\", alpha=0.8)\n",
    "        axs[1].plot(time, pred.detach().cpu().numpy()[:, 2], color=colors[key], label=f\"{key}-prediciton\", alpha=0.8)\n",
    "\n",
    "\n",
    "    axs[0].set_title(\"position\")\n",
    "    axs[0].set_ylabel(\"[m]\")\n",
    "    axs[0].set_xlabel(f\"time [s]\")\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()   \n",
    "    axs[1].set_title(\"speed\")\n",
    "    axs[1].set_ylabel(\"[m/s]\")\n",
    "    axs[1].set_xlabel(f\"time [s]\")\n",
    "    axs[1].grid()\n",
    "    axs[1].legend()\n",
    "    axs[2].set_title(\"pressure\")\n",
    "    axs[2].set_ylabel(\"[Pa]\")\n",
    "    axs[2].set_xlabel(f\"time [s]\")\n",
    "    axs[2].grid()\n",
    "    axs[2].legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def phase_plot_predictions(predictionary, x):\n",
    "\n",
    "\n",
    "    data_dic = {x : y.clone() for x, y in predictionary.items()}\n",
    "\n",
    "    p_max = 3.5*1e5 #Druck in [bar]         ... [1 , 3.5]\n",
    "    s_max = 0.6*1e-3 #Position [m]          ... [0, 0.0006]\n",
    "    w_max = 1.7 #Geschwindigkeit in [m/s]   ... [-1.7, 1.7]\n",
    "    p_min = 1.0\n",
    "    s_min = 0.0\n",
    "    w_min = -1.7\n",
    "    physics_rescaling = [p_max, s_max, w_max, p_min, s_min, w_min]\n",
    "\n",
    "    colors = {  \"lstm_or_nextstep\" : \"red\" ,\n",
    "            \"mlp_or_nextstep\" : \"green\" ,\n",
    "            \"tcn_or_nextstep\" : \"orange\" ,\n",
    "            \"lstm_no_or_nextstep\" : \"green\" ,\n",
    "            \"mlp_no_or_nextstep\" : \"red\" ,\n",
    "            \"tcn_no_or_nextstep\" : \"orange\" ,\n",
    "            \"lstm_derivative\" : \"orange\" ,\n",
    "            \"mlp_derivative\" : \"red\" ,\n",
    "            \"tcn_derivative\" : \"green\" ,\n",
    "            \"or_lstm\" : \"yellow\" ,\n",
    "            \"lstm\" : \"red\" ,\n",
    "            \"mlp\" : \"red\" ,\n",
    "            \"gru\" : \"red\" ,\n",
    "            \"tcn\" : \"red\" ,\n",
    "            \"or_tcn\" : \"darkgreen\" ,\n",
    "            \"neural_cde\" : \"red\" ,\n",
    "            \"or_mlp\" : \"tomato\"}\n",
    "\n",
    "    figure , axs = plt.subplots(1,1, figsize=(16,16))\n",
    "    figure.tight_layout(pad=5.0)    \n",
    "\n",
    "    if x.dim() == 3:\n",
    "        x = x.view(x.size(dim=1), x.size(dim=2))\n",
    "    \n",
    "        #scale back:    \n",
    "    if physics_rescaling != None:\n",
    "\n",
    "        x[:,0] = x[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "        x[:,1] = x[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        x[:,2] = x[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    greek_letterz=[chr(code) for code in range(945,970)]\n",
    "    mu = greek_letterz[11]\n",
    "\n",
    "    stepsize = 2e-5\n",
    "    time = np.linspace(0,x.size(dim=0)* stepsize, x.size(dim=0))\n",
    "\n",
    "    #data\n",
    "    axs.plot(x.detach().cpu().numpy()[:, 1],x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "\n",
    "    #predictions\n",
    "    for key, pred in data_dic.items():\n",
    "\n",
    "        if physics_rescaling != None:\n",
    "\n",
    "            # we invert:\n",
    "            # x = (x - xmin)/(xmax - xmin)\n",
    "            # x * (xmax - xmin) + xmin\n",
    "\n",
    "            pred[:,0] = pred[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "            pred[:,1] = pred[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "            pred[:,2] = pred[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.view(pred.size(dim=1), pred.size(dim=2))\n",
    "\n",
    "        axs.plot(pred.detach().cpu().numpy()[:, 1], pred.detach().cpu().numpy()[:, 2], color=colors[key], label=f\"{key}-prediciton\", alpha=0.8)\n",
    "\n",
    "    axs.set_title(\"phaseplot\")\n",
    "    axs.set_ylabel(\"[m/s]\")\n",
    "    axs.set_xlabel(f\"[m]\")\n",
    "    axs.grid()\n",
    "    axs.legend()   \n",
    "\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_errors(erros_dic, bins):\n",
    "     \n",
    "    data_dic = {x : y for x, y in erros_dic.items()}\n",
    "    # Plot histograms with MSE over many trajectories\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    colors = {  \"lstm_or_nextstep\" : \"red\" ,\n",
    "            \"mlp_or_nextstep\" : \"green\" ,\n",
    "            \"tcn_or_nextstep\" : \"blue\" ,\n",
    "            \"lstm_no_or_nextstep\" : \"green\" ,\n",
    "            \"mlp_no_or_nextstep\" : \"red\" ,\n",
    "            \"tcn_no_or_nextstep\" : \"orange\" ,\n",
    "            \"lstm_derivative\" : \"orange\" ,\n",
    "            \"mlp_derivative\" : \"red\" ,\n",
    "            \"tcn_derivative\" : \"green\" ,\n",
    "            \"or_lstm\" : \"yellow\" ,\n",
    "            \"lstm\" : \"red\" ,\n",
    "            \"mlp\" : \"red\" ,\n",
    "            \"gru\" : \"red\" ,\n",
    "            \"tcn\" : \"red\" ,\n",
    "            \"or_tcn\" : \"darkgreen\" ,\n",
    "            \"neural_cde\" : \"red\" ,\n",
    "            \"or_mlp\" : \"tomato\"}\n",
    "\n",
    "    # Plot each histogram on the same axes\n",
    "\n",
    "    hatchvals = {}\n",
    "    for k in data_dic.keys():\n",
    "         if \"lstm\" in k:\n",
    "            hatchvals[k] = \"\\\\\"\n",
    "         if \"mlp\" in k:\n",
    "            hatchvals[k] = \"//\"\n",
    "         if \"tcn\" in k:\n",
    "            hatchvals[k] = \"||\"\n",
    "         if \"lstm\" in k:\n",
    "            colors[k] = \"blue\"\n",
    "         if \"mlp\" in k:\n",
    "            colors[k] = \"red\"\n",
    "         if \"tcn\" in k:\n",
    "            colors[k] = \"green\"\n",
    "\n",
    "    hatchvals = {}\n",
    "    for k in data_dic.keys():\n",
    "\n",
    "         if \"or_tcn\" in k:\n",
    "            hatchvals[k] = \"//\"\n",
    "         if \"or_tcn\" in k:\n",
    "            colors[k] = \"blue\"\n",
    "         if \"tcn_or_nextstep\" in k:\n",
    "            hatchvals[k] = \"\\\\\"\n",
    "         if \"tcn_or_nextstep\" in k:\n",
    "            colors[k] = \"red\"\n",
    "             \n",
    "    for key, values in data_dic.items():\n",
    "        #plt.plot(np.array(values))\n",
    "\n",
    "    #'/, \\\\, |, -, +, x, o, O, .', and *`.\n",
    "\n",
    "        ax.hist(np.array(values).flatten(),color=colors[key], bins=bins, alpha=0.7, label=key, hatch = hatchvals[key], edgecolor=\"black\")\n",
    "        ax.axvline(np.array(values).mean(), color=colors[key], linestyle='dashed', linewidth=2, label=f\"{key} : Mean MSE {np.round(np.array(values).mean(),7)}\")\n",
    "\n",
    "    # Set titles and labels\n",
    "    ax.set_title('Mean squared errors over X trajectories')\n",
    "    ax.set_xlabel('MSE')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test trajectories\n",
    "\n",
    "params_lstm =   {\n",
    "                        \"window_size\" : 16,\n",
    "                        \"h_size\" : 8,\n",
    "                        \"l_num\" : 3,\n",
    "                        \"learning_rate\" : 0.0008,\n",
    "                        \"batch_size\" : 20,\n",
    "                }\n",
    "\n",
    "params_mlp =    {\n",
    "                        \"window_size\" : 20,\n",
    "                        \"h_size\" : 24,\n",
    "                        \"l_num\" : 3,\n",
    "                        \"learning_rate\" : 0.001,\n",
    "                        \"batch_size\" : 20,\n",
    "                        \"act_fn\" : \"relu\",\n",
    "                        \"nonlin_at_out\" : None #None if no nonlinearity at the end\n",
    "                }\n",
    "\n",
    "params_tcn =    {\n",
    "                    \"window_size\" : 30,\n",
    "                    \"learning_rate\" : 0.001,\n",
    "                    \"batch_size\" : 20,\n",
    "                    \"n_hidden\" : 5,\n",
    "                    \"levels\" : 4,\n",
    "                    \"kernel_size\" : 7,\n",
    "                    \"dropout\" : 0,\n",
    "                    \"input_channels\" : 3,\n",
    "                    \"output\" : 2,\n",
    "                    \"drop_half_timesteps\" : True,\n",
    "                    \"cut_off_timesteps\" : 100,\n",
    "                    \"part_of_data\" : 0,\n",
    "                    \"percentage_of_data\" : 0.8\n",
    "\n",
    "                }\n",
    "    \n",
    "parameter_configs  = [params_lstm, params_mlp, params_tcn] \n",
    "\n",
    "path = \"data/save_data_test_5xlonger_dyndyn.csv\"\n",
    "path2 = \"data/save_data_test_5xlonger.csv\"\n",
    "#path = \"data/save_data_test_revised.csv\"\n",
    "input_data, PSW_max = get_data(path = path, \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params_tcn[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params_tcn[\"part_of_data\"])\n",
    "\n",
    "input_data2, PSW_max = get_data(path = path2, \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params_tcn[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params_tcn[\"part_of_data\"])\n",
    "input_data = torch.cat((input_data, input_data2))\n",
    "#print(input_data.size())\n",
    "\n",
    "np.random.seed(1234)\n",
    "#print(\"input_data size\", input_data.size())\n",
    "num_of_inits_train = int(len(input_data)*params_tcn[\"percentage_of_data\"])\n",
    "train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "np.random.shuffle(train_inits)\n",
    "np.random.shuffle(test_inits)\n",
    "test_data = input_data[test_inits,:,:]\n",
    "np.random.seed()\n",
    "\n",
    "#load models\n",
    "\n",
    "# Initialize the LSTM models\n",
    "model_lstm = OR_LSTM(input_size=3, hidden_size=params_lstm[\"h_size\"], out_size=2, layers=params_lstm[\"l_num\"], window_size=params_lstm[\"window_size\"]).to(device)\n",
    "path_lstm = \"First_experiment_run_22_07_2024/OR_LSTM_exp0.pth\"\n",
    "model_lstm.load_state_dict(torch.load(path_lstm, map_location=torch.device(device)))\n",
    "\n",
    "model_lstm_nextstep = LSTM_or_nextstep(input_size=3, hidden_size=params_lstm[\"h_size\"], out_size=2, layers=params_lstm[\"l_num\"], window_size = params_lstm[\"window_size\"]).to(device)\n",
    "path_lstm_nextstep = \"First_experiment_run_22_07_2024/LSTM_or_nextstep_exp0.pth\"\n",
    "model_lstm_nextstep.load_state_dict(torch.load(path_lstm_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "model_lstm_no_or_nextstep = LSTM_or_nextstep(input_size=3, hidden_size=params_lstm[\"h_size\"], out_size=2, layers=params_lstm[\"l_num\"], window_size = params_lstm[\"window_size\"]).to(device)\n",
    "path_lstm_no_or_nextstep = \"First_experiment_run_22_07_2024/LSTM_no_or_nextstep_exp0.pth\"\n",
    "model_lstm_no_or_nextstep.load_state_dict(torch.load(path_lstm_no_or_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "model_lstm_no_or_derivative = OR_LSTM(input_size=3, hidden_size=params_lstm[\"h_size\"], out_size=2, layers=params_lstm[\"l_num\"], window_size = params_lstm[\"window_size\"]).to(device)\n",
    "path_lstm_no_or_derivative = \"First_experiment_run_22_07_2024/LSTM_derivative_3_exp0.pth\"\n",
    "model_lstm_no_or_derivative.load_state_dict(torch.load(path_lstm_no_or_derivative, map_location=torch.device(device)))\n",
    "\n",
    "\n",
    "# Initialize the MLP models\n",
    "model_or_mlp = OR_MLP(input_size=3*params_mlp[\"window_size\"], hidden_size = params_mlp[\"h_size\"], l_num=params_mlp[\"l_num\"], output_size=2, act_fn = params_mlp[\"act_fn\"],\n",
    "                    act_at_end = params_mlp[\"nonlin_at_out\"], timesteps=params_mlp[\"window_size\"]).to(device)\n",
    "path_or_mlp = \"First_experiment_run_22_07_2024/OR_MLP_exp1.pth\"\n",
    "model_or_mlp.load_state_dict(torch.load(path_or_mlp, map_location=torch.device(device)))\n",
    "\n",
    "model_or_mlp_nextstep = MLP_or_nextstep(input_size=3*params_mlp[\"window_size\"], hidden_size = params_mlp[\"h_size\"], l_num=params_mlp[\"l_num\"],\n",
    "                output_size=2, act_fn = params_mlp[\"act_fn\"], act_at_end = params_mlp[\"nonlin_at_out\"], timesteps=params_mlp[\"window_size\"]).to(device)\n",
    "path_or_mlp_nextstep = \"First_experiment_run_22_07_2024/MLP_or_nextstep_exp1.pth\"\n",
    "model_or_mlp_nextstep.load_state_dict(torch.load(path_or_mlp_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "model_mlp_no_or_nextstep = MLP_or_nextstep(input_size=3*params_mlp[\"window_size\"], hidden_size = params_mlp[\"h_size\"], l_num=params_mlp[\"l_num\"],\n",
    "                output_size=2, act_fn = params_mlp[\"act_fn\"], act_at_end = params_mlp[\"nonlin_at_out\"], timesteps=params_mlp[\"window_size\"]).to(device)\n",
    "path_mlp_no_or_nextstep = \"First_experiment_run_22_07_2024/MLP_no_or_nextstep_exp1.pth\"\n",
    "model_mlp_no_or_nextstep.load_state_dict(torch.load(path_mlp_no_or_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "model_mlp_no_or_derivative = OR_MLP(input_size=3*params_mlp[\"window_size\"], hidden_size = params_mlp[\"h_size\"], l_num=params_mlp[\"l_num\"],\n",
    "                output_size=2, act_fn = params_mlp[\"act_fn\"], act_at_end = params_mlp[\"nonlin_at_out\"], timesteps=params_mlp[\"window_size\"]).to(device)\n",
    "path_mlp_no_or_derivative = \"Trained_NNs_exp/MLP_derivative_exp1.pth\"\n",
    "model_mlp_no_or_derivative.load_state_dict(torch.load(path_mlp_no_or_derivative, map_location=torch.device(device)))\n",
    "\n",
    "# Initialize the TCN models\n",
    "input_channels = params_tcn[\"input_channels\"]\n",
    "output = params_tcn[\"output\"]\n",
    "num_channels = [params_tcn[\"n_hidden\"]] * params_tcn[\"levels\"]\n",
    "kernel_size = params_tcn[\"kernel_size\"]\n",
    "dropout = params_tcn[\"dropout\"]\n",
    "\n",
    "model_tcn = OR_TCN(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "path_tcn = \"First_experiment_run_22_07_2024/OR_TCN_exp2.pth\"\n",
    "model_tcn.load_state_dict(torch.load(path_tcn, map_location=torch.device(device)))\n",
    "\n",
    "model_tcn_nextstep = TCN_or_nextstep(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "path_tcn_nextstep = \"First_experiment_run_22_07_2024/TCN_or_nextstep_exp2.pth\"\n",
    "model_tcn_nextstep.load_state_dict(torch.load(path_tcn_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "#model_tcn_no_or_nextstep = TCN_no_or_nextstep(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "model_tcn_no_or_nextstep = TCN_or_nextstep(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "path_tcn_no_or_nextstep = \"First_experiment_run_22_07_2024/TCN_no_or_nextstep_exp2.pth\"\n",
    "model_tcn_no_or_nextstep.load_state_dict(torch.load(path_tcn_no_or_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "model_tcn_no_or_derivative = OR_TCN(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "path_tcn_no_or_derivative = \"First_experiment_run_22_07_2024/TCN_derivative_3exp2.pth\"\n",
    "model_tcn_no_or_derivative.load_state_dict(torch.load(path_tcn_no_or_derivative, map_location=torch.device(device)))\n",
    "\n",
    "\n",
    "# TODO Neural CDE  \n",
    "#model = NeuralCDE(input_channels=4, hidden_channels=params[\"h_size\"], hidden_width = params[\"h_width\"], output_channels=2).to(device)\n",
    "#model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "models = {\"or_lstm\" : model_lstm,\n",
    "          \"or_mlp\" : model_or_mlp,\n",
    "          \"or_tcn\" : model_tcn\n",
    "          }\n",
    "\n",
    "window_sizes = {\"or_lstm\" : params_lstm[\"window_size\"],\n",
    "                \"or_mlp\" : params_mlp[\"window_size\"],\n",
    "                \"mlp\" : params_mlp[\"window_size\"],\n",
    "                \"or_tcn\" : params_tcn[\"window_size\"],\n",
    "                \"lstm_or_nextstep\" : params_lstm[\"window_size\"],\n",
    "                \"mlp_or_nextstep\" : params_mlp[\"window_size\"],\n",
    "                \"tcn_or_nextstep\" : params_tcn[\"window_size\"],\n",
    "                \"lstm_no_or_nextstep\" : params_lstm[\"window_size\"],\n",
    "                \"mlp_no_or_nextstep\" : params_mlp[\"window_size\"],\n",
    "                \"tcn_no_or_nextstep\" : params_tcn[\"window_size\"],\n",
    "                \"lstm_derivative\" : params_lstm[\"window_size\"],\n",
    "                \"mlp_derivative\" : params_mlp[\"window_size\"],\n",
    "                \"tcn_derivative\" : params_tcn[\"window_size\"]\n",
    "                }\n",
    "    \n",
    "models_nextstep = {\"lstm_or_nextstep\" : model_lstm_nextstep,\n",
    "          \"mlp_or_nextstep\" : model_or_mlp_nextstep,\n",
    "          #\"mlp\" : model_mlp,\n",
    "          \"tcn_or_nextstep\" : model_tcn_nextstep\n",
    "          }\n",
    "\n",
    "fixed_model_categories = {\"tcn_or_nextstep\" : model_tcn_nextstep, \n",
    "                          \"or_tcn\" : model_tcn}\n",
    "\n",
    "models_no_or_nextstep = {\"lstm_no_or_nextstep\" : model_lstm_no_or_nextstep,\n",
    "                         \"tcn_no_or_nextstep\" : model_tcn_no_or_nextstep,\n",
    "                          \"mlp_no_or_nextstep\" : model_mlp_no_or_nextstep } # \n",
    "\n",
    "models_no_or_derivative = {\"or_lstm\" : model_lstm_no_or_derivative, \"or_tcn\" : model_tcn_no_or_derivative }#,\n",
    "                          #\"or_mlp\" : model_mlp_no_or_derivative,\n",
    "                               # \n",
    "\n",
    "models_test = {#\"lstm_derivative\" : model_lstm_no_or_derivative,\n",
    "               \"tcn_derivative\" : model_tcn_no_or_derivative } # \n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "test_inits = input_data.size(dim=0)\n",
    "ids = np.random.choice(test_inits, min([input_data.size(dim=0), 10]), replace=False)\n",
    "ids = np.unique(ids)\n",
    "print(ids)\n",
    "# Use k=4 as test trajectory for all plots\n",
    "k=12\n",
    "\n",
    "exp1(models_no_or_derivative, input_data[k:k+1,:,:].to(device), window_sizes, plot_errs=False, bins=7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([53, 2750, 3])\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#Test trajectories\n",
    "\n",
    "params_tcn =    {\n",
    "                \"window_size\" : 30,\n",
    "                \"learning_rate\" : 0.001,\n",
    "                \"batch_size\" : 20,\n",
    "                \"n_hidden\" : 5,\n",
    "                \"levels\" : 4,\n",
    "                \"kernel_size\" : 7,\n",
    "                \"dropout\" : 0\n",
    "                }\n",
    "\n",
    "parameter_configs  = [params_tcn] \n",
    "\n",
    "for k, d in enumerate(parameter_configs):\n",
    "        d[\"experiment_number\"] = k\n",
    "        d[\"epochs\"] = 1000\n",
    "        d[\"input_channels\"] = 3\n",
    "        d[\"output\"] = 2\n",
    "        d[\"part_of_data\"] = 0\n",
    "        d[\"percentage_of_data\"] = 0.99\n",
    "        d[\"drop_half_timesteps\"] = True\n",
    "        d[\"cut_off_timesteps\"] = 100  \n",
    "\n",
    "\n",
    "path = \"data/save_data_test_5xlonger_dyndyn.csv\"\n",
    "path2 = \"data/save_data_test_5xlonger.csv\"\n",
    "#path = \"data/save_data_test_revised.csv\"\n",
    "input_data, PSW_max = get_data(path = path, \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params_tcn[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params_tcn[\"part_of_data\"])\n",
    "\n",
    "input_data2, PSW_max = get_data(path = path2, \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params_tcn[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params_tcn[\"part_of_data\"])\n",
    "input_data = torch.cat((input_data, input_data2))\n",
    "\n",
    "# Initialize the TCN models\n",
    "input_channels = params_tcn[\"input_channels\"]\n",
    "output = params_tcn[\"output\"]\n",
    "num_channels = [params_tcn[\"n_hidden\"]] * params_tcn[\"levels\"]\n",
    "kernel_size = params_tcn[\"kernel_size\"]\n",
    "dropout = params_tcn[\"dropout\"]\n",
    "\n",
    "model_tcn = OR_TCN(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "path_tcn = \"Trained_NNs_exp\\OR_TCN_sparsedata_exp0_COPY.pth\"\n",
    "model_tcn.load_state_dict(torch.load(path_tcn, map_location=torch.device(device)))\n",
    "\n",
    "model_tcn_nextstep = TCN_or_nextstep(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "path_tcn_nextstep = \"Trained_NNs_exp\\TCN_or_nextstep_sparsedata_exp0_COPY.pth\"\n",
    "model_tcn_nextstep.load_state_dict(torch.load(path_tcn_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "\n",
    "window_sizes = {\n",
    "                \"or_tcn\" : params_tcn[\"window_size\"],\n",
    "                \"tcn_or_nextstep\" : params_tcn[\"window_size\"]\n",
    "                }\n",
    "\n",
    "models_sparse_data = {\"or_tcn\" : model_tcn,\n",
    "                      \"tcn_or_nextstep\" : model_tcn_nextstep}\n",
    "\n",
    "# Use k=4 as test trajectory for all plots\n",
    "k=10\n",
    "\n",
    "mask = input_data[:, 10, 0] > 0.6\n",
    "\n",
    "train_data = input_data[mask]\n",
    "print(train_data.size())\n",
    "train_data = train_data[:,:train_data.size(dim=1)-params_tcn[\"cut_off_timesteps\"], :]\n",
    "\n",
    "np.random.seed(1234)\n",
    "test_inits = test_data.size(dim=0)\n",
    "print(test_inits)\n",
    "ids = np.random.choice(test_inits, min([50, test_inits]), replace=False)\n",
    "ids = np.unique(ids)\n",
    "\n",
    "k=2\n",
    "exp1(models_sparse_data, train_data[0:50,:,:].to(device), window_sizes, plot_errs=True, bins=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.size()\n",
    "k=34\n",
    "print(input_data[k:k+1, 0:params_tcn[\"window_size\"], :].transpose(1,2))\n",
    "a = model_tcn_no_or_nextstep(input_data[k:k+1, 0:params_tcn[\"window_size\"], :].transpose(1,2))\n",
    "print(a)\n",
    "print(input_data[k:k+1, params_tcn[\"window_size\"]-1, :].size())\n",
    "print(input_data[k:k+1, params_tcn[\"window_size\"]-1, 1:]-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlist(a):\n",
    "    return [ (x - min(a)) / (max(a) - min(a)) for x in a]\n",
    "\n",
    "Epochs = [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "LSTM = [0.028456646258258722, 0.022694337263373117, 0.026009841374953605, 0.03045055947042709, 0.019146433432510185, 0.0076781917215315715, 0.00730898111993305, 0.007876552085049473, 0.007547752849599885, 0.006278254707170924]\n",
    "# MLP hat ausrei√üer\n",
    "#MLP = [0.01856441755029323, 0.013231895836598232, 0.010403810288739296, 0.008548521189701832, 0.009579918550359865, 0.008980504622523996, 0.009289483926369347, 0.006702352100843063, 3599.2784327571107, 0.009543711781792218]\n",
    "MLP = [0.01856441755029323, 0.013231895836598232, 0.010403810288739296, 0.008548521189701832, 0.009579918550359865, 0.008980504622523996, 0.009289483926369347, 0.006702352100843063, 0.006702352100843063, 0.009543711781792218]\n",
    "TCN = [0.03306022808310429, 0.012185637813547628, 0.008335839578852183, 0.0038785364358451145, 0.0031343244156947217, 0.003462088193589699, 0.003981136428790162, 0.002496261116017282, 0.0026503715556096402, 0.0020942350182145074]\n",
    "#MLP = normlist(MLP)\n",
    "#LSTM = normlist(LSTM)\n",
    "#TCN = normlist(TCN)\n",
    "LSTM2 = [0.024987961961632846, 0.016181169585631445, 0.014161591938671236, 0.01406885179196545, 0.012409247708514435, 0.010494681192992274, 0.008844779220702037, 0.006999178763346141, 0.006394357812348286, 0.005090870408819805]\n",
    "MLP2 = [0.0198861211717555, 0.010500711235144832, 0.007480574647699809, 0.006824193687648814, 0.006275183383519934, 0.004428913574496422, 0.003949885732163199, 0.0032829739688022457, 0.0035847660291489, 0.003276470429756819]\n",
    "TCN2 = [0.01730283516845159, 0.01574904319763183, 0.013428775159859312, 0.010616026681713377, 0.006429868407236622, 0.006101762805938836, 0.006622495231124482, 0.007598870176500983, 0.00687686763729292, 0.004873080602545475]\n",
    "\n",
    "LSTM_no_or_nextstep = [0.022155934215260128, 0.056261628580869145, 0.041086134862742686, 0.020083364984432216, 0.021504056679272295, 0.04260897157194524, 0.021326784661471452, 0.16559066118741686, 0.08671524629109771, 0.032824686261769216]\n",
    "MLP_no_or_nextstep = [0.4853717801943765, 3.4393062721485865, 0.011920182945910187, 0.511504705936588, 0.0032880174010418892, 2.5836390036492256, 4.288829318446368, 4.513461583265947, 0.4638297379572201, 3.3477028773982545]\n",
    "\n",
    "#updated wo nur tcn funktioniert hat\n",
    "TCN_no_or_nextstep =[0.08802516814381002, 0.03419620314831014, 0.01993361841693107, 0.01991005969668372, 0.035682181326244074, 0.02298526542847462, 0.07684225786408962, 1.4656454318598289, 0.05301786667549353, 0.03389456733872057]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(16,9))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i,j in [(0,0), (1,0), (0,1), (1,1)]:\n",
    "    axs[i,j].grid(True)\n",
    "    axs[i,j].set_ylabel(\"MSE\")\n",
    "    axs[i,j].set_xlabel(\"Epochs\")\n",
    "    #axs[i,j].legend()\n",
    "\n",
    "axs[0,0].plot(Epochs, LSTM, color=\"b\", label = \"LSTM\")\n",
    "axs[0,0].plot(Epochs, MLP, color=\"g\", label = \"MLP\")\n",
    "axs[0,0].plot(Epochs, TCN, color=\"r\", label = \"TCN\")\n",
    "axs[0,0].set_title(\"OR-derivative\")\n",
    "axs[0,0].legend()\n",
    "\n",
    "axs[1,0].plot(Epochs, LSTM2, color=\"b\", label = \"LSTM\")\n",
    "axs[1,0].plot(Epochs, MLP2, color=\"g\", label = \"MLP\")\n",
    "axs[1,0].plot(Epochs, TCN2, color=\"r\", label = \"TCN\")\n",
    "axs[1,0].set_title(\"OR-Nextstep\")\n",
    "axs[1,0].legend()\n",
    "\n",
    "axs[0,1].plot(Epochs, LSTM_no_or_nextstep, color=\"b\", label = \"LSTM\")\n",
    "axs[0,1].plot(Epochs, MLP_no_or_nextstep, color=\"g\", label = \"MLP\")\n",
    "axs[0,1].plot(Epochs, TCN_no_or_nextstep, color=\"r\", label = \"TCN\")\n",
    "axs[0,1].set_title(\"derivative\")\n",
    "axs[0,1].legend()\n",
    "\n",
    "axs[1,1].plot(Epochs, LSTM_no_or_nextstep, color=\"b\", label = \"LSTM\")\n",
    "axs[1,1].plot(Epochs, MLP_no_or_nextstep, color=\"g\", label = \"MLP\")\n",
    "axs[1,1].plot(Epochs, TCN_no_or_nextstep, color=\"r\", label = \"TCN\")\n",
    "axs[1,1].set_title(\"Nextstep\")\n",
    "axs[1,1].legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

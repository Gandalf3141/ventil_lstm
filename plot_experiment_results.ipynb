{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data import *\n",
    "from dataloader import *\n",
    "from NN_classes import *\n",
    "#from experiments import *\n",
    "from nextstep_NN_classes import *\n",
    "import numpy as np\n",
    "from test_function_exp import *\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the experiments to compare the trained models \n",
    "import numpy as np\n",
    "\n",
    "def exp1(models: dict, data, window_sizes, plot_errs=False, set_random=False):\n",
    "    \n",
    "    if set_random:\n",
    "         np.seed(1234)\n",
    "    \n",
    "    if plot_errs==False:\n",
    "        index = np.random.randint(0, data.size(dim=0),1)[0]\n",
    "        data = data[index:index+1,:,:]\n",
    "\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_loss_deriv = 0\n",
    "    total_loss = 0\n",
    "    total_firsthalf = 0\n",
    "    total_secondhalf = 0\n",
    "\n",
    "    device = \"cpu\" if data.get_device() == -1 else \"cuda:0\"\n",
    "    timesteps = data.size(dim=1)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    predictionary = {}\n",
    "    error_dict = {model_type : [] for model_type in list(models.keys())}\n",
    "    with torch.inference_mode():\n",
    "        for model_type, model in models.items():\n",
    "\n",
    "            window_size = window_sizes[model_type]\n",
    "            model.eval()\n",
    "                \n",
    "            if model_type == \"or_lstm\":\n",
    "                    for i, x in enumerate(data):\n",
    "\n",
    "                        x=x.to(device)        \n",
    "                        x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "                \n",
    "                        with torch.inference_mode():\n",
    "                \n",
    "                            pred = torch.zeros((timesteps, 3), device=device)\n",
    "                \n",
    "                            if window_size > 1:\n",
    "                                pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "                \n",
    "                            else:\n",
    "                                pred[0, :] = x[0, 0, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "                \n",
    "\n",
    "                            out, _ = model(x)\n",
    "                            pred[window_size:,1:] = out\n",
    "\n",
    "                            #print(x.size(), pred.size())\n",
    "                            test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                            error_dict[model_type].append(total_loss)\n",
    "\n",
    "                            total_firsthalf += loss_fn(pred[window_size:int((timesteps-window_size)/2), 1:], \n",
    "                                    x[0, window_size:int((timesteps-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                            total_secondhalf += loss_fn(pred[int((timesteps-window_size)/2):, 1:],\n",
    "                                        x[0, int((timesteps-window_size)/2):, 1:]).detach().cpu().numpy()\n",
    "                            \n",
    "                    predictionary[model_type] = pred\n",
    "                            \n",
    "      \n",
    "            if model_type == \"mlp\":\n",
    "                for i, x in enumerate(data):\n",
    "\n",
    "                        x=x.to(device)\n",
    "                        \n",
    "                        with torch.inference_mode():\n",
    "                \n",
    "                            pred = torch.zeros((timesteps, 3), device=device)\n",
    "                \n",
    "                            if window_size > 1:\n",
    "                                pred[0:window_size, :] = x[0:window_size, :]\n",
    "                                pred[:, 0] = x[ :, 0]\n",
    "                \n",
    "                            else:\n",
    "                                pred[0, :] = x[0, :]\n",
    "                                pred[:, 0] = x[:, 0]\n",
    "\n",
    "                            inp = torch.cat((x[:window_size,0], x[:window_size,1], x[:window_size,2]))\n",
    "\n",
    "                            for t in range(1,timesteps - window_size + 1 ): \n",
    "\n",
    "                                out = model(inp)\n",
    "                                pred[window_size+(t-1):window_size+t,1:] =  pred[window_size+(t-2):window_size+(t-1):,1:] + out\n",
    "                                new_p = pred[t:t+window_size,0]\n",
    "                                new_s = pred[t:t+window_size,1]\n",
    "                                new_v = pred[t:t+window_size,2]\n",
    "                                \n",
    "                                inp = torch.cat((new_p, new_s, new_v))\n",
    "\n",
    "                            test_loss += loss_fn(pred[window_size:, 1], x[window_size:, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[window_size:, 2], x[window_size:, 2]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[window_size:, 1:], x[window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                            error_dict[model_type].append(total_loss)\n",
    "\n",
    "                            \n",
    "                            total_firsthalf += loss_fn(pred[window_size:int((pred.size(dim=0)-window_size)/2), 1:], \n",
    "                                                    x[window_size:int((pred.size(dim=0)-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                            total_secondhalf += loss_fn(pred[int((pred.size(dim=0)-window_size)/2):, 1:],\n",
    "                                                        x[int((pred.size(dim=0)-window_size)/2):, 1:]).detach().cpu().numpy()  \n",
    "                            \n",
    "                predictionary[model_type] = pred\n",
    "\n",
    "            if model_type == \"lstm\":\n",
    "                for i, x in enumerate(data):\n",
    "                    x=x.to(device)\n",
    "                \n",
    "                    with torch.inference_mode():\n",
    "\n",
    "                        pred = torch.zeros((timesteps, 3), device=device)\n",
    "                        pred_next_step = torch.zeros((timesteps, 3), device=device)\n",
    "\n",
    "                        if window_size > 1:\n",
    "                            pred[0:window_size, :] = x[0:window_size, :]\n",
    "                            pred[:, 0] = x[:, 0]\n",
    "                            pred_next_step[0:window_size, :] = x[0:window_size, :]\n",
    "                            pred_next_step[:, 0] = x[:, 0]\n",
    "                        else:\n",
    "                            pred[0, :] = x[0, :]\n",
    "                            pred[:, 0] = x[:, 0]\n",
    "                            pred_next_step[0, :] = x[0, :]\n",
    "                            pred_next_step[:, 0] = x[:, 0]\n",
    "\n",
    "                        for i in range(len(x) - window_size):\n",
    "\n",
    "                            out, _ = model(pred[i:i+window_size, :])\n",
    "                            pred[i+window_size, 1:] = pred[i+window_size-1, 1:] + out[-1, :]\n",
    "                            pred_next_step[i+window_size, 1:] = x[i+window_size-1, 1:] + out[-1, :]\n",
    "                        \n",
    "                        test_loss += loss_fn(pred[:, 1], x[:, 1]).detach().cpu().numpy()\n",
    "                        test_loss_deriv += loss_fn(pred[:, 2], x[:, 2]).detach().cpu().numpy()\n",
    "\n",
    "                        total_loss += loss_fn(pred[:, 1:], x[:, 1:]).detach().cpu().numpy()\n",
    "                        error_dict[model_type].append(total_loss)\n",
    "                    \n",
    "                predictionary[model_type] = pred\n",
    "\n",
    "            if model_type == \"tcn\" :\n",
    "                    for i, x in enumerate(data):\n",
    "\n",
    "                        with torch.inference_mode():\n",
    "\n",
    "                            x=x.to(device)        \n",
    "                            x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "\n",
    "                            pred = torch.zeros_like(x, device=device)  \n",
    "                            pred_next_step = torch.zeros_like(x, device=device)               \n",
    "\n",
    "                            pred[:, 0:window_size, :] = x[0, 0:window_size, :]\n",
    "                            pred[:, :, 0] = x[0, :, 0]\n",
    "\n",
    "                            for i in range(1,x.size(1) - window_size + 1):\n",
    "\n",
    "                                pred[:, window_size+(i-1):window_size+i,1:] =  pred[:, window_size+(i-2):window_size+(i-1):,1:] + model(pred[:,i:window_size+(i-1),:].transpose(1,2))    \n",
    "\n",
    "                            test_loss += loss_fn(pred[0, :, 1], x[0, :, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[0, :, 2], x[0, :, 2]).detach().cpu().numpy()\n",
    "\n",
    "                            total_loss += loss_fn(pred[0, :, 1:], x[0, :, 1:]).detach().cpu().numpy()\n",
    "                            error_dict[model_type].append(total_loss)\n",
    "\n",
    "                        predictionary[model_type] = pred\n",
    "\n",
    "            if model_type == \"or_tcn\" :\n",
    "                    for i, x in enumerate(data):\n",
    "                    \n",
    "\n",
    "                        with torch.inference_mode():\n",
    "                            x=x.to(device)        \n",
    "                            x = x.view(1,x.size(dim=0), x.size(dim=1))                \n",
    "                            pred = torch.zeros((timesteps, 3), device=device)\n",
    "\n",
    "                            if window_size > 1:\n",
    "                                pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "\n",
    "                            else:\n",
    "                                pred[0, :] = x[0, 0, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "\n",
    "                            x_test = x.clone()\n",
    "                            x_test[:,window_size:,1:] = 0\n",
    "                            x_test = x_test.to(device)\n",
    "                            #print(\"Data passed to the model, all 0 after the initial window to prove that the forward pass is correct and doesnt access information it shouldnt.\",x_test[:,0:10,:])\n",
    "\n",
    "                            out = model(x_test.transpose(1,2))\n",
    "                            pred[window_size:,1:] = out.squeeze(0).transpose(0,1)\n",
    "\n",
    "                            test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "                            error_dict[model_type].append(total_loss)\n",
    "\n",
    "                        predictionary[model_type] = pred\n",
    "\n",
    "            if model_type == \"neural_cde\" :\n",
    "                    for i, x in enumerate(data):\n",
    "\n",
    "                        with torch.inference_mode():\n",
    "\n",
    "                            x=x.to(device)        \n",
    "                            x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "\n",
    "                            pred = torch.zeros_like(x, device=device)\n",
    "                    \n",
    "                            pred[:, 0:window_size, :] = x[0:1, 0:window_size, :]\n",
    "                            pred[:, :, 0:2] = x[0:1, :, 0:2] # time, pressure\n",
    "\n",
    "                            #start_total=time.time()\n",
    "\n",
    "                            for i in range(x.size(1) - window_size):\n",
    "                                \n",
    "                                #start_coeffs=time.time()\n",
    "                                train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(pred[0:1, i:i+window_size, :]) \n",
    "                                #train_coeffs = torchcde.linear_interpolation_coeffs(pred[0:1, i:i+window_size, :])\n",
    "\n",
    "                                #stop_coeffs=time.time()\n",
    "                                #print(stop_coeffs-start_coeffs, \"time: coeff calc one step\")\n",
    "                                if (i+1)%100==0:\n",
    "                                    print(i, \" timessteps done\")\n",
    "                                #start=time.time()\n",
    "\n",
    "                                out = model(train_coeffs)\n",
    "                                pred[0:1, i+window_size, 2:] = pred[0:1, i+window_size-1, 2:] + out.unsqueeze(1)\n",
    "\n",
    "                                #pred[0:1, i+window_size, 2:] = out\n",
    "                                #stop=time.time()\n",
    "                                #print(stop-start, \"time: model calc step\")\n",
    "\n",
    "                            test_loss += loss_fn(pred[0, window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[0, window_size:, 3], x[0, window_size:, 3]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[0, window_size:, 2:], x[0, window_size:, 2:]).detach().cpu().numpy()\n",
    "                            error_dict[model_type].append(total_loss)\n",
    "\n",
    "                            total_firsthalf += loss_fn(pred[0, window_size:int((pred.size(dim=1)-window_size)/2), 2:], \n",
    "                                                        x[0, window_size:int((pred.size(dim=1)-window_size)/2), 2:]).detach().cpu().numpy()  \n",
    "                            total_secondhalf += loss_fn(pred[0, int((pred.size(dim=1)-window_size)/2):, 2:],\n",
    "                                                            x[0, int((pred.size(dim=1)-window_size)/2):, 2:]).detach().cpu().numpy()  \n",
    "                    \n",
    "                        predictionary[model_type] = pred\n",
    "\n",
    "            if model_type == \"or_mlp\" :\n",
    "                    \n",
    "                    for i, x in enumerate(data):\n",
    "                    \n",
    "\n",
    "                        with torch.inference_mode():\n",
    "                            x=x.to(device)        \n",
    "                            x = x.view(1,x.size(dim=0), x.size(dim=1))                \n",
    "                            pred = torch.zeros((timesteps, 3), device=device)\n",
    "\n",
    "                            if window_size > 1:\n",
    "                                pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "\n",
    "                            else:\n",
    "                                pred[0, :] = x[0, 0, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "\n",
    "                            x_test = x.clone()\n",
    "                            x_test[:,window_size:,1:] = 0\n",
    "                            x_test = x_test.to(device)\n",
    "\n",
    "                            out = model(x_test)\n",
    "                            \n",
    "                            pred[window_size:,1:] = out\n",
    "\n",
    "                            test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "                            error_dict[model_type].append(total_loss)\n",
    "\n",
    "                            total_firsthalf += loss_fn(pred[window_size:int((pred.size(dim=0)-window_size)/2), 1:], \n",
    "                                                        x[0, window_size:int((pred.size(dim=0)-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                            total_secondhalf += loss_fn(pred[int((pred.size(dim=0)-window_size)/2):, 1:],\n",
    "                                                        x[0, int((pred.size(dim=0)-window_size)/2):, 1:]).detach().cpu().numpy()\n",
    "                            \n",
    "                        predictionary[model_type] = pred\n",
    "\n",
    "# Type 2: next step prediction \n",
    "            if model_type == \"lstm_or_nextstep\":\n",
    "                for i, x in enumerate(data):\n",
    "\n",
    "                    x=x.to(device)        \n",
    "                    x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "\n",
    "                    with torch.inference_mode():\n",
    "            \n",
    "                        pred = torch.zeros((timesteps, 3), device=device)\n",
    "            \n",
    "                        if window_size > 1:\n",
    "                            pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                            pred[:, 0] = x[0, :, 0]\n",
    "            \n",
    "                        else:\n",
    "                            pred[0, :] = x[0, 0, :]\n",
    "                            pred[:, 0] = x[0, :, 0]\n",
    "            \n",
    "                        \n",
    "                        out, _ = model(x)\n",
    "                        pred[window_size:,1:] = out\n",
    "\n",
    "                        test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                        test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                        total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "                        error_dict[model_type].append(total_loss)\n",
    "\n",
    "                        total_firsthalf += loss_fn(pred[window_size:int((timesteps-window_size)/2), 1:], \n",
    "                                x[0, window_size:int((timesteps-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                        total_secondhalf += loss_fn(pred[int((timesteps-window_size)/2):, 1:],\n",
    "                                    x[0, int((timesteps-window_size)/2):, 1:]).detach().cpu().numpy()\n",
    "                        predictionary[model_type] = pred\n",
    "\n",
    "\n",
    "            if model_type == \"mlp_or_nextstep\" :\n",
    "                for i, x in enumerate(data):\n",
    "\n",
    "                    with torch.inference_mode():\n",
    "                        x=x.to(device)        \n",
    "                        x = x.view(1,x.size(dim=0), x.size(dim=1))                \n",
    "                        pred = torch.zeros((timesteps, 3), device=device)\n",
    "            \n",
    "                        if window_size > 1:\n",
    "                            pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                            pred[:, 0] = x[0, :, 0]\n",
    "            \n",
    "                        else:\n",
    "                            pred[0, :] = x[0, 0, :]\n",
    "                            pred[:, 0] = x[0, :, 0]\n",
    "            \n",
    "                        x_test = x.clone()\n",
    "                        x_test[:,window_size:,1:] = 0\n",
    "                        x_test = x_test.to(device)\n",
    "                        #print(\"Data passed to the model, all 0 after the initial window to prove that the forward pass is correct and doesnt access information it shouldnt.\",x_test[:,0:10,:])\n",
    "\n",
    "                        out = model(x_test)\n",
    "                        \n",
    "                        pred[window_size:,1:] = out\n",
    "\n",
    "                        test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                        test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                        total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "                        error_dict[model_type].append(total_loss)\n",
    "\n",
    "                        total_firsthalf += loss_fn(pred[window_size:int((pred.size(dim=0)-window_size)/2), 1:], \n",
    "                                                    x[0, window_size:int((pred.size(dim=0)-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                        total_secondhalf += loss_fn(pred[int((pred.size(dim=0)-window_size)/2):, 1:],\n",
    "                                                        x[0, int((pred.size(dim=0)-window_size)/2):, 1:]).detach().cpu().numpy()\n",
    "                predictionary[model_type] = pred\n",
    "\n",
    "            if model_type == \"tcn_or_nextstep\" :\n",
    "                for i, x in enumerate(data):\n",
    "\n",
    "\n",
    "                    with torch.inference_mode():\n",
    "                        x=x.to(device)        \n",
    "                        x = x.view(1,x.size(dim=0), x.size(dim=1))                \n",
    "                        pred = torch.zeros((timesteps, 3), device=device)\n",
    "            \n",
    "                        if window_size > 1:\n",
    "                            pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                            pred[:, 0] = x[0, :, 0]\n",
    "            \n",
    "                        else:\n",
    "                            pred[0, :] = x[0, 0, :]\n",
    "                            pred[:, 0] = x[0, :, 0]\n",
    "            \n",
    "                        x_test = x.clone()\n",
    "                        x_test[:,window_size:,1:] = 0\n",
    "                        x_test = x_test.to(device)\n",
    "                        #print(\"Data passed to the model, all 0 after the initial window to prove that the forward pass is correct and doesnt access information it shouldnt.\",x_test[:,0:10,:])\n",
    "\n",
    "                        out = model(x_test.transpose(1,2))\n",
    "                        \n",
    "                        pred[window_size:,1:] = out.squeeze(0).transpose(0,1)\n",
    "\n",
    "                        test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                        test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                        total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "                        error_dict[model_type].append(total_loss)\n",
    "                predictionary[model_type] = pred\n",
    "\n",
    "        if not plot_errs:\n",
    "            phase_plot_predictions(predictionary, data)\n",
    "            plot_predictions(predictionary, data)\n",
    "        else:\n",
    "            plot_errors(error_dict, data)\n",
    "\n",
    "\n",
    "def plot_predictions(predictionary, x):\n",
    "\n",
    "\n",
    "\n",
    "    p_max = 3.5*1e5 #Druck in [bar]         ... [1 , 3.5]\n",
    "    s_max = 0.6*1e-3 #Position [m]          ... [0, 0.0006]\n",
    "    w_max = 1.7 #Geschwindigkeit in [m/s]   ... [-1.7, 1.7]\n",
    "    p_min = 1.0\n",
    "    s_min = 0.0\n",
    "    w_min = -1.7\n",
    "    physics_rescaling = [p_max, s_max, w_max, p_min, s_min, w_min]\n",
    "\n",
    "    colors = {\"or_lstm\" : \"red\",\n",
    "              \"lstm_or_nextstep\" : \"red\",\n",
    "              \"or_mlp\" : \"green\",\n",
    "              \"mlp_or_nextstep\" : \"green\",\n",
    "              \"mlp\" : \"green\",\n",
    "              \"or_tcn\" : \"purple\",\n",
    "              \"tcn_or_nextstep\" : \"purple\",\n",
    "              \"neural_cde\"  : \"brown\"}\n",
    "    \n",
    "    if \"or_lstm\" in list(predictionary.keys()) and \"lstm_or_nextstep\" in list(predictionary.keys()):\n",
    "        colors = {\"or_lstm\" : \"red\", \"lstm_or_nextstep\" : \"yellow\", \"lstm_no_or_nextstep\" : \"green\", \"lstm_derivative\" : \"purple\"}\n",
    "\n",
    "    figure , axs = plt.subplots(3,1, figsize=(16,9))\n",
    "    figure.tight_layout(pad=5.0)    \n",
    "\n",
    "    if x.dim() == 3:\n",
    "        x = x.view(x.size(dim=1), x.size(dim=2))\n",
    "    \n",
    "        #scale back:    \n",
    "    if physics_rescaling != None:\n",
    "\n",
    "        x[:,0] = x[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "        x[:,1] = x[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        x[:,2] = x[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    greek_letterz=[chr(code) for code in range(945,970)]\n",
    "    mu = greek_letterz[11]\n",
    "\n",
    "    stepsize = 2e-5\n",
    "    time = np.linspace(0,x.size(dim=0)* stepsize, x.size(dim=0))\n",
    "\n",
    "    #data\n",
    "    axs[0].plot(time, x.detach().cpu().numpy()[:, 1], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    axs[1].plot(time, x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    axs[2].plot(time, x.detach().cpu().numpy()[:,0], label=\"pressure\")\n",
    "\n",
    "    #predictions\n",
    "    for key, pred in predictionary.items():\n",
    "\n",
    "        if physics_rescaling != None:\n",
    "\n",
    "            # we invert:\n",
    "            # x = (x - xmin)/(xmax - xmin)\n",
    "            # x * (xmax - xmin) + xmin\n",
    "\n",
    "            pred[:,0] = pred[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "            pred[:,1] = pred[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "            pred[:,2] = pred[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.view(pred.size(dim=1), pred.size(dim=2))\n",
    "\n",
    "        axs[0].plot(time, pred.detach().cpu().numpy()[:, 1], color=colors[key], label=f\"{key}-prediciton\", alpha=0.5)\n",
    "        axs[1].plot(time, pred.detach().cpu().numpy()[:, 2], color=colors[key], label=f\"{key}-prediciton\", alpha=0.5)\n",
    "\n",
    "\n",
    "    axs[0].set_title(\"position\")\n",
    "    axs[0].set_ylabel(\"[m]\")\n",
    "    axs[0].set_xlabel(f\"time [s]\")\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()   \n",
    "    axs[1].set_title(\"speed\")\n",
    "    axs[1].set_ylabel(\"[m/s]\")\n",
    "    axs[1].set_xlabel(f\"time [s]\")\n",
    "    axs[1].grid()\n",
    "    axs[1].legend()\n",
    "    axs[2].set_title(\"pressure\")\n",
    "    axs[2].set_ylabel(\"[Pa]\")\n",
    "    axs[2].set_xlabel(f\"time [s]\")\n",
    "    axs[2].grid()\n",
    "    axs[2].legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def phase_plot_predictions(predictionary, x):\n",
    "\n",
    "\n",
    "\n",
    "    p_max = 3.5*1e5 #Druck in [bar]         ... [1 , 3.5]\n",
    "    s_max = 0.6*1e-3 #Position [m]          ... [0, 0.0006]\n",
    "    w_max = 1.7 #Geschwindigkeit in [m/s]   ... [-1.7, 1.7]\n",
    "    p_min = 1.0\n",
    "    s_min = 0.0\n",
    "    w_min = -1.7\n",
    "    physics_rescaling = [p_max, s_max, w_max, p_min, s_min, w_min]\n",
    "\n",
    "    colors = {\"or_lstm\" : \"red\",\n",
    "              \"or_mlp\" : \"green\",\n",
    "              \"or_tcn\" : \"purple\",\n",
    "              \"neural_cde\"  : \"brown\"}\n",
    "\n",
    "    figure , axs = plt.subplots(1,1, figsize=(16,16))\n",
    "    figure.tight_layout(pad=5.0)    \n",
    "\n",
    "    if x.dim() == 3:\n",
    "        x = x.view(x.size(dim=1), x.size(dim=2))\n",
    "    \n",
    "        #scale back:    \n",
    "    if physics_rescaling != None:\n",
    "\n",
    "        x[:,0] = x[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "        x[:,1] = x[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        x[:,2] = x[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    greek_letterz=[chr(code) for code in range(945,970)]\n",
    "    mu = greek_letterz[11]\n",
    "\n",
    "    stepsize = 2e-5\n",
    "    time = np.linspace(0,x.size(dim=0)* stepsize, x.size(dim=0))\n",
    "\n",
    "    #data\n",
    "    axs.plot(x.detach().cpu().numpy()[:, 1],x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "\n",
    "    #predictions\n",
    "    for key, pred in predictionary.items():\n",
    "\n",
    "        if physics_rescaling != None:\n",
    "\n",
    "            # we invert:\n",
    "            # x = (x - xmin)/(xmax - xmin)\n",
    "            # x * (xmax - xmin) + xmin\n",
    "\n",
    "            pred[:,0] = pred[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "            pred[:,1] = pred[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "            pred[:,2] = pred[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.view(pred.size(dim=1), pred.size(dim=2))\n",
    "\n",
    "        axs.plot(pred.detach().cpu().numpy()[:, 1], pred.detach().cpu().numpy()[:, 2], color=colors[key], label=f\"{key}-prediciton\", alpha=0.5)\n",
    "\n",
    "    axs.set_title(\"position\")\n",
    "    axs.set_ylabel(\"[m]\")\n",
    "    axs.set_xlabel(f\"time [s]\")\n",
    "    axs.grid()\n",
    "    axs.legend()   \n",
    "\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_errors(predictionary, x):\n",
    "     \n",
    "    # Plot histograms with MSE over many trajectories\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot each histogram on the same axes\n",
    "    for key, values in predictionary.items():\n",
    "        #plt.plot(np.array(values))\n",
    "        ax.hist(np.array(values).flatten(), bins=20, alpha=0.5, label=key)\n",
    "        ax.axvline(np.array(values).mean(), color='red', linestyle='dashed', linewidth=2, label=f\"{key} : Mean MSE {np.round(np.array(values).mean(),7)}\")\n",
    "\n",
    "    # Set titles and labels\n",
    "    ax.set_title('Mean squared errors over X trajectories')\n",
    "    ax.set_xlabel('MSE')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlist(a):\n",
    "    return [ (x - min(a)) / (max(a) - min(a)) for x in a]\n",
    "\n",
    "Epochs = [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "LSTM = [0.028456646258258722, 0.022694337263373117, 0.026009841374953605, 0.03045055947042709, 0.019146433432510185, 0.0076781917215315715, 0.00730898111993305, 0.007876552085049473, 0.007547752849599885, 0.006278254707170924]\n",
    "# MLP hat ausrei√üer\n",
    "#MLP = [0.01856441755029323, 0.013231895836598232, 0.010403810288739296, 0.008548521189701832, 0.009579918550359865, 0.008980504622523996, 0.009289483926369347, 0.006702352100843063, 3599.2784327571107, 0.009543711781792218]\n",
    "MLP = [0.01856441755029323, 0.013231895836598232, 0.010403810288739296, 0.008548521189701832, 0.009579918550359865, 0.008980504622523996, 0.009289483926369347, 0.006702352100843063, 0.006702352100843063, 0.009543711781792218]\n",
    "TCN = [0.03306022808310429, 0.012185637813547628, 0.008335839578852183, 0.0038785364358451145, 0.0031343244156947217, 0.003462088193589699, 0.003981136428790162, 0.002496261116017282, 0.0026503715556096402, 0.0020942350182145074]\n",
    "#MLP = normlist(MLP)\n",
    "#LSTM = normlist(LSTM)\n",
    "#TCN = normlist(TCN)\n",
    "LSTM2 = [0.024987961961632846, 0.016181169585631445, 0.014161591938671236, 0.01406885179196545, 0.012409247708514435, 0.010494681192992274, 0.008844779220702037, 0.006999178763346141, 0.006394357812348286, 0.005090870408819805]\n",
    "MLP2 = [0.0198861211717555, 0.010500711235144832, 0.007480574647699809, 0.006824193687648814, 0.006275183383519934, 0.004428913574496422, 0.003949885732163199, 0.0032829739688022457, 0.0035847660291489, 0.003276470429756819]\n",
    "TCN2 = [0.01730283516845159, 0.01574904319763183, 0.013428775159859312, 0.010616026681713377, 0.006429868407236622, 0.006101762805938836, 0.006622495231124482, 0.007598870176500983, 0.00687686763729292, 0.004873080602545475]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(16,9))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i,j in [(0,0), (1,0), (0,1), (1,1)]:\n",
    "    axs[i,j].grid(True)\n",
    "    axs[i,j].set_ylabel(\"MSE\")\n",
    "    axs[i,j].set_xlabel(\"Epochs\")\n",
    "\n",
    "axs[0,0].plot(Epochs, LSTM, color=\"b\")\n",
    "axs[0,0].plot(Epochs, MLP, color=\"g\")\n",
    "axs[0,0].plot(Epochs, TCN, color=\"r\")\n",
    "axs[0,0].set_title(\"OR-Rightside\")\n",
    "\n",
    "axs[1,0].plot(Epochs, LSTM2, color=\"b\")\n",
    "axs[1,0].plot(Epochs, MLP2, color=\"g\")\n",
    "axs[1,0].plot(Epochs, TCN2, color=\"r\")\n",
    "axs[1,0].set_title(\"OR-Nextstep\")\n",
    "\n",
    "axs[0,1].plot(Epochs, LSTM, color=\"b\")\n",
    "axs[0,1].plot(Epochs, MLP, color=\"g\")\n",
    "axs[0,1].plot(Epochs, TCN, color=\"r\")\n",
    "axs[0,1].set_title(\"Rightside\")\n",
    "\n",
    "axs[1,1].plot(Epochs, LSTM, color=\"b\")\n",
    "axs[1,1].plot(Epochs, MLP, color=\"g\")\n",
    "axs[1,1].plot(Epochs, TCN, color=\"r\")\n",
    "axs[1,1].set_title(\"Nextstep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test trajectories\n",
    "\n",
    "params_lstm =   {\n",
    "                        \"window_size\" : 16,\n",
    "                        \"h_size\" : 8,\n",
    "                        \"l_num\" : 3,\n",
    "                        \"learning_rate\" : 0.0008,\n",
    "                        \"batch_size\" : 20,\n",
    "                }\n",
    "\n",
    "params_mlp =    {\n",
    "                        \"window_size\" : 20,\n",
    "                        \"h_size\" : 24,\n",
    "                        \"l_num\" : 3,\n",
    "                        \"learning_rate\" : 0.001,\n",
    "                        \"batch_size\" : 20,\n",
    "                        \"act_fn\" : \"relu\",\n",
    "                        \"nonlin_at_out\" : None #None if no nonlinearity at the end\n",
    "                }\n",
    "\n",
    "params_tcn =    {\n",
    "                    \"window_size\" : 30,\n",
    "                    \"learning_rate\" : 0.001,\n",
    "                    \"batch_size\" : 20,\n",
    "                    \"n_hidden\" : 5,\n",
    "                    \"levels\" : 4,\n",
    "                    \"kernel_size\" : 7,\n",
    "                    \"dropout\" : 0,\n",
    "                    \"input_channels\" : 3,\n",
    "                    \"output\" : 2,\n",
    "                    \"drop_half_timesteps\" : True,\n",
    "                    \"cut_off_timesteps\" : 100,\n",
    "                    \"part_of_data\" : 0,\n",
    "                    \"percentage_of_data\" : 0.8\n",
    "\n",
    "                }\n",
    "    \n",
    "parameter_configs  = [params_lstm, params_mlp, params_tcn] \n",
    "\n",
    "path = \"data\\save_data_test_5xlonger_dyndyn.csv\"\n",
    "#path = \"data\\save_data_test_revised.csv\"\n",
    "input_data, PSW_max = get_data(path = path, \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params_tcn[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params_tcn[\"part_of_data\"])\n",
    "\n",
    "#print(input_data.size())\n",
    "\n",
    "np.random.seed(1234)\n",
    "#print(\"input_data size\", input_data.size())\n",
    "num_of_inits_train = int(len(input_data)*params_tcn[\"percentage_of_data\"])\n",
    "train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "np.random.shuffle(train_inits)\n",
    "np.random.shuffle(test_inits)\n",
    "test_data = input_data[test_inits,:,:]\n",
    "np.random.seed()\n",
    "\n",
    "#load models\n",
    "\n",
    "# Initialize the LSTM model\n",
    "model_lstm = LSTMmodel(input_size=3, hidden_size=params_lstm[\"h_size\"], out_size=2, layers=params_lstm[\"l_num\"], window_size=params_lstm[\"window_size\"]).to(device)\n",
    "path_lstm = \"First_experiment_run_22_07_2024\\OR_LSTM_exp0.pth\"\n",
    "model_lstm.load_state_dict(torch.load(path_lstm, map_location=torch.device(device)))\n",
    "\n",
    "model_lstm_nextstep = LSTMmodel_or_nextstep(input_size=3, hidden_size=params_lstm[\"h_size\"], out_size=2, layers=params_lstm[\"l_num\"], window_size = params_lstm[\"window_size\"]).to(device)\n",
    "path_lstm_nextstep = \"First_experiment_run_22_07_2024\\LSTM_or_nextstep_exp0.pth\"\n",
    "model_lstm_nextstep.load_state_dict(torch.load(path_lstm_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "# Initialize the MLP model\n",
    "model_or_mlp = OR_MLP(input_size=3*params_mlp[\"window_size\"], hidden_size = params_mlp[\"h_size\"], l_num=params_mlp[\"l_num\"], output_size=2, act_fn = params_mlp[\"act_fn\"],\n",
    "                    act_at_end = params_mlp[\"nonlin_at_out\"], timesteps=params_mlp[\"window_size\"]).to(device)\n",
    "path_or_mlp = \"First_experiment_run_22_07_2024\\OR_MLP_exp1.pth\"\n",
    "model_or_mlp.load_state_dict(torch.load(path_or_mlp, map_location=torch.device(device)))\n",
    "\n",
    "model_or_mlp_nextstep = MLP_or_nextstep(input_size=3*params_mlp[\"window_size\"], hidden_size = params_mlp[\"h_size\"], l_num=params_mlp[\"l_num\"],\n",
    "                output_size=2, act_fn = params_mlp[\"act_fn\"], act_at_end = params_mlp[\"nonlin_at_out\"], timesteps=params_mlp[\"window_size\"]).to(device)\n",
    "path_or_mlp_nextstep = \"First_experiment_run_22_07_2024\\MLP_or_nextstep_exp1.pth\"\n",
    "model_or_mlp_nextstep.load_state_dict(torch.load(path_or_mlp_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "# Initialize the TCN model\n",
    "input_channels = params_tcn[\"input_channels\"]\n",
    "output = params_tcn[\"output\"]\n",
    "num_channels = [params_tcn[\"n_hidden\"]] * params_tcn[\"levels\"]\n",
    "kernel_size = params_tcn[\"kernel_size\"]\n",
    "dropout = params_tcn[\"dropout\"]\n",
    "\n",
    "model_tcn = OR_TCN(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "path_tcn = \"First_experiment_run_22_07_2024\\OR_TCN_exp2.pth\"\n",
    "model_tcn.load_state_dict(torch.load(path_tcn, map_location=torch.device(device)))\n",
    "\n",
    "model_tcn_nextstep = TCN_or_nextstep(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "path_tcn_nextstep = \"First_experiment_run_22_07_2024\\TCN_or_nextstep_exp2.pth\"\n",
    "model_tcn_nextstep.load_state_dict(torch.load(path_tcn_nextstep, map_location=torch.device(device)))\n",
    "\n",
    "# TODO Neural CDE  \n",
    "#model = NeuralCDE(input_channels=4, hidden_channels=params[\"h_size\"], hidden_width = params[\"h_width\"], output_channels=2).to(device)\n",
    "#model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "models = {\"or_lstm\" : model_lstm,\n",
    "          \"or_mlp\" : model_or_mlp,\n",
    "          #\"mlp\" : model_mlp,\n",
    "          \"or_tcn\" : model_tcn\n",
    "          }\n",
    "\n",
    "window_sizes = {\"or_lstm\" : params_lstm[\"window_size\"],\n",
    "                \"or_mlp\" : params_mlp[\"window_size\"],\n",
    "                \"mlp\" : params_mlp[\"window_size\"],\n",
    "                \"or_tcn\" : params_tcn[\"window_size\"],\n",
    "                \"lstm_or_nextstep\" : params_lstm[\"window_size\"],\n",
    "                \"mlp_or_nextstep\" : params_mlp[\"window_size\"],\n",
    "                \"tcn_or_nextstep\" : params_tcn[\"window_size\"]\n",
    "                }\n",
    "    \n",
    "models_nextstep = {\"lstm_or_nextstep\" : model_lstm_nextstep,\n",
    "          \"mlp_or_nextstep\" : model_or_mlp_nextstep,\n",
    "          #\"mlp\" : model_mlp,\n",
    "          \"tcn_or_nextstep\" : model_tcn_nextstep\n",
    "          }\n",
    "\n",
    "fixed_model_categories = {\"lstm_or_nextstep\" : model_lstm_nextstep, \n",
    "                          \"or_lstm\" : model_lstm}\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "test_inits = input_data.size(dim=0)\n",
    "ids = np.random.choice(test_inits, min([input_data.size(dim=0), 10]), replace=False)\n",
    "ids = np.unique(ids)\n",
    "\n",
    "exp1(models, input_data[0:50,:,:], window_sizes, plot_errs=True)\n",
    "\n",
    "#  0.005090870408819805]\n",
    "#  0.003276470429756819]\n",
    "#  0.004873080602545475] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

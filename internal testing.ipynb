{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "from tqdm import tqdm\n",
    "from get_data import *\n",
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data generated via matlab/simulink:\n",
    "\n",
    "# see get_data.py for more info\n",
    "data_tensor = get_data(path = \"save_data_test3.csv\", timesteps_from_data=0, skip_steps_start = 0, skip_steps_end = 0, drop_half_timesteps = False, normalise_s_w=True, rescale_p=False, num_inits=0)\n",
    "\n",
    "# View an example of a simulation run\n",
    "#visualise(data_tensor, num_inits=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    " #Define the LSTM model class\n",
    "\n",
    "# Use the GPU if available\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device=\"cpu\"\n",
    "print(device)\n",
    "\n",
    "class LSTMmodel(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model class for derivative estimation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, out_size, layers):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM model.\n",
    "\n",
    "        Args:\n",
    "        - input_size: Size of input\n",
    "        - hidden_size: Size of hidden layer\n",
    "        - out_size: Size of output\n",
    "        - layers: Number of layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.act = nn.ReLU()\n",
    "        # Define LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=layers, batch_first=True)\n",
    "\n",
    "        # Define linear layer\n",
    "        self.linear = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        \"\"\"\n",
    "        Forward pass through the LSTM model.\n",
    "\n",
    "        Args:\n",
    "        - seq: Input sequence\n",
    "\n",
    "        Returns:\n",
    "        - pred: Model prediction\n",
    "        - hidden: Hidden state\n",
    "        \"\"\"\n",
    "        lstm_out, hidden = self.lstm(seq)\n",
    "        #lstm_out = self.act(lstm_out)\n",
    "        pred = self.linear(lstm_out)\n",
    "\n",
    "        return pred, hidden\n",
    "\n",
    "\n",
    "class GRUmodel(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model class for derivative estimation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, out_size, layers):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM model.\n",
    "\n",
    "        Args:\n",
    "        - input_size: Size of input\n",
    "        - hidden_size: Size of hidden layer\n",
    "        - out_size: Size of output\n",
    "        - layers: Number of layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Define LSTM layer\n",
    "        self.lstm = nn.GRU(input_size, hidden_size, num_layers=layers, batch_first=True)\n",
    "\n",
    "        # Define linear layer\n",
    "        self.linear = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        \"\"\"\n",
    "        Forward pass through the LSTM model.\n",
    "\n",
    "        Args:\n",
    "        - seq: Input sequence\n",
    "\n",
    "        Returns:\n",
    "        - pred: Model prediction\n",
    "        - hidden: Hidden state\n",
    "        \"\"\"\n",
    "        lstm_out, hidden = self.lstm(seq)\n",
    "        pred = self.linear(lstm_out)\n",
    "\n",
    "        return pred, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data, model, steps=600, ws=10, plot_opt=False, n = 5):\n",
    "\n",
    "    #test_data = test_dataloader.get_all_data() \n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    test_loss = 0\n",
    "    test_loss_deriv = 0\n",
    "    total_loss = 0\n",
    "    #np.random.seed(123)\n",
    "    ids = np.random.choice(test_data.size(dim=0), min([n, test_data.size(dim=0)]), replace=False)\n",
    "    ids = np.unique(ids)\n",
    "\n",
    "    for i, x in enumerate(test_data):\n",
    "        x=x.to(device)\n",
    "        if i not in ids:\n",
    "            continue\n",
    "\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            pred = torch.zeros((steps, 3), device=device)\n",
    "            pred_next_step = torch.zeros((steps, 3), device=device)\n",
    "\n",
    "            if ws > 1:\n",
    "                pred[0:ws, :] = x[0:ws, :]\n",
    "                pred[:, 0] = x[:, 0]\n",
    "                pred_next_step[0:ws, :] = x[0:ws, :]\n",
    "                pred_next_step[:, 0] = x[:, 0]\n",
    "            else:\n",
    "                pred[0, :] = x[0, :]\n",
    "                pred[:, 0] = x[:, 0]\n",
    "                pred_next_step[0, :] = x[0, :]\n",
    "                pred_next_step[:, 0] = x[:, 0]\n",
    "\n",
    "            for i in range(len(x) - ws):\n",
    "\n",
    "                out, _ = model(pred[i:i+ws, :])\n",
    "                pred[i+ws, 1:] = pred[i+ws-1, 1:] + out[-1, :]\n",
    "                pred_next_step[i+ws, 1:] = x[i+ws-1, 1:] + out[-1, :]\n",
    "            \n",
    "            test_loss += loss_fn(pred[:, 1], x[:, 1]).detach().cpu().numpy()\n",
    "            test_loss_deriv += loss_fn(pred[:, 2], x[:, 2]).detach().cpu().numpy()\n",
    "\n",
    "            total_loss += loss_fn(pred[:, 1:], x[:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "            if plot_opt:\n",
    "                figure , axs = plt.subplots(1,3,figsize=(16,9))\n",
    "            \n",
    "                axs[0].plot(pred.detach().cpu().numpy()[:, 1], color=\"red\", label=\"pred\")\n",
    "                axs[0].plot(pred_next_step.detach().cpu().numpy()[:, 1], color=\"green\", label=\"next step from data\")\n",
    "                axs[0].plot(x.detach().cpu().numpy()[:, 1], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "                axs[0].set_title(\"position\")\n",
    "                axs[0].grid()\n",
    "                axs[0].legend()\n",
    "\n",
    "                axs[1].plot(pred.detach().cpu().numpy()[:, 2], color=\"red\", label=\"pred\")\n",
    "                axs[1].plot(pred_next_step.detach().cpu().numpy()[:, 2], color=\"green\", label=\"next step from data\")\n",
    "                axs[1].plot(x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "                axs[1].set_title(\"speed\")\n",
    "                axs[1].grid()\n",
    "                axs[1].legend()\n",
    "\n",
    "                axs[2].plot(x.detach().cpu().numpy()[:,0], label=\"pressure\")\n",
    "                axs[2].set_title(\"pressure\")\n",
    "                axs[2].grid()\n",
    "                axs[2].legend()\n",
    "\n",
    "                plt.grid(True)\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            \n",
    "    return np.mean(test_loss), np.mean(test_loss_deriv), np.mean(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works:\n",
    "def train1(input_data, model, weight_decay, future_decay, learning_rate=0.001, ws=0, future=1):\n",
    "    \"\"\"\n",
    "    Train the LSTM model using input data.\n",
    "\n",
    "    Args:\n",
    "    - input_data: Input data for training\n",
    "    - model: LSTM model to be trained\n",
    "    - ws: Window size\n",
    "    - odestep: Option for using ODE steps\n",
    "    - use_autograd: Option for using autograd\n",
    "\n",
    "    Returns:\n",
    "    - Mean loss over all batches\n",
    "    \"\"\"\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "\n",
    "    for k, (inp, label) in enumerate(input_data):  # inp = (u, x) label = x\n",
    "        #print(k, f\"timesteps {k} : {k+4} mit label bis {k+6}\")\n",
    "        inp=inp.to(device)\n",
    "        label=label.to(device)\n",
    "\n",
    "        # Predict one timestep :\n",
    "        output, _ = model(inp)\n",
    "        out = inp[:, :, 1:] + output\n",
    "\n",
    "        # print(\"inp\", inp, inp.size())\n",
    "        # print(\"label\", label, label.size())\n",
    "        # print(\"out\", out, out.size())\n",
    "        \n",
    "        #1. extra step-------------------------\n",
    "        if future>1:\n",
    "            new_combined_inp = torch.cat((label[:, 0, 0:1], out[:,-1,:]), dim=1)\n",
    "            new_combined_inp = new_combined_inp.view(inp.size(dim=0),1,3)\n",
    "\n",
    "            #print(\"new_combined_inp\", new_combined_inp, new_combined_inp.size())\n",
    "\n",
    "            inp2 = torch.cat((inp[: , 1:ws,:], new_combined_inp), dim =1)        \n",
    "            #print(\"inp2\" , inp2, inp2.size())\n",
    "\n",
    "            output2, _ = model(inp2)\n",
    "            out2 = inp2[:, :, 1:] + output2\n",
    "\n",
    "            #print(\"out2\", out2, out2.size())\n",
    "\n",
    "        #2. extra step-------------------------\n",
    "        if future > 2:\n",
    "            #new_combined_inp2 = torch.cat((label[:, 1, 0:1], out2[:,-1,:].clone()), dim=1)\n",
    "            new_combined_inp2 = torch.cat((label[:, 1, 0:1], out2[:,-1,:]), dim=1)\n",
    "            new_combined_inp2 = new_combined_inp2.view(inp2.size(dim=0),1,3)\n",
    "\n",
    "            inp3 = torch.cat((inp2[: , 1:ws,:], new_combined_inp2), dim =1)        \n",
    "\n",
    "            output3, _ = model(inp3)\n",
    "            out3 = inp3[:, :, 1:] + output3\n",
    "        \n",
    "        #3. extra step-------------------------\n",
    "        if future > 3:\n",
    "            new_combined_inp3 = torch.cat((label[:, 1, 0:1], out3[:,-1,:].clone()), dim=1)\n",
    "            new_combined_inp3 = new_combined_inp3.view(inp2.size(dim=0),1,3)\n",
    "\n",
    "            inp4 = torch.cat((inp3[: , 1:ws,:], new_combined_inp3), dim =1)        \n",
    "\n",
    "            output4, _ = model(inp4)\n",
    "            out4 = inp4[:, :, 1:] + output4\n",
    "\n",
    "        # reset the gradient\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # calculate the error\n",
    "        if future<2:\n",
    "            loss = loss_fn(out[:,-1,:], label[:, 1:])\n",
    "        else:   \n",
    "            loss = loss_fn(out[:,-1,:], label[:, 0, 1:])\n",
    "\n",
    "        #backpropagation\n",
    "        if future>1:\n",
    "            loss2 = future_decay * loss_fn(out2[:,-1,:], label[:, 1, 1:])\n",
    "            loss += loss2\n",
    "        if future>2:\n",
    "            loss3 = future_decay * loss_fn(out3[:,-1,:], label[:, 2, 1:])\n",
    "            loss += loss3\n",
    "        if future>3:\n",
    "            loss4 = future_decay * loss_fn(out4[:,-1,:], label[:, 3, 1:])\n",
    "            loss += loss4\n",
    "            print(loss4)\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "   # return the average error of the next step prediction\n",
    "    return np.mean(total_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(input_data, model, weight_decay, future_decay, learning_rate=0.001, ws=0, future=1, timesteps=0, batch_size=0):\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "\n",
    "    for k, (inp, label) in enumerate(input_data):  \n",
    "        print(ws+(k)*(batch_size + ws + future), ws+(k+1)*(batch_size + ws + future))\n",
    "        if ((k+1)%(timesteps/batch_size))*(batch_size + ws + future) > timesteps:\n",
    "            print(\"skipping\")\n",
    "            continue\n",
    "        # if k%future != 0:\n",
    "        #     continue\n",
    "        \n",
    "        inp=inp.to(device)\n",
    "        label=label.to(device)\n",
    "\n",
    "        # Predict one timestep :\n",
    "        output, _ = model(inp)\n",
    "        out = inp[:, :, 1:] + output\n",
    "        \n",
    "        inputs = [0]\n",
    "        outputs = [out]\n",
    "        loss_future = []\n",
    "\n",
    "        for t in range(future-1): \n",
    "           \n",
    "            new_combined_inp = torch.cat((label[:, t, 0:1], outputs[t][:,-1,:]), dim=1)\n",
    "            new_combined_inp = new_combined_inp.view(inp.size(dim=0),1,3)\n",
    "            if t>0:\n",
    "                inputs.append(torch.cat((inputs[t-1][: , 1:ws,:], new_combined_inp), dim =1))\n",
    "            else:\n",
    "                inputs[0] = torch.cat((inp[: , 1:ws,:], new_combined_inp), dim =1)\n",
    "\n",
    "            output2, _ = model(inputs[t])\n",
    "            outputs.append(inputs[t][:, :, 1:] + output2)\n",
    "\n",
    "            loss_future.append(loss_fn(outputs[t][:,-1,:], label[:, t+1, 1:]))\n",
    "\n",
    "\n",
    "        # reset the gradient\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # calculate the error\n",
    "        if future<2:\n",
    "            loss = loss_fn(out[:,-1,:], label[:, 1:])\n",
    "        else:   \n",
    "            loss = loss_fn(out[:,-1,:], label[:, 0, 1:])\n",
    "\n",
    "        #backpropagation\n",
    "        if future>1:\n",
    "            for loss_f in loss_future:\n",
    "             loss += future_decay * loss_f\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "   # return the average error of the next step prediction\n",
    "    return np.mean(total_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1100, 3])\n",
      "torch.Size([8, 100, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.6208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.7575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.4072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.5365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.3071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.2139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8034, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:03,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.8924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(3.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.9767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.7021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.8175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.6217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2.1420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.5668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0725, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, the average next step error was : loss_epoch\n",
      "Average error over full trajectories: training data : 837.8120490925781\n",
      "Average error over full trajectories: testing data : 10558.220479885771\n",
      "tensor(0.5367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9980, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1916, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:03,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.4028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2807, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1700, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2890, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.7763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5909, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3725, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.8451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.6813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2830, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:02<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, the average next step error was : loss_epoch\n",
      "Average error over full trajectories: training data : 282.45782962769823\n",
      "Average error over full trajectories: testing data : 2558.8003248697933\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.5590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1442, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:02<00:02,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.4170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.3533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1285, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:03<00:02,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, the average next step error was : loss_epoch\n",
      "Average error over full trajectories: training data : 83.09712215200094\n",
      "Average error over full trajectories: testing data : 241.388544465192\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1814, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:04<00:01,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.1286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(7.1935e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:04<00:01,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, the average next step error was : loss_epoch\n",
      "Average error over full trajectories: training data : 25.996457095409212\n",
      "Average error over full trajectories: testing data : 1.76305492172296\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2146, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:05<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.0213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.3541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(9.1408e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.9671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(1.2857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.2502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.1965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, the average next step error was : loss_epoch\n",
      "Average error over full trajectories: training data : 16.15940949315261\n",
      "Average error over full trajectories: testing data : 0.4868150800437522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FINISHED: Average error over full trajectories: training data : 16.15940949315261\n",
      "TRAINING FINISHED: Average error over full trajectories: testing data : 0.4868150800437522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set some parameters for learning \n",
    "                    #window_size, h_size,  l_num,  epochs, learning_rate,  part_of_data,   weight_decay,   percentage_of_data    future_decay      batch_size\n",
    "parameter_sets  =    [1,             5 ,      1,       10,       5*0.0001,           10,           1e-5,               0.8,               1 ,           8]\n",
    "           # {'lr': 0.0006226762071294569, 'ws': 9, 'bs': 51, 'hs': 13, 'ls': 2}         \n",
    "window_size, h_size, l_num, epochs, learning_rate, part_of_data, weight_decay,  percentage_of_data, future_decay, batch_size = parameter_sets\n",
    "\n",
    "future =4 \n",
    "\n",
    "# Initialize the LSTM model\n",
    "#model = LSTMmodel(input_size=3, hidden_size=h_size, out_size=2, layers=l_num).to(device)\n",
    "model = LSTMmodel(input_size=3, hidden_size=h_size, out_size=2, layers=l_num).to(device)\n",
    "# Generate input data (the data is normalized and some timesteps are cut off)\n",
    "input_data = get_data(path = \"save_data_test3.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = False,\n",
    "                        normalise_s_w=True,\n",
    "                        rescale_p=False,\n",
    "                        num_inits=part_of_data)\n",
    "\n",
    "cut_off_timesteps = 1000\n",
    "print(input_data.size())\n",
    "#Split data into train and test sets\n",
    "\n",
    "num_of_inits_train = int(len(input_data)*percentage_of_data)\n",
    "train_inits = np.random.randint(0,len(input_data), num_of_inits_train)\n",
    "train_inits = np.unique(train_inits)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "\n",
    "# make sure we really get the specified percentage of training data..\n",
    "if percentage_of_data < 0.99: \n",
    "        while len(train_inits) < num_of_inits_train:\n",
    "            i = np.random.randint(0,len(test_inits),1)[0]\n",
    "            train_inits = np.append(train_inits,test_inits[i])\n",
    "            test_inits = np.delete(test_inits, i)\n",
    "\n",
    "train_data = input_data[train_inits,:input_data.size(dim=1)-cut_off_timesteps,:]\n",
    "test_data = input_data[test_inits,:,:]\n",
    "print(train_data.size())\n",
    "\n",
    "data_set  = CustomDataset(train_data, window_size=window_size, future=future)\n",
    "train_dataloader = DataLoader(data_set, batch_size=batch_size, pin_memory=True, drop_last=True)\n",
    "\n",
    "losses = []\n",
    "average_traj_err_train = []\n",
    "average_traj_err_test = []\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    \n",
    "    loss_epoch = train1(train_dataloader, model, weight_decay, future_decay, learning_rate=learning_rate, ws=window_size, future=future)#, timesteps=train_data.size(dim=1), batch_size=batch_size)\n",
    "    losses.append(loss_epoch)\n",
    "\n",
    "    # Every few epochs get the error MSE of the true data\n",
    "    # compared to the network prediction starting from some initial conditions\n",
    "    if (e+1)%2 == 0:\n",
    "        _,_, err_train = test(train_data, model, steps=train_data.size(dim=1), ws=window_size, plot_opt=False, n = 20)\n",
    "        _,_, err_test = test(test_data, model, steps=test_data.size(dim=1), ws=window_size, plot_opt=False, n = 20)\n",
    "        average_traj_err_train.append(err_train)\n",
    "        average_traj_err_test.append(err_test)\n",
    "        print(f\"Epoch: {epochs}, the average next step error was : loss_epoch\")\n",
    "        print(f\"Average error over full trajectories: training data : {err_train}\")\n",
    "        print(f\"Average error over full trajectories: testing data : {err_test}\")\n",
    "\n",
    "_,_, err_train = test(train_data, model, steps=train_data.size(dim=1), ws=window_size, plot_opt=False, n = 100)\n",
    "_,_, err_test = test(test_data, model, steps=test_data.size(dim=1), ws=window_size, plot_opt=False, n = 100)\n",
    "print(f\"TRAINING FINISHED: Average error over full trajectories: training data : {err_train}\")\n",
    "print(f\"TRAINING FINISHED: Average error over full trajectories: testing data : {err_test}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "path = f\"Ventil_trained_NNs\\my_example_model.pth\"\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "# Load the model and test it on the test data\n",
    "\n",
    "path = \"Ventil_trained_NNs\\my_example_model.pth\"\n",
    "model = LSTMmodel(input_size=3, hidden_size=h_size, out_size=2, layers=l_num).to(device)\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "train_data = input_data[train_inits,:,:]\n",
    "\n",
    "test_loss, test_loss_deriv, total_loss = test(test_data, model, steps=input_data.size(dim=1), ws=window_size, plot_opt=True , n = 3)\n",
    "\n",
    "\n",
    "ic(test_loss, test_loss_deriv, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = [\"window_size\", \"batch_size\", \"future\",  \"h_size\",  \"l_num\",  \"epochs\", \"learning_rate\", \"weight_decay\",  \"part_of_data\",  \"percentage_of_data\" ]\n",
    "\n",
    "param_dic = {x : 0 for x in parameter_list}\n",
    "\n",
    "\n",
    "param_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.choice(test_data.size(dim=0), min([n, test_data.size(dim=0)]), replace=False)\n",
    "ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# So you want to train a Neural CDE model?\n",
    "# Let's get started!\n",
    "######################\n",
    "import math\n",
    "import torch\n",
    "import torchcde\n",
    "import math\n",
    "import torch\n",
    "import torchcde\n",
    "from get_data import *\n",
    "from dataloader import *\n",
    "from test_function import *\n",
    "from tqdm import tqdm\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################\n",
    "# A CDE model looks like\n",
    "#\n",
    "# z_t = z_0 + \\int_0^t f_\\theta(z_s) dX_s\n",
    "#\n",
    "#    Where X is your data and f_\\theta is a neural network. So the first thing we need to do is define such an f_\\theta.\n",
    "# That's what this CDEFunc class does.\n",
    "# Here we've built a small single-hidden-layer neural network, whose hidden layer is of width 128.\n",
    "######################\n",
    "class CDEFunc(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, hidden_width=128):\n",
    "        ######################\n",
    "        # input_channels is the number of input channels in the data X. (Determined by the data.)\n",
    "        # hidden_channels is the number of channels for z_t. (Determined by you!)\n",
    "        ######################\n",
    "        super(CDEFunc, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.hidden_width  = hidden_width\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, self.hidden_width)\n",
    "        self.linear2 = torch.nn.Linear(self.hidden_width, input_channels * hidden_channels)\n",
    "\n",
    "    ######################\n",
    "    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n",
    "    # different times, which would be unusual. But it's there if you need it!\n",
    "    ######################\n",
    "    def forward(self, t, z):\n",
    "        # z has shape (batch, hidden_channels)\n",
    "        z = self.linear1(z)\n",
    "        z = z.relu()\n",
    "        z = self.linear2(z)\n",
    "        ######################\n",
    "        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n",
    "        ######################\n",
    "        z = z.tanh()\n",
    "        ######################\n",
    "        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n",
    "        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n",
    "        ######################\n",
    "        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n",
    "        return z\n",
    "\n",
    "\n",
    "# Next, we need to package CDEFunc up into a model that computes the integral.\n",
    "######################\n",
    "class NeuralCDE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, hidden_width, output_channels, interpolation=\"cubic\"):\n",
    "        super(NeuralCDE, self).__init__()\n",
    "\n",
    "        self.func = CDEFunc(input_channels, hidden_channels, hidden_width)\n",
    "        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        if self.interpolation == 'cubic':\n",
    "            X = torchcde.CubicSpline(coeffs)\n",
    "        elif self.interpolation == 'linear':\n",
    "            X = torchcde.LinearInterpolation(coeffs)\n",
    "        else:\n",
    "            raise ValueError(\"Only 'linear' and 'cubic' interpolation methods are implemented.\")\n",
    "\n",
    "        ######################\n",
    "        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n",
    "        ######################\n",
    "        X0 = X.evaluate(X.interval[0])\n",
    "        z0 = self.initial(X0)\n",
    "\n",
    "        ######################\n",
    "        # Actually solve the CDE.\n",
    "        ######################\n",
    "        z_T = torchcde.cdeint(X=X,\n",
    "                              z0=z0,\n",
    "                              func=self.func,\n",
    "                              t=X.interval)\n",
    "\n",
    "        ######################\n",
    "        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n",
    "        # and then apply a linear map.\n",
    "        ######################\n",
    "        z_T = z_T[:, 1]\n",
    "        pred_y = self.readout(z_T)\n",
    "        return pred_y\n",
    "######################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_configs =        [  \n",
    "    \n",
    "                        {\n",
    "                    \"experiment_number\" : 0,\n",
    "                    \"window_size\" : 50,\n",
    "                    \"h_size\" : 8,\n",
    "                    \"h_width\" : 128,\n",
    "                    \"l_num\" : 3,\n",
    "                    \"epochs\" : 80,\n",
    "                    \"learning_rate\" : 0.001,\n",
    "                    \"part_of_data\" : 2, \n",
    "                    \"percentage_of_data\" : 0.8,\n",
    "                    \"batch_size\" : 1000,\n",
    "                    \"cut_off_timesteps\" : 400,\n",
    "                    \"drop_half_timesteps\": True\n",
    "                    }\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "for k, d in enumerate(parameter_configs):\n",
    "    d[\"experiment_number\"] = k\n",
    "\n",
    "for params in parameter_configs:\n",
    "\n",
    "    input_data1, PSW_max = get_data_cde(path = \"data\\save_data_test_revised.csv\", \n",
    "                                timesteps_from_data=0, \n",
    "                                skip_steps_start = 0,\n",
    "                                skip_steps_end = 0, \n",
    "                                drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                                normalise_s_w=\"minmax\",\n",
    "                                rescale_p=False,\n",
    "                                num_inits=params[\"part_of_data\"])\n",
    "    input_data = input_data1\n",
    "    #cols = time_cols, pb_cols, sb_cols, wb_cols\n",
    "\n",
    "        #Split data into train and test sets\n",
    "    np.random.seed(1234)\n",
    "    num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "    train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "    test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "    np.random.shuffle(train_inits)\n",
    "    np.random.shuffle(test_inits)\n",
    "    train_data = input_data[train_inits,:input_data.size(dim=1)-params[\"cut_off_timesteps\"],:]\n",
    "    test_data = input_data[test_inits,:,:]\n",
    "\n",
    "\n",
    "    train_set = CustomDataset_cde(train_data, window_size=params[\"window_size\"])\n",
    "    train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"])  \n",
    "    if device == \"cuda:0\":\n",
    "        train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"], pin_memory=True)  \n",
    "\n",
    "    print(train_data.size(), test_data.size())\n",
    "    ######################\n",
    "    # input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, and time.\n",
    "    # hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n",
    "    # output_channels=1 because we're doing binary classification.\n",
    "    ######################\n",
    "    model = NeuralCDE(input_channels=4, hidden_channels=params[\"h_size\"], hidden_width = params[\"h_width\"], output_channels=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    ######################\n",
    "    # Now we turn our dataset into a continuous path. We do this here via Hermite cubic spline interpolation.\n",
    "    # The resulting `train_coeffs` is a tensor describing the path.\n",
    "    # For most problems, it's probably easiest to save this tensor and treat it as the dataset.\n",
    "    ######################\n",
    "        # train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(train_X)\n",
    "\n",
    "        # train_dataset = torch.utils.data.TensorDataset(train_coeffs, train_y)\n",
    "        # train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "    for epoch in tqdm(range(params[\"epochs\"])):\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "\n",
    "            train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(x)\n",
    "            batch_coeffs, batch_y = train_coeffs.to(device), y.to(device)\n",
    "        \n",
    "            pred_y = model(batch_coeffs).squeeze(-1)\n",
    "            #out = x[:,-1,2:].squeeze(-1)+ pred_y\n",
    "            out = x[:,-1,2:] + pred_y\n",
    "            loss = loss_fn(out, batch_y[:, 2:])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        #print('Epoch: {}   Training loss (next step): {}'.format(epoch, loss.item()))    \n",
    "\n",
    "        if (epoch+1) % 50 == 0:            \n",
    "            test_loss, test_loss_deriv, err_test = test(test_data.to(device), model, model_type = \"neural_cde\", window_size=params[\"window_size\"], \n",
    "                                                    display_plots=False, num_of_inits = 1, set_rand_seed=True, physics_rescaling = PSW_max)\n",
    "            print('Epoch: {}   Test loss (MSE over whole Traj.): {}'.format(epoch, err_test.item()))\n",
    "\n",
    "    path = f'Ventil_trained_NNs\\cde{params[\"experiment_number\"]}.pth'\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Run finished, file saved as: \\n {path}\")\n",
    "\n",
    "    test_loss, test_loss_deriv, err_test = test(test_data.to(device), model, model_type = \"neural_cde\", window_size=params[\"window_size\"], \n",
    "                                                    display_plots=False, num_of_inits = 10, set_rand_seed=True, physics_rescaling = PSW_max)\n",
    "    print(\"Training finised! Final error:\", err_test)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "path = \"Ventil_trained_NNs\\cde83.pth\"\n",
    "\n",
    "paramsliste =        [            {\n",
    "                        \"experiment_number\" : 0,\n",
    "                        \"window_size\" : 50,\n",
    "                        \"h_size\" : 8,\n",
    "                        \"l_num\" : 3,\n",
    "                        \"epochs\" : 80,\n",
    "                        \"learning_rate\" : 0.001,\n",
    "                        \"part_of_data\" : 10, \n",
    "                        \"percentage_of_data\" : 0.8,\n",
    "                        \"batch_size\" : 1000,\n",
    "                        \"cut_off_timesteps\" : 0,\n",
    "                        \"drop_half_timesteps\": True\n",
    "                        }\n",
    "            ]\n",
    "\n",
    "for params in paramsliste:\n",
    "\n",
    "    input_data1, PSW_max = get_data_cde(path = \"data\\save_data_test_revised.csv\", \n",
    "                                timesteps_from_data=0, \n",
    "                                skip_steps_start = 0,\n",
    "                                skip_steps_end = 0, \n",
    "                                drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                                normalise_s_w=\"minmax\",\n",
    "                                rescale_p=False,\n",
    "                                num_inits=params[\"part_of_data\"])\n",
    "    input_data = input_data1\n",
    "    #cols = time_cols, pb_cols, sb_cols, wb_cols\n",
    "\n",
    "        #Split data into train and test sets\n",
    "    np.random.seed(1234)\n",
    "    num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "    train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "    test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "    np.random.shuffle(train_inits)\n",
    "    np.random.shuffle(test_inits)\n",
    "    train_data = input_data[train_inits,:input_data.size(dim=1)-params[\"cut_off_timesteps\"],:]\n",
    "    test_data = input_data[test_inits,:,:]\n",
    "\n",
    "\n",
    "    train_set = CustomDataset_cde(train_data, window_size=params[\"window_size\"])\n",
    "    train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"])  \n",
    "    if device == \"cuda:0\":\n",
    "        train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"], pin_memory=True)  \n",
    "\n",
    "    model = NeuralCDE(input_channels=4, hidden_channels=8, hidden_width = 16, output_channels=2).to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "           \n",
    "    test_loss, test_loss_deriv, err_test = test(train_data.to(device), model, model_type = \"neural_cde\", window_size=params[\"window_size\"], \n",
    "                                                display_plots=True, num_of_inits = 5, set_rand_seed=False, physics_rescaling = PSW_max)\n",
    "    print('Test loss (MSE over whole Traj.): {}'.format(err_test.item()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "path = \"Ventil_trained_NNs\\cde0.pth\"\n",
    "\n",
    "paramsliste =        [            {\n",
    "                        \"experiment_number\" : 0,\n",
    "                        \"window_size\" : 50,\n",
    "                        \"h_size\" : 8,\n",
    "                        \"l_num\" : 3,\n",
    "                        \"epochs\" : 80,\n",
    "                        \"learning_rate\" : 0.001,\n",
    "                        \"part_of_data\" : 10, \n",
    "                        \"percentage_of_data\" : 0.8,\n",
    "                        \"batch_size\" : 1000,\n",
    "                        \"cut_off_timesteps\" : 0,\n",
    "                        \"drop_half_timesteps\": True\n",
    "                        }\n",
    "            ]\n",
    "\n",
    "for params in paramsliste:\n",
    "\n",
    "    input_data1, PSW_max = get_data_cde(path = \"data\\save_data_test_revised.csv\", \n",
    "                                timesteps_from_data=0, \n",
    "                                skip_steps_start = 0,\n",
    "                                skip_steps_end = 0, \n",
    "                                drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                                normalise_s_w=\"minmax\",\n",
    "                                rescale_p=False,\n",
    "                                num_inits=params[\"part_of_data\"])\n",
    "    input_data = input_data1\n",
    "    #cols = time_cols, pb_cols, sb_cols, wb_cols\n",
    "\n",
    "        #Split data into train and test sets\n",
    "    np.random.seed(1234)\n",
    "    num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "    train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "    test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "    np.random.shuffle(train_inits)\n",
    "    np.random.shuffle(test_inits)\n",
    "    train_data = input_data[train_inits,:input_data.size(dim=1)-params[\"cut_off_timesteps\"],:]\n",
    "    test_data = input_data[test_inits,:,:]\n",
    "\n",
    "\n",
    "    train_set = CustomDataset_cde(train_data, window_size=params[\"window_size\"])\n",
    "    train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"])  \n",
    "    if device == \"cuda:0\":\n",
    "        train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"], pin_memory=True)  \n",
    "\n",
    "    model = NeuralCDE(input_channels=4, hidden_channels=8, hidden_width = 128, output_channels=2).to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "           \n",
    "    test_loss, test_loss_deriv, err_test = test(train_data.to(device), model, model_type = \"neural_cde\", window_size=params[\"window_size\"], \n",
    "                                                display_plots=True, num_of_inits = 5, set_rand_seed=False, physics_rescaling = PSW_max)\n",
    "    print('Test loss (MSE over whole Traj.): {}'.format(err_test.item()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

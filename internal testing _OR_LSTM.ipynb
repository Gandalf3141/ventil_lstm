{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "from tqdm import tqdm\n",
    "from get_data import *\n",
    "from dataloader import *\n",
    "from test_function import test\n",
    "from NN_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data generated via matlab/simulink:\n",
    "\n",
    "# see get_data.py for more info\n",
    "\n",
    "#save_data_test_revised.csv\n",
    "\n",
    "data_tensor, PSW_max = get_data(path = r\"data\\save_data_test_5xlonger.csv\", timesteps_from_data=0,\n",
    "                                 skip_steps_start = 0, skip_steps_end = 0, drop_half_timesteps = True, normalise_s_w=\"minmax\", rescale_p=False, num_inits=0)\n",
    "\n",
    "# View an example of a simulation run\n",
    "visualise(data_tensor, num_inits=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class custom_simple_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, window_size):\n",
    "\n",
    "        self.data = data\n",
    "        self.ws = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        inp = self.data[idx, :, :]\n",
    "        label = self.data[idx, self.ws:, 1:]\n",
    "\n",
    "        return inp, label\n",
    "\n",
    "\n",
    "# Use the GPU if available\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device=\"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fr(v):\n",
    "\n",
    "#parBoost_gen.d_b  = 3.2;                    % Dämpfungskonste Booster in [Ns/m]  Update AP: 2021Feb alter Wert 33.184\n",
    "#parBoost_gen.F_c  = 0.5;                      % Coulombreibkraft Booster in [N] Update AP: 2021Feb alter Wert: 1.53;\n",
    "\n",
    "    d = 3.2\n",
    "    F_c  = 0.5\n",
    "\n",
    "    fr = - d * v - F_c * torch.sign(v)\n",
    "\n",
    "\n",
    "    return fr\n",
    "\n",
    "def fk(s,v):\n",
    "\n",
    "# % Paramter Kontaktmodell\n",
    "# % Unterer Anschlag\n",
    "# parBoost_gen.c_bwl = 166e3;          % Federkonstante unterer Anschlag in [N/m]\n",
    "# parBoost_gen.d_bwl = 474;            % Dämpfungskonstante unterer Anschlag in [Ns/m]\n",
    "# parBoost_gen.s_0bwl = 0.3e-4;        % Kontaktpunkt unterer Anschlag in [m] \n",
    "# % Oberer Anschlag\n",
    "# parBoost_gen.c_bwu = 166e3;                         % Federkonstante oberer Anschlag in [N/m]\n",
    "# parBoost_gen.d_bwu = 474;                           % Dämpfungskonstante oberer Anschlag in [Ns/m]\n",
    "# parBoost_gen.s_0bwu = parBoost_gen.s_b_max - 0.12e-4;     % Kontaktpunkt oberer Anschlag in [m]\n",
    "#parBoost_gen.s_b_max = 0.6e-3;                                      % Maximaler Hub in [m]\n",
    "\n",
    "    s_u =  0.6e-3 - 0.12e-4\n",
    "    c_u = 166e3\n",
    "    d_u = 474\n",
    "\n",
    "    c_l = 166e3\n",
    "    s_l =  0.3e-4\n",
    "    d_l = 474\n",
    "\n",
    "\n",
    "    if s_u <= s:\n",
    "        \n",
    "        fk = -c_u * (s - s_u) - d_u * v * (s - s_u)\n",
    "\n",
    "    elif s <= s_l:\n",
    "\n",
    "        fk = c_l * (s - s_l) - d_l * v * (s - s_l)\n",
    "\n",
    "    else:\n",
    "        fk = 0\n",
    "\n",
    "    return fk\n",
    "\n",
    "def ODE_right_side(x, pressure, physics_rescaling=None):\n",
    "\n",
    "    #rescale to physical units\n",
    "\n",
    "   # x[:, :,0] = x[:, :,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "   # x[:, :,1] = x[:, :,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "   # pressure[:, :,0] = pressure[:, :,0]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    x_dt = torch.zeros_like(x[:,:,0:1]) # write s' = v (v from real data)  \n",
    "    #          v'  = 1/m ( A * ( p - p0) - c * (s - s0) + fr(v) + fk(s,v) )  \n",
    "\n",
    "    # andere Formulierung: fs = -(c_b*s_b - F_cb0) statt -c_b *(s_b - s_0b);\n",
    "\n",
    "    #          v'  = 1/m ( A * ( p - p0) - (c_b*s_b - F_cb0) + fr(v) + fk(s,v) )  \n",
    "\n",
    "\n",
    "    m = 1.8931e-3                         # 1.8931e-3;              % Masse Booster in [kg]\n",
    "    A = 0.5*(71.0526e-6 + 78.9793e-6 )  # 0.5*(parBoost_gen.A_b_closed + parBoost_gen.A_b_open);   % Mittlere Fläche Booster in [m²]                                \n",
    "                                            # % Anfangswerte der Boostereinheit\n",
    "    p0 = 1e5                                # parBoost_gen.s_b_0 = 3e-4;\n",
    "    s0 = 3e-4                               # parBoost_gen.p_b_0 = 1e5;\n",
    "    c = 16.5e3                              # parBoost_gen.c_b  = 16.5e3;                 % Federkonstante Booster in [N/m]\n",
    "    F_cb0 = -4.3                            #parBoost_gen.F_cb0 = -4.3;                    % Federvorspannkraft (Kraft der Feder bei sb=0) [N]\n",
    "\n",
    "\n",
    "    for i in range(x_dt.size(dim=0)):\n",
    "        for time in range(x_dt.size(dim=1)):\n",
    "\n",
    "            p = pressure[i, time, 0] * (physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "            s =  x[i, time, 0] * (physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "            v = x[i, time, 1] * (physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "\n",
    "            x_dt[i, time, 0:1] =  1/m * ( A * ( p - p0) - (c * s - F_cb0) + fr(v) + fk(s,v) ) \n",
    "\n",
    "    return x_dt\n",
    "\n",
    "def train(input_data, model, weight_decay, learning_rate=0.001, ws=0, PSW_max=0, physics_loss_weight = 0.0001):\n",
    " \n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    " \n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    total_physics_loss = []\n",
    "\n",
    "    # s' = v\n",
    "    # v' = f(s,v,p)\n",
    "    # \n",
    "    # (s,v) = model return (we can also return the derivatives calculated by the model!)\n",
    "    #\n",
    "    # (s,v), (s', v') = model (return are vectors len = timesteps modulo init values)\n",
    "    #  \n",
    "    #  physic_error = 1/len * sum( mse ( (s', v') - (v, f(s,v,p))  ))\n",
    "    #\n",
    "    #  def f(s,v, p) from matlab (bad with normalisation!!!)\n",
    "    #\n",
    "\n",
    "    for k, (x,y) in enumerate(input_data):  # inp = (u, x) label = x\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output, _, derivative_sv = model(x)\n",
    "\n",
    "        # reset the gradient\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # calculate the error\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        # calc physics loss\n",
    "        physics_loss=0\n",
    "        if physics_loss_weight != 0:\n",
    "        \n",
    "         pressure = x[:, ws:, 0:1] # Anfangswerte sind abgeschnitten weil len(output) == len(x) - windowsize \n",
    "         assert pressure.size(dim=1) == output.size(dim=1)\n",
    "         physics_loss = physics_loss_weight * loss_fn(ODE_right_side(output, pressure, PSW_max), ODE_right_side(y, pressure, PSW_max))\n",
    "         \n",
    "        losses = loss + physics_loss\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        total_loss.append(loss.detach().cpu().numpy())\n",
    "        total_physics_loss.append(physics_loss.detach().cpu().numpy())\n",
    "   # return the average error of the next step prediction\n",
    "\n",
    "   \n",
    "    return np.mean(total_loss), np.mean(total_physics_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params =           {\n",
    "                           \"experiment_number\" : 2,\n",
    "                           \"window_size\" : 16,\n",
    "                           \"h_size\" : 8,\n",
    "                           \"l_num\" : 1,\n",
    "                           \"epochs\" : 100,\n",
    "                           \"learning_rate\" : 0.001,\n",
    "                           \"part_of_data\" : 50, \n",
    "                           \"weight_decay\" : 1e-5,\n",
    "                           \"percentage_of_data\" : 0.3,\n",
    "                           \"future_decay\"  : 0.5,\n",
    "                           \"batch_size\" : 2,\n",
    "                           \"future\" : 10,\n",
    "                           \"cut_off_timesteps\" : 300,\n",
    "                           \"drop_half_timesteps\": True,\n",
    "                           \"physics_loss_weight\" : 0.001\n",
    "                        }\n",
    "\n",
    "# Initialize the LSTM model\n",
    "model = LSTMmodel(input_size=3, hidden_size=params[\"h_size\"], out_size=2, layers=params[\"l_num\"], window_size=params[\"window_size\"], rungekutta=False).to(device)\n",
    "# Generate input data (the data is normalized and some timesteps are cut off)\n",
    "input_data1, PSW_max = get_data(path = \"data\\save_data_test_5xlonger.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "\n",
    "# input_data2, PSW_max = get_data(path = \"save_data_test5.csv\", \n",
    "#                         timesteps_from_data=0, \n",
    "#                         skip_steps_start = 0,\n",
    "#                         skip_steps_end = 0, \n",
    "#                         drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "#                         normalise_s_w=\"minmax\",\n",
    "#                         rescale_p=False,\n",
    "#                         num_inits=params[\"part_of_data\"])\n",
    "\n",
    "# input_data3, PSW_max = get_data(path = \"Testruns_from_trajectory_generator_t2_t6_revised.csv\", \n",
    "#                         timesteps_from_data=0, \n",
    "#                         skip_steps_start = 0,\n",
    "#                         skip_steps_end = 0, \n",
    "#                         drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "#                         normalise_s_w=\"minmax\",\n",
    "#                         rescale_p=False,\n",
    "#                         num_inits=params[\"part_of_data\"])\n",
    "\n",
    "input_data = input_data1#torch.cat((input_data1, input_data2, input_data3))\n",
    "print(input_data.size())\n",
    "\n",
    "#Split data into train and test sets\n",
    "np.random.seed(1234)\n",
    "num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "np.random.shuffle(train_inits)\n",
    "np.random.shuffle(test_inits)\n",
    "train_data = input_data[train_inits,:input_data.size(dim=1)-params[\"cut_off_timesteps\"],:]\n",
    "test_data = input_data[test_inits,:,:]\n",
    "\n",
    "# dataloader for batching during training\n",
    "train_set = custom_simple_dataset(train_data, window_size=params[\"window_size\"])\n",
    "train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"], pin_memory=True)\n",
    "\n",
    "losses = []\n",
    "average_traj_err_train = []\n",
    "average_traj_err_test = []\n",
    "\n",
    "for e in tqdm(range(params[\"epochs\"])):\n",
    "    \n",
    "    loss_epoch, loss_physics = train(train_loader, model, params[\"weight_decay\"], learning_rate= params[\"learning_rate\"],\n",
    "                        ws=params[\"window_size\"], PSW_max = PSW_max, physics_loss_weight=params[\"physics_loss_weight\"])\n",
    "    losses.append(loss_epoch)\n",
    "\n",
    "    # Every few epochs get the error MSE of the true data\n",
    "    # compared to the network prediction starting from some initial conditions\n",
    "    if (e+1)%2 == 0:    \n",
    "\n",
    "        print(\"Train loss:\", loss_epoch)\n",
    "        print(\"physics loss:\", loss_physics)\n",
    "\n",
    "        _,_, err_train = test(input_data, model, model_type = \"or_lstm\", window_size=params[\"window_size\"], display_plots=False,\n",
    "                               num_of_inits = 20, set_rand_seed=True, physics_rescaling = PSW_max)\n",
    "\n",
    "        average_traj_err_train.append(err_train)\n",
    "        #average_traj_err_test.append(err_test)\n",
    "        print(f\"Epoch: {e}, the average next step error was : loss_epoch\")\n",
    "        print(f\"Average error over full trajectories: training data : {err_train}\")\n",
    "                #print(f\"Average error over full trajectories: testing data : {err_test}\")\n",
    "\n",
    "_,_, err_test = test(input_data, model, model_type = \"or_lstm\", window_size=params[\"window_size\"], display_plots=False, num_of_inits = 1, set_rand_seed=True, physics_rescaling = PSW_max)\n",
    "#_,_, err_test = test(test_data, model, steps=test_data.size(dim=1), ws=window_size, plot_opt=False, n = 100)\n",
    "print(f\"TRAINING FINISHED: Average error over full trajectories: testing data : {err_test}\")\n",
    "#print(f\"TRAINING FINISHED: Average error over full trajectories: testing data : {err_test}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# path = f\"Ventil_trained_NNs\\lstm_ws0.pth\"\n",
    "# #\n",
    "# torch.save(model.state_dict(), path)\n",
    "\n",
    "# Load the model and test it on the test data\n",
    "path = \"working_networks\\OR_lstm_16_8_3_best_V2.pth\"\n",
    "\n",
    "params =                 {\n",
    "                           \"experiment_number\" : 2,\n",
    "                           \"window_size\" : 16,\n",
    "                           \"h_size\" : 8,\n",
    "                           \"l_num\" : 3,\n",
    "                           \"epochs\" : 3000,\n",
    "                           \"learning_rate\" : 0.0008,\n",
    "                           \"part_of_data\" : 0, \n",
    "                           \"weight_decay\" : 0,\n",
    "                           \"percentage_of_data\" : 0.8,\n",
    "                           \"future_decay\"  : 0.5,\n",
    "                           \"batch_size\" : 20,\n",
    "                           \"future\" : 10,\n",
    "                           \"cut_off_timesteps\" : 0,\n",
    "                           \"drop_half_timesteps\": True\n",
    "                        }\n",
    "\n",
    "\n",
    "\n",
    "input_data1, PSW_max = get_data(path = \"data\\save_data_test_5xlonger.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "\n",
    "input_data2, PSW_max = get_data(path = \"data\\save_data_test5.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "\n",
    "input_data3, PSW_max = get_data(path = \"data\\Testruns_from_trajectory_generator_t2_t6_revised.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "                        \n",
    "\n",
    "#input_data = torch.cat((input_data1, input_data2, input_data3))\n",
    "input_data=input_data1\n",
    "np.random.seed(1234)\n",
    "print(\"input_data size\", input_data.size())\n",
    "num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "np.random.shuffle(train_inits)\n",
    "np.random.shuffle(test_inits)\n",
    "test_data = input_data[test_inits,:,:]\n",
    "np.random.seed()\n",
    "\n",
    "# Initialize the LSTM model\n",
    "\n",
    "model = LSTMmodel(input_size=3, hidden_size=params[\"h_size\"], out_size=2, layers=params[\"l_num\"], window_size=params[\"window_size\"], stepsize=1, rungekutta=False)\n",
    "\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "train_data = input_data[train_inits,:,:]\n",
    "#%matplotlib qt \n",
    "#%matplotlib inline \n",
    "\n",
    "#test_loss, test_loss_deriv, total_loss, physloss\n",
    "test_loss, test_loss_deriv, total_loss = test(test_data, model, model_type = \"or_lstm\", window_size=params[\"window_size\"],\n",
    "                                                         display_plots=True, num_of_inits = 3, set_rand_seed=False, physics_rescaling = PSW_max, additional_data=None)\n",
    "#test_loss, test_loss_deriv, total_loss = test(train_data, model, steps=input_data.size(dim=1), ws=params[\"window_size\"], plot_opt=True , n = 1,  test_inits=len(test_data), rand=False, PSW_max=0)\n",
    "\n",
    "#[350000.0, 0.0006, 1.7, 0.0, 0.0, -1.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# path = f\"Ventil_trained_NNs\\lstm_ws0.pth\"\n",
    "# #\n",
    "# torch.save(model.state_dict(), path)\n",
    " \n",
    "# Load the model and test it on the test data\n",
    "path = \"working_networks\\OR_lstm_16_8_3_best_V2.pth\"\n",
    " \n",
    "params =                 {\n",
    "                           \"experiment_number\" : 2,\n",
    "                           \"window_size\" : 16,\n",
    "                           \"h_size\" : 8,\n",
    "                           \"l_num\" : 3,\n",
    "                           \"epochs\" : 3000,\n",
    "                           \"learning_rate\" : 0.0008,\n",
    "                           \"part_of_data\" : 0,\n",
    "                           \"weight_decay\" : 0,\n",
    "                           \"percentage_of_data\" : 0.8,\n",
    "                           \"future_decay\"  : 0.5,\n",
    "                           \"batch_size\" : 20,\n",
    "                           \"future\" : 10,\n",
    "                           \"cut_off_timesteps\" : 0,\n",
    "                           \"drop_half_timesteps\": True\n",
    "                        }\n",
    " \n",
    " \n",
    " \n",
    "input_data1, PSW_max = get_data(path = \"data\\save_data_test_5xlonger.csv\",\n",
    "                        timesteps_from_data=0,\n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0,\n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    " \n",
    "input_data2, PSW_max = get_data(path = \"data\\save_data_test5.csv\",\n",
    "                        timesteps_from_data=0,\n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0,\n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    " \n",
    "input_data3, PSW_max = get_data(path = \"data\\Testruns_from_trajectory_generator_t2_t6_revised.csv\",\n",
    "                        timesteps_from_data=0,\n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0,\n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "                       \n",
    " \n",
    "#input_data = torch.cat((input_data1, input_data2, input_data3))\n",
    "input_data = input_data1\n",
    "\n",
    " \n",
    "np.random.seed(1234)\n",
    "print(\"input_data size\", input_data.size())\n",
    "num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "np.random.shuffle(train_inits)\n",
    "np.random.shuffle(test_inits)\n",
    "test_data = input_data[test_inits,:,:]\n",
    "np.random.seed()\n",
    " \n",
    "# Initialize the LSTM model\n",
    " \n",
    "model = LSTMmodel(input_size=3, hidden_size=params[\"h_size\"], out_size=2, layers=params[\"l_num\"], window_size=params[\"window_size\"], stepsize=1, rungekutta=False)\n",
    " \n",
    "model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    " \n",
    "train_data = input_data[train_inits,:,:]\n",
    "#%matplotlib qt\n",
    "#%matplotlib inline\n",
    " \n",
    "#test_loss, test_loss_deriv, total_loss, physloss\n",
    "test_loss, test_loss_deriv, total_loss = test(test_data, model, model_type = \"or_lstm\", window_size=params[\"window_size\"],\n",
    "                                                         display_plots=True, num_of_inits = 5, set_rand_seed=False, physics_rescaling = PSW_max, additional_data=None)\n",
    "#test_loss, test_loss_deriv, total_loss = test(train_data, model, steps=input_data.size(dim=1), ws=params[\"window_size\"], plot_opt=True , n = 1,  test_inits=len(test_data), rand=False, PSW_max=0)\n",
    " \n",
    "#[350000.0, 0.0006, 1.7, 0.0, 0.0, -1.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

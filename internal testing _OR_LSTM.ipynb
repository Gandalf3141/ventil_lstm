{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "from tqdm import tqdm\n",
    "from get_data import *\n",
    "from dataloader import *\n",
    "from test_function import test\n",
    "from NN_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data generated via matlab/simulink:\n",
    "\n",
    "# see get_data.py for more info\n",
    "\n",
    "#save_data_test_revised.csv\n",
    "\n",
    "data_tensor, PSW_max = get_data(path = r\"data\\testrun_festodaten.csv\", timesteps_from_data=0,\n",
    "                                 skip_steps_start = 0, skip_steps_end = 0, drop_half_timesteps = True, normalise_s_w=False, rescale_p=False, num_inits=0)\n",
    "\n",
    "# View an example of a simulation run\n",
    "visualise(data_tensor, num_inits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class custom_simple_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, window_size):\n",
    "\n",
    "        self.data = data\n",
    "        self.ws = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        inp = self.data[idx, :, :]\n",
    "        label = self.data[idx, self.ws:, 1:]\n",
    "\n",
    "        return inp, label\n",
    "\n",
    "\n",
    "# Use the GPU if available\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device=\"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fr(v):\n",
    "\n",
    "#parBoost_gen.d_b  = 3.2;                    % Dämpfungskonste Booster in [Ns/m]  Update AP: 2021Feb alter Wert 33.184\n",
    "#parBoost_gen.F_c  = 0.5;                      % Coulombreibkraft Booster in [N] Update AP: 2021Feb alter Wert: 1.53;\n",
    "\n",
    "    d = 3.2\n",
    "    F_c  = 0.5\n",
    "\n",
    "    fr = - d * v - F_c * torch.sign(v)\n",
    "\n",
    "\n",
    "    return fr\n",
    "\n",
    "def fk(s,v):\n",
    "\n",
    "# % Paramter Kontaktmodell\n",
    "# % Unterer Anschlag\n",
    "# parBoost_gen.c_bwl = 166e3;          % Federkonstante unterer Anschlag in [N/m]\n",
    "# parBoost_gen.d_bwl = 474;            % Dämpfungskonstante unterer Anschlag in [Ns/m]\n",
    "# parBoost_gen.s_0bwl = 0.3e-4;        % Kontaktpunkt unterer Anschlag in [m] \n",
    "# % Oberer Anschlag\n",
    "# parBoost_gen.c_bwu = 166e3;                         % Federkonstante oberer Anschlag in [N/m]\n",
    "# parBoost_gen.d_bwu = 474;                           % Dämpfungskonstante oberer Anschlag in [Ns/m]\n",
    "# parBoost_gen.s_0bwu = parBoost_gen.s_b_max - 0.12e-4;     % Kontaktpunkt oberer Anschlag in [m]\n",
    "#parBoost_gen.s_b_max = 0.6e-3;                                      % Maximaler Hub in [m]\n",
    "\n",
    "    s_u =  0.6e-3 - 0.12e-4\n",
    "    c_u = 166e3\n",
    "    d_u = 474\n",
    "\n",
    "    c_l = 166e3\n",
    "    s_l =  0.3e-4\n",
    "    d_l = 474\n",
    "\n",
    "\n",
    "    if s_u <= s:\n",
    "        \n",
    "        fk = -c_u * (s - s_u) - d_u * v * (s - s_u)\n",
    "\n",
    "    elif s <= s_l:\n",
    "\n",
    "        fk = c_l * (s - s_l) - d_l * v * (s - s_l)\n",
    "\n",
    "    else:\n",
    "        fk = 0\n",
    "\n",
    "    return fk\n",
    "\n",
    "def ODE_right_side(x, pressure, physics_rescaling=None):\n",
    "\n",
    "    #rescale to physical units\n",
    "\n",
    "   # x[:, :,0] = x[:, :,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "   # x[:, :,1] = x[:, :,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "   # pressure[:, :,0] = pressure[:, :,0]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    x_dt = torch.zeros_like(x[:,:,0:1]) # write s' = v (v from real data)  \n",
    "    #          v'  = 1/m ( A * ( p - p0) - c * (s - s0) + fr(v) + fk(s,v) )  \n",
    "\n",
    "    # andere Formulierung: fs = -(c_b*s_b - F_cb0) statt -c_b *(s_b - s_0b);\n",
    "\n",
    "    #          v'  = 1/m ( A * ( p - p0) - (c_b*s_b - F_cb0) + fr(v) + fk(s,v) )  \n",
    "\n",
    "\n",
    "    m = 1.8931e-3                         # 1.8931e-3;              % Masse Booster in [kg]\n",
    "    A = 0.5*(71.0526e-6 + 78.9793e-6 )  # 0.5*(parBoost_gen.A_b_closed + parBoost_gen.A_b_open);   % Mittlere Fläche Booster in [m²]                                \n",
    "                                            # % Anfangswerte der Boostereinheit\n",
    "    p0 = 1e5                                # parBoost_gen.s_b_0 = 3e-4;\n",
    "    s0 = 3e-4                               # parBoost_gen.p_b_0 = 1e5;\n",
    "    c = 16.5e3                              # parBoost_gen.c_b  = 16.5e3;                 % Federkonstante Booster in [N/m]\n",
    "    F_cb0 = -4.3                            #parBoost_gen.F_cb0 = -4.3;                    % Federvorspannkraft (Kraft der Feder bei sb=0) [N]\n",
    "\n",
    "\n",
    "    for i in range(x_dt.size(dim=0)):\n",
    "        for time in range(x_dt.size(dim=1)):\n",
    "\n",
    "            p = pressure[i, time, 0] * (physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "            s =  x[i, time, 0] * (physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "            v = x[i, time, 1] * (physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "\n",
    "            x_dt[i, time, 0:1] =  1/m * ( A * ( p - p0) - (c * s - F_cb0) + fr(v) + fk(s,v) ) \n",
    "\n",
    "    return x_dt\n",
    "\n",
    "def train(input_data, model, weight_decay, learning_rate=0.001, ws=0, PSW_max=0, physics_loss_weight = 0.0001):\n",
    " \n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    " \n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    total_physics_loss = []\n",
    "\n",
    "    # s' = v\n",
    "    # v' = f(s,v,p)\n",
    "    # \n",
    "    # (s,v) = model return (we can also return the derivatives calculated by the model!)\n",
    "    #\n",
    "    # (s,v), (s', v') = model (return are vectors len = timesteps modulo init values)\n",
    "    #  \n",
    "    #  physic_error = 1/len * sum( mse ( (s', v') - (v, f(s,v,p))  ))\n",
    "    #\n",
    "    #  def f(s,v, p) from matlab (bad with normalisation!!!)\n",
    "    #\n",
    "\n",
    "    for k, (x,y) in enumerate(input_data):  # inp = (u, x) label = x\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output, _, derivative_sv = model(x)\n",
    "\n",
    "        # reset the gradient\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # calculate the error\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        # calc physics loss\n",
    "        physics_loss=0\n",
    "        if physics_loss_weight != 0:\n",
    "        \n",
    "         pressure = x[:, ws:, 0:1] # Anfangswerte sind abgeschnitten weil len(output) == len(x) - windowsize \n",
    "         assert pressure.size(dim=1) == output.size(dim=1)\n",
    "         physics_loss = physics_loss_weight * loss_fn(ODE_right_side(output, pressure, PSW_max), ODE_right_side(y, pressure, PSW_max))\n",
    "         \n",
    "        losses = loss + physics_loss\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        total_loss.append(loss.detach().cpu().numpy())\n",
    "        total_physics_loss.append(physics_loss.detach().cpu().numpy())\n",
    "   # return the average error of the next step prediction\n",
    "\n",
    "   \n",
    "    return np.mean(total_loss), np.mean(total_physics_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params =           {\n",
    "                           \"experiment_number\" : 2,\n",
    "                           \"window_size\" : 16,\n",
    "                           \"h_size\" : 8,\n",
    "                           \"l_num\" : 1,\n",
    "                           \"epochs\" : 100,\n",
    "                           \"learning_rate\" : 0.001,\n",
    "                           \"part_of_data\" : 50, \n",
    "                           \"weight_decay\" : 1e-5,\n",
    "                           \"percentage_of_data\" : 0.3,\n",
    "                           \"future_decay\"  : 0.5,\n",
    "                           \"batch_size\" : 2,\n",
    "                           \"future\" : 10,\n",
    "                           \"cut_off_timesteps\" : 300,\n",
    "                           \"drop_half_timesteps\": True,\n",
    "                           \"physics_loss_weight\" : 0.001\n",
    "                        }\n",
    "\n",
    "# Initialize the LSTM model\n",
    "model = LSTMmodel(input_size=3, hidden_size=params[\"h_size\"], out_size=2, layers=params[\"l_num\"], window_size=params[\"window_size\"], rungekutta=False).to(device)\n",
    "# Generate input data (the data is normalized and some timesteps are cut off)\n",
    "input_data1, PSW_max = get_data(path = \"data\\save_data_test_revised.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "\n",
    "# input_data2, PSW_max = get_data(path = \"save_data_test5.csv\", \n",
    "#                         timesteps_from_data=0, \n",
    "#                         skip_steps_start = 0,\n",
    "#                         skip_steps_end = 0, \n",
    "#                         drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "#                         normalise_s_w=\"minmax\",\n",
    "#                         rescale_p=False,\n",
    "#                         num_inits=params[\"part_of_data\"])\n",
    "\n",
    "# input_data3, PSW_max = get_data(path = \"Testruns_from_trajectory_generator_t2_t6_revised.csv\", \n",
    "#                         timesteps_from_data=0, \n",
    "#                         skip_steps_start = 0,\n",
    "#                         skip_steps_end = 0, \n",
    "#                         drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "#                         normalise_s_w=\"minmax\",\n",
    "#                         rescale_p=False,\n",
    "#                         num_inits=params[\"part_of_data\"])\n",
    "\n",
    "input_data = input_data1#torch.cat((input_data1, input_data2, input_data3))\n",
    "print(input_data.size())\n",
    "\n",
    "#Split data into train and test sets\n",
    "np.random.seed(1234)\n",
    "num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "np.random.shuffle(train_inits)\n",
    "np.random.shuffle(test_inits)\n",
    "train_data = input_data[train_inits,:input_data.size(dim=1)-params[\"cut_off_timesteps\"],:]\n",
    "test_data = input_data[test_inits,:,:]\n",
    "\n",
    "# dataloader for batching during training\n",
    "train_set = custom_simple_dataset(train_data, window_size=params[\"window_size\"])\n",
    "train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"], pin_memory=True)\n",
    "\n",
    "losses = []\n",
    "average_traj_err_train = []\n",
    "average_traj_err_test = []\n",
    "\n",
    "for e in tqdm(range(params[\"epochs\"])):\n",
    "    \n",
    "    loss_epoch, loss_physics = train(train_loader, model, params[\"weight_decay\"], learning_rate= params[\"learning_rate\"],\n",
    "                        ws=params[\"window_size\"], PSW_max = PSW_max, physics_loss_weight=params[\"physics_loss_weight\"])\n",
    "    losses.append(loss_epoch)\n",
    "\n",
    "    # Every few epochs get the error MSE of the true data\n",
    "    # compared to the network prediction starting from some initial conditions\n",
    "    if (e+1)%2 == 0:    \n",
    "\n",
    "        print(\"Train loss:\", loss_epoch)\n",
    "        print(\"physics loss:\", loss_physics)\n",
    "\n",
    "        _,_, err_train = test(input_data, model, model_type = \"or_lstm\", window_size=params[\"window_size\"], display_plots=False,\n",
    "                               num_of_inits = 20, set_rand_seed=True, physics_rescaling = PSW_max)\n",
    "\n",
    "        average_traj_err_train.append(err_train)\n",
    "        #average_traj_err_test.append(err_test)\n",
    "        print(f\"Epoch: {e}, the average next step error was : loss_epoch\")\n",
    "        print(f\"Average error over full trajectories: training data : {err_train}\")\n",
    "                #print(f\"Average error over full trajectories: testing data : {err_test}\")\n",
    "\n",
    "_,_, err_test = test(input_data, model, model_type = \"or_lstm\", window_size=params[\"window_size\"], display_plots=False, num_of_inits = 100, set_rand_seed=True, physics_rescaling = PSW_max)\n",
    "#_,_, err_test = test(test_data, model, steps=test_data.size(dim=1), ws=window_size, plot_opt=False, n = 100)\n",
    "print(f\"TRAINING FINISHED: Average error over full trajectories: testing data : {err_test}\")\n",
    "#print(f\"TRAINING FINISHED: Average error over full trajectories: testing data : {err_test}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# path = f\"Ventil_trained_NNs\\lstm_ws0.pth\"\n",
    "# #\n",
    "# torch.save(model.state_dict(), path)\n",
    "\n",
    "# Load the model and test it on the test data\n",
    "path = \"working_networks\\OR_lstm_16_8_3_best_V2.pth\"\n",
    "\n",
    "params =                  {\n",
    "                                \"experiment_number\" : 2,\n",
    "                                \"window_size\" : 16,\n",
    "                                \"h_size\" : 8,\n",
    "                                \"l_num\" : 3,\n",
    "                                \"part_of_data\" : 100, \n",
    "                                \"percentage_of_data\" : 0.8,\n",
    "                                \"future_decay\"  : 0.5,\n",
    "                                \"batch_size\" : 20,\n",
    "                                \"future\" : 10,\n",
    "                                \"cut_off_timesteps\" : 0,\n",
    "                                \"drop_half_timesteps\": True,\n",
    "                                \"physics_loss_weight\" : 1e-10\n",
    "                                }\n",
    "\n",
    "\n",
    "input_data1, PSW_max = get_data(path = r\"data\\testrun_festodaten.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "\n",
    "input_data2, PSW_max = get_data(path = \"data\\save_data_test5.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "\n",
    "input_data3, PSW_max = get_data(path = \"data\\Testruns_from_trajectory_generator_t2_t6_revised.csv\", \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params[\"part_of_data\"])\n",
    "                        \n",
    "\n",
    "#input_data = torch.cat((input_data1, input_data2, input_data3))\n",
    "input_data = input_data1[2:,1:,:]\n",
    "additional_data = input_data1[0:2,1:,:]\n",
    "#np.random.seed(1234)\n",
    "\n",
    "print(\"input_data size\", input_data.size())\n",
    "num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "np.random.shuffle(train_inits)\n",
    "np.random.shuffle(test_inits)\n",
    "test_data = input_data[test_inits,:,:]\n",
    "\n",
    "# Initialize the LSTM model\n",
    "\n",
    "model = LSTMmodel(input_size=3, hidden_size=params[\"h_size\"], out_size=2, layers=params[\"l_num\"], window_size=params[\"window_size\"], stepsize=1, rungekutta=False)\n",
    "\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "train_data = input_data[train_inits,:,:]\n",
    "#%matplotlib qt \n",
    "#%matplotlib inline #\n",
    "\n",
    "#test_loss, test_loss_deriv, total_loss, physloss\n",
    "test_loss, test_loss_deriv, total_loss = test(input_data, model, model_type = \"or_lstm\", window_size=params[\"window_size\"],\n",
    "                                                         display_plots=True, num_of_inits = 1, set_rand_seed=True, physics_rescaling = PSW_max, additional_data=additional_data)\n",
    "#test_loss, test_loss_deriv, total_loss = test(train_data, model, steps=input_data.size(dim=1), ws=params[\"window_size\"], plot_opt=True , n = 1,  test_inits=len(test_data), rand=False, PSW_max=0)\n",
    "\n",
    "#[350000.0, 0.0006, 1.7, 0.0, 0.0, -1.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fr(v):\n",
    "\n",
    "    d = 3.2\n",
    "    F_c  = 0.5\n",
    "    #fr = - d * v - F_c * np.sign(v)\n",
    "    fr = - d * v - F_c * np.tanh(v/0.1)\n",
    "\n",
    "    return fr\n",
    "\n",
    "def fk(s,v):\n",
    "\n",
    "    s_u =  0.6e-3 - 0.12e-4\n",
    "    c_u = 166e3\n",
    "    d_u = 474\n",
    "    c_l = 166e3\n",
    "    s_l =  0.3e-4\n",
    "    d_l = 474\n",
    "\n",
    "    fk = 0\n",
    "\n",
    "    if s_u <= s:\n",
    "        \n",
    "        fk = -c_u * (s - s_u) - d_u * v * (s - s_u)\n",
    "\n",
    "    elif s <= s_l:\n",
    "\n",
    "        fk = c_l * (s - s_l) - d_l * v * (s - s_l)\n",
    "\n",
    "    return fk\n",
    "\n",
    "\n",
    "def plot_results(x, pred, pred_next_step=None, physics_rescaling=None):\n",
    "\n",
    "\n",
    "    if x.dim() == 3:\n",
    "        x = x.view(x.size(dim=1), x.size(dim=2))\n",
    "    if pred.dim() == 3:\n",
    "        pred = pred.view(pred.size(dim=1), pred.size(dim=2))\n",
    "    if pred_next_step != None:\n",
    "        if pred_next_step.dim() == 3:\n",
    "            pred_next_step = pred_next_step.view(pred_next_step.size(dim=1), pred_next_step.size(dim=2))\n",
    "\n",
    "        #scale back:    \n",
    "    if physics_rescaling != None:\n",
    "\n",
    "        # we invert:\n",
    "        # x = (x - xmin)/(xmax - xmin)\n",
    "        # x * (xmax - xmin) + xmin\n",
    "\n",
    "        pred[:,0] = pred[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "       # pred[:,0] = pred[:,0]/1e5\n",
    "        pred[:,1] = pred[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        pred[:,2] = pred[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "        x[:,0] = x[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "       # x[:,0] = x[:,0]/1e5\n",
    "        x[:,1] = x[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        x[:,2] = x[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    figure , axs = plt.subplots(1,3,figsize=(20,9))\n",
    "\n",
    "\n",
    "    axs[0].plot(pred.detach().cpu().numpy()[:, 1], color=\"red\", label=\"pred\")\n",
    "    axs[0].plot(x.detach().cpu().numpy()[:, 1], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    axs[0].set_title(\"position\")\n",
    "    axs[0].set_ylabel(\"[m]\")\n",
    "    axs[0].set_xlabel(\"time\")\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()\n",
    "\n",
    "\n",
    "    axs[1].plot(pred.detach().cpu().numpy()[:, 2], color=\"red\", label=\"pred\")\n",
    "    axs[1].plot(x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    axs[1].set_title(\"speed\")\n",
    "    axs[1].set_ylabel(\"[m/s]\")\n",
    "    axs[1].set_xlabel(\"time\")\n",
    "    axs[1].grid()\n",
    "    axs[1].legend()\n",
    "\n",
    "    axs[2].plot(x.detach().cpu().numpy()[:,0], label=\"pressure\")\n",
    "    axs[2].set_title(\"pressure\")\n",
    "    axs[2].set_ylabel(\"[Pascal]\")\n",
    "    axs[2].set_xlabel(\"time\")\n",
    "    axs[2].grid()\n",
    "    axs[2].legend()\n",
    "\n",
    "\n",
    "    if pred_next_step != None:\n",
    "        axs[0].plot(pred_next_step.detach().cpu().numpy()[:, 1], color=\"green\", label=\"next step from data\")\n",
    "        axs[1].plot(pred_next_step.detach().cpu().numpy()[:, 2], color=\"green\", label=\"next step from data\")\n",
    "\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def test(data, model, model_type = \"or_lstm\", window_size=10, display_plots=False, num_of_inits = 5, set_rand_seed=True, physics_rescaling = 0):\n",
    "\n",
    "    if model_type not in [\"or_lstm\", \"lstm\", \"mlp\", \"gru\", \"tcm\"]:\n",
    "        print(\"Error: model_type = \", model_type, \"available options are: [or_lstm, lstm, mlp, gru, tcm]\")\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    device = \"cpu\" if data.get_device() == -1 else \"cuda:0\"\n",
    "    \n",
    "    if data.dim() != 3:\n",
    "        print(\"data tensor has unexpected dimension\", data.dim(), \"expected\", 3 )\n",
    "        return 0\n",
    "    \n",
    "    timesteps = data.size(dim=1)\n",
    "\n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    test_loss = 0\n",
    "    test_loss_deriv = 0\n",
    "    total_loss = 0\n",
    "   \n",
    "    if set_rand_seed:\n",
    "     np.random.seed(1234)\n",
    "\n",
    "\n",
    "    \n",
    "    if model_type in [\"or_lstm\", \"gru\"]:\n",
    "        for i, x in enumerate(data):\n",
    "            if i > 0: \n",
    "                break\n",
    "            x = data[num_of_inits]\n",
    "            x=x.to(device)        \n",
    "            x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "    \n",
    "            with torch.inference_mode():\n",
    "    \n",
    "                pred = torch.zeros((timesteps, 3), device=device)\n",
    "    \n",
    "                if window_size > 1:\n",
    "                    pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                    pred[:, 0] = x[0, :, 0]\n",
    "    \n",
    "                else:\n",
    "                    pred[0, :] = x[0, 0, :]\n",
    "                    pred[:, 0] = x[0, :, 0]\n",
    "      \n",
    "                        # (s' ,  v')        \n",
    "                out, _, derivative_sv = model(x)\n",
    "                pred[window_size:,1:] = out\n",
    "                print(out.size())\n",
    "\n",
    "#######################################################\n",
    "                physics_loss=0\n",
    "\n",
    "                x_dt = torch.zeros_like(x[:,window_size:,2:])\n",
    "                x_dt_net = torch.zeros_like(x[:,window_size:,2:])\n",
    "\n",
    "                m = 1.8931e-3                         # 1.8931e-3;              % Masse Booster in [kg]\n",
    "                A = 0.5*(71.0526e-6 + 78.9793e-6 )  # 0.5*(parBoost_gen.A_b_closed + parBoost_gen.A_b_open);   % Mittlere Fläche Booster in [m²]                                \n",
    "                                                        # % Anfangswerte der Boostereinheit\n",
    "                p0 = 1e5                                # parBoost_gen.s_b_0 = 3e-4;\n",
    "                s0 = 3e-4                               # parBoost_gen.p_b_0 = 1e5;\n",
    "                c = 16.5e3                              # parBoost_gen.c_b  = 16.5e3;                 % Federkonstante Booster in [N/m]\n",
    "                F_cb0 = -4.3                            #parBoost_gen.F_cb0 = -4.3;                    % Federvorspannkraft (Kraft der Feder bei sb=0) [N]\n",
    "\n",
    "                for i in range(x_dt.size(dim=0)):\n",
    "                    for time in range(window_size, x_dt.size(dim=1)):\n",
    "\n",
    "                        p =  x[i, time, 0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "                        s =  x[i, time, 1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "                        v =  x[i, time, 2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "                        x_dt[i, time - window_size, 0:] =  1/m * ( A * ( p - p0) - (c * s - F_cb0) + fr(v))\n",
    "                        #x_dt[i, time - window_size, 0:] =  1/m * ( A * ( p - p0) - (c * s - F_cb0) + fr(v) + fk(s,v) )\n",
    "                        #x_dt[i, time - window_size, 0:] =  1/m * ( A * ( p - p0) - (c * s - F_cb0))\n",
    "\n",
    "                        s_net =  out[i, time - window_size, 0]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "                        v_net =  out[i, time - window_size, 1]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "                        x_dt_net[i, time - window_size, 0:] =  1/m * ( A * ( p - p0) - (c * s_net - F_cb0) + fr(v_net)) \n",
    "                        #x_dt_net[i, time - window_size, 0:] =  1/m * ( A * ( p - p0) - (c * s_net - F_cb0) + fr(v_net) + fk(s_net, v_net) )\n",
    "                        #x_dt_net[i, time - window_size, 0:] =  1/m * ( A * ( p - p0) - (c * s_net - F_cb0)) \n",
    "\n",
    "                        if abs(x_dt_net[i, time - window_size, 0:] -  x_dt[i, time - window_size, 0:]) > 100:\n",
    "                            print(\"netz werte:\", \"s\", s_net.numpy(), \"v\", v_net.numpy())\n",
    "                            print(\"werte true:\", \"s\", s.numpy(), \"v\", v.numpy())\n",
    "                            print(\"f(netz)\", x_dt_net[i, time - window_size, 0:], \"f(true)\" ,x_dt[i, time - window_size, 0:])\n",
    "                            print(\"fr net\", fr(v_net), \"fk net\", fk(s_net, v_net))\n",
    "                            print(\"fr true\", fr(v), \"fk true\", fk(s, v))\n",
    "                            print(\"sign net\", np.sign(v_net), \"true sign\" , np.sign(v))\n",
    "                            print(\"---------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "                # numeric differentiation\n",
    "\n",
    "                v_rescaled = x[0,:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "                v_net_rescaled = out[0,:,1]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "                h = 1e-5\n",
    "\n",
    "                a_numeric = np.gradient(v_rescaled.numpy()) / h\n",
    "                a_numeric2 = (v_rescaled[1:] - v_rescaled[:-1]) / h\n",
    "                a_net_numeric = np.gradient(v_net_rescaled.numpy()) / h\n",
    "\n",
    "                # physics loss\n",
    "                loss_fn = nn.MSELoss()\n",
    "               # physics_loss = loss_fn(x_dt[0, :, 0], x_dt_net[0, :, 0]) \n",
    "                physics_loss = loss_fn(x_dt, x_dt_net)\n",
    "\n",
    "                n = x_dt.size(dim=1)\n",
    "                physics_loss_manuel = 1/ n * np.sum([ (x_dt[0,i,0] - x_dt_net[0,i,0])**2 for i in range(n) ])\n",
    "                print(physics_loss_manuel)\n",
    "                plt.plot((x_dt[0,:,0] - x_dt_net[0,:,0]))\n",
    "                plt.show()\n",
    "                figure , axs = plt.subplots(1,1,figsize=(20,9))\n",
    "\n",
    "                print(x_dt.size(), x_dt_net.size(), len(a_numeric))\n",
    "\n",
    "                axs.plot(x_dt[i, :, 0:].detach().cpu().numpy(), color=\"red\", label=\"a true\")\n",
    "                axs.plot(x_dt_net[i, :, 0:].detach().cpu().numpy(), color=\"blue\", label=\"a net\")\n",
    "                axs.plot(a_numeric[window_size:], color=\"green\", label=\"a numeric\")\n",
    "                #axs.plot(a_numeric2[window_size:], color=\"yellow\", label=\"[ v(t+1)-v(t) ] / h\")\n",
    "                axs.plot(a_net_numeric, color=\"purple\", label=\"a_net_numeric\")\n",
    "\n",
    "                axs.grid(True)\n",
    "                axs.legend()\n",
    "\n",
    "\n",
    "                #plt.plot(derivative_sv.numpy())\n",
    "                plt.show()\n",
    "                \n",
    "#######################################################\n",
    "            \n",
    "                test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                if display_plots:\n",
    "                    plot_results(x, pred, pred_next_step=None, physics_rescaling=physics_rescaling)\n",
    "\n",
    "    return np.mean(test_loss), np.mean(test_loss_deriv), np.mean(total_loss), physics_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.tanh(np.arange(-2,2, 0.01)/0.1)\n",
    "plt.plot(np.arange(-2,2, 0.01),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data import *\n",
    "from dataloader import *\n",
    "from NN_classes import *\n",
    "from experiments import *\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torchcde\n",
    "import time\n",
    "\n",
    "\n",
    "def plot_results(x, pred, pred_next_step=None, physics_rescaling=None, additional_data=None):\n",
    "\n",
    "    if x.dim() == 3:\n",
    "        x = x.view(x.size(dim=1), x.size(dim=2))\n",
    "    if pred.dim() == 3:\n",
    "        pred = pred.view(pred.size(dim=1), pred.size(dim=2))\n",
    "    if pred_next_step != None:\n",
    "        if pred_next_step.dim() == 3:\n",
    "            pred_next_step = pred_next_step.view(pred_next_step.size(dim=1), pred_next_step.size(dim=2))\n",
    "\n",
    "        #scale back:    \n",
    "    if physics_rescaling != None:\n",
    "\n",
    "        # we invert:\n",
    "        # x = (x - xmin)/(xmax - xmin)\n",
    "        # x * (xmax - xmin) + xmin\n",
    "\n",
    "        pred[:,0] = pred[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "       # pred[:,0] = pred[:,0]/1e5\n",
    "        pred[:,1] = pred[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        pred[:,2] = pred[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "        x[:,0] = x[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "       # x[:,0] = x[:,0]/1e5\n",
    "        x[:,1] = x[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        x[:,2] = x[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "        if additional_data != None:\n",
    "            for i in range(additional_data.size(dim=0)):\n",
    "                additional_data[i,:,0] = additional_data[i,:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "                additional_data[i,:,1] = additional_data[i,:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "                additional_data[i,:,2] = additional_data[i,:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    #figure , axs = plt.subplots(1,3,figsize=(20,8))\n",
    "    figure , axs = plt.subplots(3,1, figsize=(16,9))\n",
    "    figure.tight_layout(pad=5.0)\n",
    "\n",
    "    greek_letterz=[chr(code) for code in range(945,970)]\n",
    "    mu = greek_letterz[11]\n",
    "\n",
    "    stepsize = 2e-5\n",
    "    time = np.linspace(0,x.size(dim=0)* stepsize, x.size(dim=0))\n",
    "\n",
    "    if pred_next_step != None:\n",
    "        axs[0].plot(time, pred_next_step.detach().cpu().numpy()[:, 1], color=\"green\", label=\"next step from data\")\n",
    "        axs[1].plot(time, pred_next_step.detach().cpu().numpy()[:, 2], color=\"green\", label=\"next step from data\")\n",
    "\n",
    "    axs[0].plot(time, pred.detach().cpu().numpy()[:, 1], color=\"red\", label=\"pred\")\n",
    "    axs[0].plot(time, x.detach().cpu().numpy()[:, 1], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "\n",
    "    if additional_data != None:\n",
    "        for i in range(additional_data.size(dim=0)):\n",
    "           names = [\"simulink\", \"Hub im Regler\"]\n",
    "           axs[0].plot(time, additional_data[i, :, 1], label=names[i])\n",
    "\n",
    "    axs[0].set_title(\"position\")\n",
    "    axs[0].set_ylabel(\"[m]\")\n",
    "    axs[0].set_xlabel(f\"time [s]\")\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()\n",
    "\n",
    "\n",
    "    axs[1].plot(time, pred.detach().cpu().numpy()[:, 2], color=\"red\", label=\"pred\")\n",
    "    axs[1].plot(time, x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    if additional_data != None:\n",
    "        for i in range(additional_data.size(dim=0)):\n",
    "           names = [\"simulink\", \"Hub im Regler\"]\n",
    "           axs[1].plot(time, additional_data[i, :, 2], label=names[i])\n",
    "    axs[1].set_title(\"speed\")\n",
    "    axs[1].set_ylabel(\"[m/s]\")\n",
    "    axs[1].set_xlabel(f\"time [s]\")\n",
    "    axs[1].grid()\n",
    "    axs[1].legend()\n",
    "\n",
    "    axs[2].plot(time, x.detach().cpu().numpy()[:,0], label=\"pressure\")\n",
    "    if additional_data != None:\n",
    "       for i in range(additional_data.size(dim=0)):\n",
    "           names = [\"simulink\", \"Hub im Regler\"]\n",
    "           axs[2].plot(time, additional_data[i, :, 0], label=names[i])\n",
    "    axs[2].set_title(\"pressure\")\n",
    "    axs[2].set_ylabel(\"[Pa]\")\n",
    "    axs[2].set_xlabel(f\"time [s]\")\n",
    "    axs[2].grid()\n",
    "    axs[2].legend()\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test(data, model, model_type = \"or_lstm\", window_size=10, display_plots=False, num_of_inits = 5, set_rand_seed=True, physics_rescaling = 0, additional_data=None):\n",
    "\n",
    "    if model_type not in [\"or_lstm\", \"lstm\", \"mlp\", \"gru\", \"tcn\", \"or_tcn\", \"neural_cde\", \"or_mlp\"]:\n",
    "        print(\"Error: model_type = \", model_type, \"available options are: [or_lstm, lstm, mlp, gru, tcm]\")\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    device = \"cpu\" if data.get_device() == -1 else \"cuda:0\"\n",
    "    \n",
    "    if data.dim() != 3:\n",
    "        print(\"data tensor has unexpected dimension\", data.dim(), \"expected\", 3 )\n",
    "        return 0\n",
    "    \n",
    "    timesteps = data.size(dim=1)\n",
    "\n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    test_loss = 0\n",
    "    test_loss_deriv = 0\n",
    "    total_loss = 0\n",
    "    total_firsthalf = 0\n",
    "    total_secondhalf = 0\n",
    "   \n",
    "    if set_rand_seed:\n",
    "     np.random.seed(1234)\n",
    "\n",
    "    test_inits = data.size(dim=0)\n",
    "    ids = np.random.choice(test_inits, min([num_of_inits, test_inits]), replace=False)\n",
    "    ids = np.unique(ids)\n",
    "    \n",
    "\n",
    "    if model_type in [\"or_lstm\", \"gru\"]:\n",
    "        for i, x in enumerate(data):\n",
    "\n",
    "            x=x.to(device)        \n",
    "            x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "\n",
    "            if i not in ids:\n",
    "                continue\n",
    "    \n",
    "            with torch.inference_mode():\n",
    "    \n",
    "                pred = torch.zeros((timesteps, 3), device=device)\n",
    "    \n",
    "                if window_size > 1:\n",
    "                    pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                    pred[:, 0] = x[0, :, 0]\n",
    "    \n",
    "                else:\n",
    "                    pred[0, :] = x[0, 0, :]\n",
    "                    pred[:, 0] = x[0, :, 0]\n",
    "    \n",
    "\n",
    "                out, _ = model(x)\n",
    "                pred[window_size:,1:] = out\n",
    "\n",
    "                print(x.size(), pred.size())\n",
    "                test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                total_firsthalf += loss_fn(pred[window_size:int((timesteps-window_size)/2), 1:], \n",
    "                        x[0, window_size:int((timesteps-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                total_secondhalf += loss_fn(pred[int((timesteps-window_size)/2):, 1:],\n",
    "                            x[0, int((timesteps-window_size)/2):, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                if display_plots:\n",
    "                    plot_results(x, pred, pred_next_step=None, physics_rescaling=physics_rescaling, additional_data=additional_data)\n",
    "\n",
    "    if model_type == \"mlp\":\n",
    "        for i, x in enumerate(data):\n",
    "\n",
    "                x=x.to(device)\n",
    "                \n",
    "                if i not in ids:\n",
    "                    continue\n",
    "        \n",
    "                with torch.inference_mode():\n",
    "        \n",
    "                    pred = torch.zeros((timesteps, 3), device=device)\n",
    "        \n",
    "                    if window_size > 1:\n",
    "                        pred[0:window_size, :] = x[0:window_size, :]\n",
    "                        pred[:, 0] = x[ :, 0]\n",
    "        \n",
    "                    else:\n",
    "                        pred[0, :] = x[0, :]\n",
    "                        pred[:, 0] = x[:, 0]\n",
    "\n",
    "                    inp = torch.cat((x[:window_size,0], x[:window_size,1], x[:window_size,2]))\n",
    "\n",
    "                    for t in range(1,timesteps - window_size + 1 ): \n",
    "\n",
    "                        out = model(inp)\n",
    "                        pred[window_size+(t-1):window_size+t,1:] =  pred[window_size+(t-2):window_size+(t-1):,1:] + out\n",
    "                        new_p = pred[t:t+window_size,0]\n",
    "                        new_s = pred[t:t+window_size,1]\n",
    "                        new_v = pred[t:t+window_size,2]\n",
    "                        \n",
    "                        inp = torch.cat((new_p, new_s, new_v))\n",
    "\n",
    "                    test_loss += loss_fn(pred[window_size:, 1], x[window_size:, 1]).detach().cpu().numpy()\n",
    "                    test_loss_deriv += loss_fn(pred[window_size:, 2], x[window_size:, 2]).detach().cpu().numpy()\n",
    "                    total_loss += loss_fn(pred[window_size:, 1:], x[window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                    \n",
    "                    total_firsthalf += loss_fn(pred[window_size:int((pred.size(dim=0)-window_size)/2), 1:], \n",
    "                                            x[window_size:int((pred.size(dim=0)-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                    total_secondhalf += loss_fn(pred[int((pred.size(dim=0)-window_size)/2):, 1:],\n",
    "                                                x[int((pred.size(dim=0)-window_size)/2):, 1:]).detach().cpu().numpy()  \n",
    "                    #print(\"Error first half: \", total_firsthalf)\n",
    "                    #print(\"Error second half: \", total_secondhalf)\n",
    "\n",
    "                    if display_plots:\n",
    "                        plot_results(x, pred, pred_next_step=None, physics_rescaling=physics_rescaling, additional_data=additional_data)\n",
    "\n",
    "    if model_type == \"lstm\":\n",
    "        for i, x in enumerate(data):\n",
    "            x=x.to(device)\n",
    "            if i not in ids:\n",
    "                continue\n",
    "\n",
    "            with torch.inference_mode():\n",
    "\n",
    "                pred = torch.zeros((timesteps, 3), device=device)\n",
    "                pred_next_step = torch.zeros((timesteps, 3), device=device)\n",
    "\n",
    "                if window_size > 1:\n",
    "                    pred[0:window_size, :] = x[0:window_size, :]\n",
    "                    pred[:, 0] = x[:, 0]\n",
    "                    pred_next_step[0:window_size, :] = x[0:window_size, :]\n",
    "                    pred_next_step[:, 0] = x[:, 0]\n",
    "                else:\n",
    "                    pred[0, :] = x[0, :]\n",
    "                    pred[:, 0] = x[:, 0]\n",
    "                    pred_next_step[0, :] = x[0, :]\n",
    "                    pred_next_step[:, 0] = x[:, 0]\n",
    "\n",
    "                for i in range(len(x) - window_size):\n",
    "\n",
    "                    out, _ = model(pred[i:i+window_size, :])\n",
    "                    pred[i+window_size, 1:] = pred[i+window_size-1, 1:] + out[-1, :]\n",
    "                    pred_next_step[i+window_size, 1:] = x[i+window_size-1, 1:] + out[-1, :]\n",
    "                \n",
    "                test_loss += loss_fn(pred[:, 1], x[:, 1]).detach().cpu().numpy()\n",
    "                test_loss_deriv += loss_fn(pred[:, 2], x[:, 2]).detach().cpu().numpy()\n",
    "\n",
    "                total_loss += loss_fn(pred[:, 1:], x[:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                if display_plots:\n",
    "                    plot_results(x, pred, pred_next_step=None, physics_rescaling=physics_rescaling , additional_data=additional_data)\n",
    "\n",
    "    if model_type == \"tcn\" :\n",
    "         for i, x in enumerate(data):\n",
    "            \n",
    "            if i not in ids:\n",
    "                continue\n",
    "\n",
    "            with torch.inference_mode():\n",
    "\n",
    "                x=x.to(device)        \n",
    "                x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "\n",
    "                pred = torch.zeros_like(x, device=device)  \n",
    "                pred_next_step = torch.zeros_like(x, device=device)               \n",
    "\n",
    "                pred[:, 0:window_size, :] = x[0, 0:window_size, :]\n",
    "                pred[:, :, 0] = x[0, :, 0]\n",
    "\n",
    "                for i in range(1,x.size(1) - window_size + 1):\n",
    "\n",
    "                    pred[:, window_size+(i-1):window_size+i,1:] =  pred[:, window_size+(i-2):window_size+(i-1):,1:] + model(pred[:,i:window_size+(i-1),:].transpose(1,2))    \n",
    "\n",
    "                test_loss += loss_fn(pred[0, :, 1], x[0, :, 1]).detach().cpu().numpy()\n",
    "                test_loss_deriv += loss_fn(pred[0, :, 2], x[0, :, 2]).detach().cpu().numpy()\n",
    "\n",
    "                total_loss += loss_fn(pred[0, :, 1:], x[0, :, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                if display_plots:\n",
    "                    plot_results(x, pred, pred_next_step=None, physics_rescaling=physics_rescaling , additional_data=additional_data)\n",
    "\n",
    "    if model_type == \"or_tcn\" :\n",
    "         for i, x in enumerate(data):\n",
    "            \n",
    "            if i not in ids:\n",
    "                continue\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                x=x.to(device)        \n",
    "                x = x.view(1,x.size(dim=0), x.size(dim=1))                \n",
    "                pred = torch.zeros((timesteps, 3), device=device)\n",
    "    \n",
    "                if window_size > 1:\n",
    "                    pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                    pred[:, 0] = x[0, :, 0]\n",
    "    \n",
    "                else:\n",
    "                    pred[0, :] = x[0, 0, :]\n",
    "                    pred[:, 0] = x[0, :, 0]\n",
    "    \n",
    "                x_test = x.clone()\n",
    "                x_test[:,window_size:,1:] = 0\n",
    "                x_test = x_test.to(device)\n",
    "                #print(\"Data passed to the model, all 0 after the initial window to prove that the forward pass is correct and doesnt access information it shouldnt.\",x_test[:,0:10,:])\n",
    "\n",
    "                out = model(x_test.transpose(1,2))\n",
    "                \n",
    "                pred[window_size:,1:] = out.squeeze(0).transpose(0,1)\n",
    "\n",
    "                test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                if display_plots:\n",
    "                    plot_results(x, pred, pred_next_step=None, physics_rescaling=physics_rescaling , additional_data=additional_data)\n",
    "\n",
    "    if model_type == \"neural_cde\" :\n",
    "         for i, x in enumerate(data):\n",
    "            \n",
    "            if i not in ids:\n",
    "                continue\n",
    "\n",
    "            with torch.inference_mode():\n",
    "\n",
    "                x=x.to(device)        \n",
    "                x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "\n",
    "                pred = torch.zeros_like(x, device=device)\n",
    "        \n",
    "                pred[:, 0:window_size, :] = x[0:1, 0:window_size, :]\n",
    "                pred[:, :, 0:2] = x[0:1, :, 0:2] # time, pressure\n",
    "\n",
    "                #start_total=time.time()\n",
    "\n",
    "                for i in range(x.size(1) - window_size):\n",
    "                    \n",
    "                    #start_coeffs=time.time()\n",
    "                    train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(pred[0:1, i:i+window_size, :]) \n",
    "                    #train_coeffs = torchcde.linear_interpolation_coeffs(pred[0:1, i:i+window_size, :])\n",
    "   \n",
    "                    #stop_coeffs=time.time()\n",
    "                    #print(stop_coeffs-start_coeffs, \"time: coeff calc one step\")\n",
    "                    if (i+1)%100==0:\n",
    "                     print(i, \" timessteps done\")\n",
    "                    #start=time.time()\n",
    "\n",
    "                    out = model(train_coeffs)\n",
    "                    pred[0:1, i+window_size, 2:] = pred[0:1, i+window_size-1, 2:] + out.unsqueeze(1)\n",
    "\n",
    "                    #pred[0:1, i+window_size, 2:] = out\n",
    "                    #stop=time.time()\n",
    "                    #print(stop-start, \"time: model calc step\")\n",
    "\n",
    "                test_loss += loss_fn(pred[0, window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                test_loss_deriv += loss_fn(pred[0, window_size:, 3], x[0, window_size:, 3]).detach().cpu().numpy()\n",
    "                total_loss += loss_fn(pred[0, window_size:, 2:], x[0, window_size:, 2:]).detach().cpu().numpy()\n",
    "\n",
    "                total_firsthalf += loss_fn(pred[0, window_size:int((pred.size(dim=1)-window_size)/2), 2:], \n",
    "                                           x[0, window_size:int((pred.size(dim=1)-window_size)/2), 2:]).detach().cpu().numpy()  \n",
    "                total_secondhalf += loss_fn(pred[0, int((pred.size(dim=1)-window_size)/2):, 2:],\n",
    "                                             x[0, int((pred.size(dim=1)-window_size)/2):, 2:]).detach().cpu().numpy()  \n",
    "                #print(\"Error first half: \", total_firsthalf)\n",
    "                #print(\"Error second half: \", total_secondhalf)\n",
    "\n",
    "                #stop_total=time.time()\n",
    "               # print(stop_total-start_total, \"time: model calc step\")\n",
    "\n",
    "                if display_plots:\n",
    "                    plot_results(x[:,:,1:], pred[:,:,1:], pred_next_step=None, physics_rescaling=physics_rescaling , additional_data=additional_data)\n",
    "\n",
    "    if model_type == \"or_mlp\" :\n",
    "         for i, x in enumerate(data):\n",
    "            \n",
    "            if i not in ids:\n",
    "                continue\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                x=x.to(device)        \n",
    "                x = x.view(1,x.size(dim=0), x.size(dim=1))                \n",
    "                pred = torch.zeros((timesteps, 3), device=device)\n",
    "    \n",
    "                if window_size > 1:\n",
    "                    pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                    pred[:, 0] = x[0, :, 0]\n",
    "    \n",
    "                else:\n",
    "                    pred[0, :] = x[0, 0, :]\n",
    "                    pred[:, 0] = x[0, :, 0]\n",
    "    \n",
    "                x_test = x.clone()\n",
    "                x_test[:,window_size:,1:] = 0\n",
    "                x_test = x_test.to(device)\n",
    "                #print(\"Data passed to the model, all 0 after the initial window to prove that the forward pass is correct and doesnt access information it shouldnt.\",x_test[:,0:10,:])\n",
    "\n",
    "                out = model(x_test)\n",
    "                \n",
    "                pred[window_size:,1:] = out\n",
    "\n",
    "                test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                total_firsthalf += loss_fn(pred[window_size:int((pred.size(dim=0)-window_size)/2), 1:], \n",
    "                                            x[0, window_size:int((pred.size(dim=0)-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                total_secondhalf += loss_fn(pred[int((pred.size(dim=0)-window_size)/2):, 1:],\n",
    "                                                x[0, int((pred.size(dim=0)-window_size)/2):, 1:]).detach().cpu().numpy()  \n",
    "\n",
    "                if display_plots:\n",
    "                    plot_results(x, pred, pred_next_step=None, physics_rescaling=physics_rescaling , additional_data=additional_data)\n",
    "\n",
    "\n",
    "    print(\"Error first half: \", np.mean(total_firsthalf))\n",
    "    print(\"Error second half: \", np.mean(total_secondhalf))\n",
    "    print(\"total loss full traj: \", np.mean(total_loss))\n",
    "\n",
    "    return np.mean(test_loss), np.mean(test_loss_deriv), np.mean(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2750, 3])\n",
      "input_data size torch.Size([50, 2750, 3])\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Ventil_trained_NNs\\\\OR_MLP1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m path_or_mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVentil_trained_NNs\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOR_MLP1.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m#path_mlp = \"working_networks\\MLP_5_8_1.pth\"\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m model_or_mlp\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     74\u001b[0m model_mlp \u001b[38;5;241m=\u001b[39m MLP(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mparams_mlp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], hidden_size \u001b[38;5;241m=\u001b[39m params_mlp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], l_num\u001b[38;5;241m=\u001b[39mparams_mlp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_num\u001b[39m\u001b[38;5;124m\"\u001b[39m], output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, act_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, act_at_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     75\u001b[0m path_mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworking_networks\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMLP_5_8_1.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\strasserp\\AppData\\Local\\anaconda3\\envs\\my_test_env\\Lib\\site-packages\\torch\\serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\strasserp\\AppData\\Local\\anaconda3\\envs\\my_test_env\\Lib\\site-packages\\torch\\serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\strasserp\\AppData\\Local\\anaconda3\\envs\\my_test_env\\Lib\\site-packages\\torch\\serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Ventil_trained_NNs\\\\OR_MLP1.pth'"
     ]
    }
   ],
   "source": [
    "params_lstm =   {\n",
    "                        \"window_size\" : 16,\n",
    "                        \"h_size\" : 8,\n",
    "                        \"l_num\" : 3,\n",
    "                        \"learning_rate\" : 0.0008,\n",
    "                        \"batch_size\" : 20,\n",
    "                }\n",
    "\n",
    "params_mlp =    {\n",
    "                        \"window_size\" : 5,\n",
    "                        \"h_size\" : 8,\n",
    "                        \"l_num\" : 1,\n",
    "                        \"learning_rate\" : 0.001,\n",
    "                        \"batch_size\" : 20,\n",
    "                        \"act_fn\" : \"relu\",\n",
    "                        \"nonlin_at_out\" : None #None if no nonlinearity at the end\n",
    "                }\n",
    "\n",
    "params_tcn =    {\n",
    "                    \"window_size\" : 30,\n",
    "                    \"learning_rate\" : 0.001,\n",
    "                    \"batch_size\" : 20,\n",
    "                    \"n_hidden\" : 5,\n",
    "                    \"levels\" : 4,\n",
    "                    \"kernel_size\" : 7,\n",
    "                    \"dropout\" : 0,\n",
    "                    \"input_channels\" : 3,\n",
    "                    \"output\" : 2,\n",
    "                    \"drop_half_timesteps\" : True,\n",
    "                    \"cut_off_timesteps\" : 100,\n",
    "                    \"part_of_data\" : 0,\n",
    "                    \"percentage_of_data\" : 0.8\n",
    "\n",
    "                }\n",
    "    \n",
    "parameter_configs  = [params_lstm, params_mlp, params_tcn] \n",
    "\n",
    "path = \"data\\save_data_test_5xlonger_dyndyn.csv\"\n",
    "#path = \"data\\save_data_test_revised.csv\"\n",
    "input_data, PSW_max = get_data(path = path, \n",
    "                        timesteps_from_data=0, \n",
    "                        skip_steps_start = 0,\n",
    "                        skip_steps_end = 0, \n",
    "                        drop_half_timesteps = params_tcn[\"drop_half_timesteps\"],\n",
    "                        normalise_s_w=\"minmax\",\n",
    "                        rescale_p=False,\n",
    "                        num_inits=params_tcn[\"part_of_data\"])\n",
    "\n",
    "print(input_data.size())\n",
    "\n",
    "np.random.seed(1234)\n",
    "print(\"input_data size\", input_data.size())\n",
    "num_of_inits_train = int(len(input_data)*params_tcn[\"percentage_of_data\"])\n",
    "train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "np.random.shuffle(train_inits)\n",
    "np.random.shuffle(test_inits)\n",
    "test_data = input_data[test_inits,:,:]\n",
    "np.random.seed()\n",
    "\n",
    "#load models\n",
    "# Initialize the LSTM model\n",
    "model_lstm = LSTMmodel(input_size=3, hidden_size=params_lstm[\"h_size\"], out_size=2, layers=params_lstm[\"l_num\"], window_size=params_lstm[\"window_size\"]).to(device)\n",
    "path_lstm = \"Ventil_trained_NNs\\OR_LSTM0.pth\"#\n",
    "path_lstm = \"First_experiment_run_22_07_2024\\LSTM_or_nextstep_exp0.pth\"\n",
    "#path_lstm = \"working_networks\\OR_lstm_16_8_3_best_V2.pth\"\n",
    "model_lstm.load_state_dict(torch.load(path_lstm, map_location=torch.device(device)))\n",
    "# Initialize the MLP model\n",
    "model_or_mlp = OR_MLP(input_size=3*params_mlp[\"window_size\"], hidden_size = params_mlp[\"h_size\"], l_num=params_mlp[\"l_num\"],\n",
    "                output_size=2, act_fn = params_mlp[\"act_fn\"], act_at_end = params_mlp[\"nonlin_at_out\"], timesteps=params_mlp[\"window_size\"]).to(device)\n",
    "path_or_mlp = \"Ventil_trained_NNs\\OR_MLP1.pth\"\n",
    "#path_mlp = \"working_networks\\MLP_5_8_1.pth\"\n",
    "model_or_mlp.load_state_dict(torch.load(path_or_mlp, map_location=torch.device(device)))\n",
    "\n",
    "model_mlp = MLP(input_size=3*params_mlp[\"window_size\"], hidden_size = params_mlp[\"h_size\"], l_num=params_mlp[\"l_num\"], output_size=2, act_fn = \"relu\", act_at_end = None).to(device)\n",
    "path_mlp = \"working_networks\\MLP_5_8_1.pth\"\n",
    "#path_mlp = \"working_networks\\MLP_5_8_1.pth\"\n",
    "model_mlp.load_state_dict(torch.load(path_mlp, map_location=torch.device(device)))\n",
    "\n",
    "# Initialize the TCN model\n",
    "input_channels = params_tcn[\"input_channels\"]\n",
    "output = params_tcn[\"output\"]\n",
    "num_channels = [params_tcn[\"n_hidden\"]] * params_tcn[\"levels\"]\n",
    "kernel_size = params_tcn[\"kernel_size\"]\n",
    "dropout = params_tcn[\"dropout\"]\n",
    "model_tcn = OR_TCN(input_channels, output, num_channels, kernel_size=kernel_size, dropout=dropout, windowsize=params_tcn[\"window_size\"]).to(device)\n",
    "#path_tcn = \"Ventil_trained_NNs\\OR_TCN2.pth\"\n",
    "path_tcn = \"working_networks\\or_tcn_547.pth\"\n",
    "model_tcn.load_state_dict(torch.load(path_tcn, map_location=torch.device(device)))\n",
    "\n",
    "# TODO Neural CDE  \n",
    "#model = NeuralCDE(input_channels=4, hidden_channels=params[\"h_size\"], hidden_width = params[\"h_width\"], output_channels=2).to(device)\n",
    "#model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "models = {\"or_lstm\" : model_lstm,\n",
    "          #\"or_mlp\" : model_or_mlp,\n",
    "          \"mlp\" : model_mlp,\n",
    "          \"or_tcn\" : model_tcn\n",
    "          }\n",
    "\n",
    "window_sizes = {\"or_lstm\" : params_lstm[\"window_size\"],\n",
    "                \"or_mlp\" : params_mlp[\"window_size\"],\n",
    "                \"mlp\" : params_mlp[\"window_size\"],\n",
    "                \"or_tcn\" : params_tcn[\"window_size\"]\n",
    "                }\n",
    "    \n",
    "\n",
    "\n",
    "exp1(models, input_data[:,:,:], window_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the experiments to compare the trained models \n",
    "import torch\n",
    "import torchcde\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def exp1(models: dict, data, window_sizes, plot_errs=False, set_random=False):\n",
    "    \n",
    "    if set_random:\n",
    "         np.seed(1234)\n",
    "    \n",
    "    if plot_errs==False:\n",
    "        index = np.random.randint(0, data.size(dim=0),1)[0]\n",
    "        data = data[index:index+1,:,:]\n",
    "\n",
    "    print(data.size())\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_loss_deriv = 0\n",
    "    total_loss = 0\n",
    "    total_firsthalf = 0\n",
    "    total_secondhalf = 0\n",
    "\n",
    "    device = \"cpu\" if data.get_device() == -1 else \"cuda:0\"\n",
    "    timesteps = data.size(dim=1)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    predictionary = {}\n",
    "    error_dict = {}\n",
    "    with torch.inference_mode():\n",
    "        for model_type, model in models.items():\n",
    "\n",
    "            window_size = window_sizes[model_type]\n",
    "            model.eval()\n",
    "                \n",
    "            if model_type == \"or_lstm\":\n",
    "                    for i, x in enumerate(data):\n",
    "\n",
    "                        x=x.to(device)        \n",
    "                        x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "                \n",
    "                        with torch.inference_mode():\n",
    "                \n",
    "                            pred = torch.zeros((timesteps, 3), device=device)\n",
    "                \n",
    "                            if window_size > 1:\n",
    "                                pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "                \n",
    "                            else:\n",
    "                                pred[0, :] = x[0, 0, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "                \n",
    "\n",
    "                            out, _ = model(x)\n",
    "                            pred[window_size:,1:] = out\n",
    "\n",
    "                            print(x.size(), pred.size())\n",
    "                            test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                            total_firsthalf += loss_fn(pred[window_size:int((timesteps-window_size)/2), 1:], \n",
    "                                    x[0, window_size:int((timesteps-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                            total_secondhalf += loss_fn(pred[int((timesteps-window_size)/2):, 1:],\n",
    "                                        x[0, int((timesteps-window_size)/2):, 1:]).detach().cpu().numpy()\n",
    "                            \n",
    "                    predictionary[model_type] = pred\n",
    "                    error_dict[model_type] = total_loss\n",
    "            \n",
    "            if model_type == \"mlp\":\n",
    "                for i, x in enumerate(data):\n",
    "\n",
    "                        x=x.to(device)\n",
    "                        \n",
    "                        with torch.inference_mode():\n",
    "                \n",
    "                            pred = torch.zeros((timesteps, 3), device=device)\n",
    "                \n",
    "                            if window_size > 1:\n",
    "                                pred[0:window_size, :] = x[0:window_size, :]\n",
    "                                pred[:, 0] = x[ :, 0]\n",
    "                \n",
    "                            else:\n",
    "                                pred[0, :] = x[0, :]\n",
    "                                pred[:, 0] = x[:, 0]\n",
    "\n",
    "                            inp = torch.cat((x[:window_size,0], x[:window_size,1], x[:window_size,2]))\n",
    "\n",
    "                            for t in range(1,timesteps - window_size + 1 ): \n",
    "\n",
    "                                out = model(inp)\n",
    "                                pred[window_size+(t-1):window_size+t,1:] =  pred[window_size+(t-2):window_size+(t-1):,1:] + out\n",
    "                                new_p = pred[t:t+window_size,0]\n",
    "                                new_s = pred[t:t+window_size,1]\n",
    "                                new_v = pred[t:t+window_size,2]\n",
    "                                \n",
    "                                inp = torch.cat((new_p, new_s, new_v))\n",
    "\n",
    "                            test_loss += loss_fn(pred[window_size:, 1], x[window_size:, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[window_size:, 2], x[window_size:, 2]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[window_size:, 1:], x[window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                            \n",
    "                            total_firsthalf += loss_fn(pred[window_size:int((pred.size(dim=0)-window_size)/2), 1:], \n",
    "                                                    x[window_size:int((pred.size(dim=0)-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                            total_secondhalf += loss_fn(pred[int((pred.size(dim=0)-window_size)/2):, 1:],\n",
    "                                                        x[int((pred.size(dim=0)-window_size)/2):, 1:]).detach().cpu().numpy()  \n",
    "                            \n",
    "                predictionary[model_type] = pred\n",
    "                error_dict[model_type] = total_loss\n",
    "\n",
    "            if model_type == \"lstm\":\n",
    "                for i, x in enumerate(data):\n",
    "                    x=x.to(device)\n",
    "                \n",
    "                    with torch.inference_mode():\n",
    "\n",
    "                        pred = torch.zeros((timesteps, 3), device=device)\n",
    "                        pred_next_step = torch.zeros((timesteps, 3), device=device)\n",
    "\n",
    "                        if window_size > 1:\n",
    "                            pred[0:window_size, :] = x[0:window_size, :]\n",
    "                            pred[:, 0] = x[:, 0]\n",
    "                            pred_next_step[0:window_size, :] = x[0:window_size, :]\n",
    "                            pred_next_step[:, 0] = x[:, 0]\n",
    "                        else:\n",
    "                            pred[0, :] = x[0, :]\n",
    "                            pred[:, 0] = x[:, 0]\n",
    "                            pred_next_step[0, :] = x[0, :]\n",
    "                            pred_next_step[:, 0] = x[:, 0]\n",
    "\n",
    "                        for i in range(len(x) - window_size):\n",
    "\n",
    "                            out, _ = model(pred[i:i+window_size, :])\n",
    "                            pred[i+window_size, 1:] = pred[i+window_size-1, 1:] + out[-1, :]\n",
    "                            pred_next_step[i+window_size, 1:] = x[i+window_size-1, 1:] + out[-1, :]\n",
    "                        \n",
    "                        test_loss += loss_fn(pred[:, 1], x[:, 1]).detach().cpu().numpy()\n",
    "                        test_loss_deriv += loss_fn(pred[:, 2], x[:, 2]).detach().cpu().numpy()\n",
    "\n",
    "                        total_loss += loss_fn(pred[:, 1:], x[:, 1:]).detach().cpu().numpy()\n",
    "                    \n",
    "                predictionary[model_type] = pred\n",
    "                error_dict[model_type] = total_loss\n",
    "\n",
    "            if model_type == \"tcn\" :\n",
    "                    for i, x in enumerate(data):\n",
    "\n",
    "                        with torch.inference_mode():\n",
    "\n",
    "                            x=x.to(device)        \n",
    "                            x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "\n",
    "                            pred = torch.zeros_like(x, device=device)  \n",
    "                            pred_next_step = torch.zeros_like(x, device=device)               \n",
    "\n",
    "                            pred[:, 0:window_size, :] = x[0, 0:window_size, :]\n",
    "                            pred[:, :, 0] = x[0, :, 0]\n",
    "\n",
    "                            for i in range(1,x.size(1) - window_size + 1):\n",
    "\n",
    "                                pred[:, window_size+(i-1):window_size+i,1:] =  pred[:, window_size+(i-2):window_size+(i-1):,1:] + model(pred[:,i:window_size+(i-1),:].transpose(1,2))    \n",
    "\n",
    "                            test_loss += loss_fn(pred[0, :, 1], x[0, :, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[0, :, 2], x[0, :, 2]).detach().cpu().numpy()\n",
    "\n",
    "                            total_loss += loss_fn(pred[0, :, 1:], x[0, :, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                        predictionary[model_type] = pred\n",
    "                        error_dict[model_type] = total_loss\n",
    "\n",
    "            if model_type == \"or_tcn\" :\n",
    "                    for i, x in enumerate(data):\n",
    "                    \n",
    "\n",
    "                        with torch.inference_mode():\n",
    "                            x=x.to(device)        \n",
    "                            x = x.view(1,x.size(dim=0), x.size(dim=1))                \n",
    "                            pred = torch.zeros((timesteps, 3), device=device)\n",
    "\n",
    "                            if window_size > 1:\n",
    "                                pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "\n",
    "                            else:\n",
    "                                pred[0, :] = x[0, 0, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "\n",
    "                            x_test = x.clone()\n",
    "                            x_test[:,window_size:,1:] = 0\n",
    "                            x_test = x_test.to(device)\n",
    "                            #print(\"Data passed to the model, all 0 after the initial window to prove that the forward pass is correct and doesnt access information it shouldnt.\",x_test[:,0:10,:])\n",
    "\n",
    "                            out = model(x_test.transpose(1,2))\n",
    "                            \n",
    "                            pred[window_size:,1:] = out.squeeze(0).transpose(0,1)\n",
    "\n",
    "                            test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                        predictionary[model_type] = pred\n",
    "                        error_dict[model_type] = total_loss\n",
    "\n",
    "            if model_type == \"neural_cde\" :\n",
    "                    for i, x in enumerate(data):\n",
    "\n",
    "                        with torch.inference_mode():\n",
    "\n",
    "                            x=x.to(device)        \n",
    "                            x = x.view(1,x.size(dim=0), x.size(dim=1))\n",
    "\n",
    "                            pred = torch.zeros_like(x, device=device)\n",
    "                    \n",
    "                            pred[:, 0:window_size, :] = x[0:1, 0:window_size, :]\n",
    "                            pred[:, :, 0:2] = x[0:1, :, 0:2] # time, pressure\n",
    "\n",
    "                            #start_total=time.time()\n",
    "\n",
    "                            for i in range(x.size(1) - window_size):\n",
    "                                \n",
    "                                #start_coeffs=time.time()\n",
    "                                train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(pred[0:1, i:i+window_size, :]) \n",
    "                                #train_coeffs = torchcde.linear_interpolation_coeffs(pred[0:1, i:i+window_size, :])\n",
    "\n",
    "                                #stop_coeffs=time.time()\n",
    "                                #print(stop_coeffs-start_coeffs, \"time: coeff calc one step\")\n",
    "                                if (i+1)%100==0:\n",
    "                                    print(i, \" timessteps done\")\n",
    "                                #start=time.time()\n",
    "\n",
    "                                out = model(train_coeffs)\n",
    "                                pred[0:1, i+window_size, 2:] = pred[0:1, i+window_size-1, 2:] + out.unsqueeze(1)\n",
    "\n",
    "                                #pred[0:1, i+window_size, 2:] = out\n",
    "                                #stop=time.time()\n",
    "                                #print(stop-start, \"time: model calc step\")\n",
    "\n",
    "                            test_loss += loss_fn(pred[0, window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[0, window_size:, 3], x[0, window_size:, 3]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[0, window_size:, 2:], x[0, window_size:, 2:]).detach().cpu().numpy()\n",
    "\n",
    "                            total_firsthalf += loss_fn(pred[0, window_size:int((pred.size(dim=1)-window_size)/2), 2:], \n",
    "                                                        x[0, window_size:int((pred.size(dim=1)-window_size)/2), 2:]).detach().cpu().numpy()  \n",
    "                            total_secondhalf += loss_fn(pred[0, int((pred.size(dim=1)-window_size)/2):, 2:],\n",
    "                                                            x[0, int((pred.size(dim=1)-window_size)/2):, 2:]).detach().cpu().numpy()  \n",
    "                    \n",
    "                        predictionary[model_type] = pred\n",
    "                        error_dict[model_type] = total_loss\n",
    "\n",
    "            if model_type == \"or_mlp\" :\n",
    "                    \n",
    "                    for i, x in enumerate(data):\n",
    "                    \n",
    "\n",
    "                        with torch.inference_mode():\n",
    "                            x=x.to(device)        \n",
    "                            x = x.view(1,x.size(dim=0), x.size(dim=1))                \n",
    "                            pred = torch.zeros((timesteps, 3), device=device)\n",
    "\n",
    "                            if window_size > 1:\n",
    "                                pred[0:window_size, :] = x[0, 0:window_size, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "\n",
    "                            else:\n",
    "                                pred[0, :] = x[0, 0, :]\n",
    "                                pred[:, 0] = x[0, :, 0]\n",
    "\n",
    "                            x_test = x.clone()\n",
    "                            x_test[:,window_size:,1:] = 0\n",
    "                            x_test = x_test.to(device)\n",
    "\n",
    "                            out = model(x_test)\n",
    "                            \n",
    "                            pred[window_size:,1:] = out\n",
    "\n",
    "                            test_loss += loss_fn(pred[window_size:, 1], x[0, window_size:, 1]).detach().cpu().numpy()\n",
    "                            test_loss_deriv += loss_fn(pred[window_size:, 2], x[0, window_size:, 2]).detach().cpu().numpy()\n",
    "                            total_loss += loss_fn(pred[window_size:, 1:], x[0, window_size:, 1:]).detach().cpu().numpy()\n",
    "\n",
    "                            total_firsthalf += loss_fn(pred[window_size:int((pred.size(dim=0)-window_size)/2), 1:], \n",
    "                                                        x[0, window_size:int((pred.size(dim=0)-window_size)/2), 1:]).detach().cpu().numpy()  \n",
    "                            total_secondhalf += loss_fn(pred[int((pred.size(dim=0)-window_size)/2):, 1:],\n",
    "                                                        x[0, int((pred.size(dim=0)-window_size)/2):, 1:]).detach().cpu().numpy()\n",
    "                            \n",
    "                        predictionary[model_type] = pred\n",
    "                        error_dict[model_type] = total_loss  \n",
    "        \n",
    "        if not plot_errs:\n",
    "            #phase_plot_predictions(predictionary, data)\n",
    "            plot_predictions(predictionary, data)\n",
    "        else:\n",
    "            plot_errors(error_dict)\n",
    "\n",
    "def plot_predictions(predictionary, x):\n",
    "\n",
    "\n",
    "\n",
    "    p_max = 3.5*1e5 #Druck in [bar]         ... [1 , 3.5]\n",
    "    s_max = 0.6*1e-3 #Position [m]          ... [0, 0.0006]\n",
    "    w_max = 1.7 #Geschwindigkeit in [m/s]   ... [-1.7, 1.7]\n",
    "    p_min = 1.0\n",
    "    s_min = 0.0\n",
    "    w_min = -1.7\n",
    "    physics_rescaling = [p_max, s_max, w_max, p_min, s_min, w_min]\n",
    "\n",
    "    colors = {\"or_lstm\" : \"red\",\n",
    "              \"or_mlp\" : \"green\",\n",
    "              \"mlp\" : \"green\",\n",
    "              \"or_tcn\" : \"purple\",\n",
    "              \"neural_cde\"  : \"brown\"}\n",
    "\n",
    "    figure , axs = plt.subplots(3,1, figsize=(16,9))\n",
    "    figure.tight_layout(pad=5.0)    \n",
    "\n",
    "    if x.dim() == 3:\n",
    "        x = x.view(x.size(dim=1), x.size(dim=2))\n",
    "    \n",
    "        #scale back:    \n",
    "    if physics_rescaling != None:\n",
    "\n",
    "        x[:,0] = x[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "        x[:,1] = x[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        x[:,2] = x[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    greek_letterz=[chr(code) for code in range(945,970)]\n",
    "    mu = greek_letterz[11]\n",
    "\n",
    "    stepsize = 2e-5\n",
    "    time = np.linspace(0,x.size(dim=0)* stepsize, x.size(dim=0))\n",
    "\n",
    "    #data\n",
    "    axs[0].plot(time, x.detach().cpu().numpy()[:, 1], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    axs[1].plot(time, x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "    axs[2].plot(time, x.detach().cpu().numpy()[:,0], label=\"pressure\")\n",
    "\n",
    "    #predictions\n",
    "    for key, pred in predictionary.items():\n",
    "\n",
    "        if physics_rescaling != None:\n",
    "\n",
    "            # we invert:\n",
    "            # x = (x - xmin)/(xmax - xmin)\n",
    "            # x * (xmax - xmin) + xmin\n",
    "\n",
    "            pred[:,0] = pred[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "            pred[:,1] = pred[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "            pred[:,2] = pred[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.view(pred.size(dim=1), pred.size(dim=2))\n",
    "\n",
    "        axs[0].plot(time, pred.detach().cpu().numpy()[:, 1], color=colors[key], label=f\"{key}-prediciton\", alpha=0.5)\n",
    "        axs[1].plot(time, pred.detach().cpu().numpy()[:, 2], color=colors[key], label=f\"{key}-prediciton\", alpha=0.5)\n",
    "\n",
    "\n",
    "    axs[0].set_title(\"position\")\n",
    "    axs[0].set_ylabel(\"[m]\")\n",
    "    axs[0].set_xlabel(f\"time [s]\")\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()   \n",
    "    axs[1].set_title(\"speed\")\n",
    "    axs[1].set_ylabel(\"[m/s]\")\n",
    "    axs[1].set_xlabel(f\"time [s]\")\n",
    "    axs[1].grid()\n",
    "    axs[1].legend()\n",
    "    axs[2].set_title(\"pressure\")\n",
    "    axs[2].set_ylabel(\"[Pa]\")\n",
    "    axs[2].set_xlabel(f\"time [s]\")\n",
    "    axs[2].grid()\n",
    "    axs[2].legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def phase_plot_predictions(predictionary, x):\n",
    "\n",
    "\n",
    "\n",
    "    p_max = 3.5*1e5 #Druck in [bar]         ... [1 , 3.5]\n",
    "    s_max = 0.6*1e-3 #Position [m]          ... [0, 0.0006]\n",
    "    w_max = 1.7 #Geschwindigkeit in [m/s]   ... [-1.7, 1.7]\n",
    "    p_min = 1.0\n",
    "    s_min = 0.0\n",
    "    w_min = -1.7\n",
    "    physics_rescaling = [p_max, s_max, w_max, p_min, s_min, w_min]\n",
    "\n",
    "    colors = {\"or_lstm\" : \"red\",\n",
    "              \"or_mlp\" : \"green\",\n",
    "              \"or_tcn\" : \"purple\",\n",
    "              \"neural_cde\"  : \"brown\"}\n",
    "\n",
    "    figure , axs = plt.subplots(1,1, figsize=(16,16))\n",
    "    figure.tight_layout(pad=5.0)    \n",
    "\n",
    "    if x.dim() == 3:\n",
    "        x = x.view(x.size(dim=1), x.size(dim=2))\n",
    "    \n",
    "        #scale back:    \n",
    "    if physics_rescaling != None:\n",
    "\n",
    "        x[:,0] = x[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "        x[:,1] = x[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "        x[:,2] = x[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "    greek_letterz=[chr(code) for code in range(945,970)]\n",
    "    mu = greek_letterz[11]\n",
    "\n",
    "    stepsize = 2e-5\n",
    "    time = np.linspace(0,x.size(dim=0)* stepsize, x.size(dim=0))\n",
    "\n",
    "    #data\n",
    "    axs.plot(x.detach().cpu().numpy()[:, 1],x.detach().cpu().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "\n",
    "    #predictions\n",
    "    for key, pred in predictionary.items():\n",
    "\n",
    "        if physics_rescaling != None:\n",
    "\n",
    "            # we invert:\n",
    "            # x = (x - xmin)/(xmax - xmin)\n",
    "            # x * (xmax - xmin) + xmin\n",
    "\n",
    "            pred[:,0] = pred[:,0]*(physics_rescaling[0] - physics_rescaling[3]) + physics_rescaling[3]\n",
    "            pred[:,1] = pred[:,1]*(physics_rescaling[1] - physics_rescaling[4]) + physics_rescaling[4]\n",
    "            pred[:,2] = pred[:,2]*(physics_rescaling[2] - physics_rescaling[5]) + physics_rescaling[5]\n",
    "\n",
    "        if pred.dim() == 3:\n",
    "            pred = pred.view(pred.size(dim=1), pred.size(dim=2))\n",
    "\n",
    "        axs.plot(pred.detach().cpu().numpy()[:, 1], pred.detach().cpu().numpy()[:, 2], color=colors[key], label=f\"{key}-prediciton\", alpha=0.5)\n",
    "\n",
    "    axs.set_title(\"position\")\n",
    "    axs.set_ylabel(\"[m]\")\n",
    "    axs.set_xlabel(f\"time [s]\")\n",
    "    axs.grid()\n",
    "    axs.legend()   \n",
    "\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_errors():\n",
    "     return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

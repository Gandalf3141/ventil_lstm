{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"save_data_test.csv\", nrows=600, skiprows=150)\n",
    "\n",
    "L = df.columns.to_list()\n",
    "time_cols = L[0::4]\n",
    "sb_cols = L[1::4]\n",
    "pb_cols = L[2::4]\n",
    "wb_cols = L[3::4]\n",
    "df[pb_cols] = df[pb_cols].to_numpy() / 1e5\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 6))\n",
    "df[sb_cols].plot(ax=axs[0])\n",
    "df[pb_cols].plot(ax=axs[1])\n",
    "df[wb_cols].plot(ax=axs[2])\n",
    "axs[0].get_legend().remove()\n",
    "axs[1].get_legend().remove()\n",
    "axs[2].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"save_data_validate.csv\", nrows=600, skiprows=150)\n",
    "L = df.columns.to_list()\n",
    "time_cols = L[0::4]\n",
    "sb_cols = L[1::4]\n",
    "pb_cols = L[2::4]\n",
    "wb_cols = L[3::4]\n",
    "df[pb_cols] = df[pb_cols].to_numpy() / 1e5\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(8, 6))\n",
    "df[sb_cols].plot(ax=axs[0])\n",
    "df[pb_cols].plot(ax=axs[1])\n",
    "df[wb_cols].plot(ax=axs[2])\n",
    "df[time_cols].plot(ax=axs[3])\n",
    "axs[0].get_legend().remove()\n",
    "axs[1].get_legend().remove()\n",
    "axs[2].get_legend().remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"save_data_test.csv\", nrows=600, header=0, skiprows=[x for x in range(1,100)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k=np.random.randint(0,500,1)[0]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 6))\n",
    "df[f\"sb_{k}\"].plot(ax=axs[0], label=\"sb\", color=\"red\")\n",
    "df[f\"pb_{k}\"]=df[f\"pb_{k}\"]/1e5\n",
    "df[f\"pb_{k}\"].plot(ax=axs[1], label=\"p_b\", color=\"green\")\n",
    "df[f\"wb_{k}\"].plot(ax=axs[2], label=\"w_b\")\n",
    "for i in range(3):\n",
    "    axs[i].legend()\n",
    "    axs[i].grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(df.values)\n",
    "tensor = tensor.view(600,500,4).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path = \"ventil_lstm\\save_data_test.csv\"):\n",
    "    \n",
    "    df = pd.read_csv(path, header=0, nrows=600, skiprows=[x for x in range(1,100)])\n",
    "\n",
    "    #drop even more timesteps\n",
    "    df = df.iloc[::2]\n",
    "\n",
    "    #Reorder columns for familiar setup (t,u,x) here (t, p_b, s_b, w_b)\n",
    "    L = df.columns.to_list()\n",
    "    time_cols = L[0::4]\n",
    "    sb_cols = L[1::4]\n",
    "    pb_cols = L[2::4]\n",
    "    wb_cols = L[3::4]\n",
    "    new_col_order = [x for sub in list(zip(time_cols, pb_cols, sb_cols, wb_cols)) for x in sub]\n",
    "    df= df[new_col_order]\n",
    "    df = df.drop(time_cols, axis=1)\n",
    "\n",
    "    #normalise each column of the dataframe\n",
    "    #mean normalization\n",
    "    #df=(df-df.mean())/df.std()\n",
    "\n",
    "    #min max normalization\n",
    "    #normalize only a part of the data(??)\n",
    "    df[sb_cols+wb_cols]=(df[sb_cols+wb_cols]-df[sb_cols+wb_cols].min())/(df[sb_cols+wb_cols].max()-df[sb_cols+wb_cols].min())\n",
    "    \n",
    "    #Can't normalize p_b because then a[i]*X+b[i] becomes cX+d for all i.. same with mean normal. \n",
    "    \n",
    "    df[pb_cols] = df[pb_cols] / 1e5\n",
    "\n",
    "    tensor = torch.tensor(df.values)\n",
    "\n",
    "    #tensor with t=0:600, 500 different input and the 4 outputs [time, s_b, p_b, w_b]\n",
    "    tensor = tensor.view(len(df),500,3).permute(1,0,2)\n",
    "\n",
    "\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"save_data_test.csv\", header=0, nrows=600, skiprows=[x for x in range(1,100)])\n",
    "\n",
    "#Reorder columns for familiar setup (t,u,x) here (t, p_b, s_b, w_b)\n",
    "L = df.columns.to_list()\n",
    "time_cols = L[0::4]\n",
    "sb_cols = L[1::4]\n",
    "pb_cols = L[2::4]\n",
    "wb_cols = L[3::4]\n",
    "new_col_order = [x for sub in list(zip(time_cols, pb_cols, sb_cols, wb_cols)) for x in sub]\n",
    "df= df[new_col_order]\n",
    "df = df.drop(time_cols, axis=1)\n",
    "\n",
    "#normalise each column of the dataframe\n",
    "#mean normalization\n",
    "#df=(df-df.mean())/df.std()\n",
    "\n",
    "#min max normalization\n",
    "df[sb_cols+wb_cols]=(df[sb_cols+wb_cols]-df[sb_cols+wb_cols].min())/(df[sb_cols+wb_cols].max()-df[sb_cols+wb_cols].min())\n",
    "\n",
    "df[pb_cols] = df[pb_cols] / 1e5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor[0])\n",
    "a= torch.tensor([[1,2],[3,4]])\n",
    "a=tensor[0]\n",
    "a[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = get_data(path=\"save_data_test.csv\")\n",
    "\n",
    "train_size = int(0.9 * len(input_data))\n",
    "test_size = len(input_data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(input_data, [train_size, test_size])\n",
    "\n",
    "tensor=input_data[1:100, :, :]\n",
    "for x in test_dataset:\n",
    "    plt.plot(x[:500,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.version.cuda(): Returns CUDA version of the currently installed packages\n",
    "# torch.cuda.is_available(): Returns True if CUDA is supported by your system, else False\n",
    "# torch.cuda.current_device(): Returns ID of current device\n",
    "# torch.cuda.get_device_name(device_ID): Returns name of the CUDA device with ID = ‘device_ID’\n",
    "print( torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(test_data, model, steps=600, ws=10):\n",
    "\n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    test_loss = 0\n",
    "    test_loss_deriv = 0\n",
    "\n",
    "    for i, x in enumerate(test_data):\n",
    "        \n",
    "        if i > 3:\n",
    "            break\n",
    "\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            pred = torch.zeros((steps, 3))\n",
    "            pred_next_step = torch.zeros((steps, 3))\n",
    "\n",
    "            if ws > 1:\n",
    "                pred[0:ws, :] = x[0:ws, :]\n",
    "                pred[:, 0] = x[:, 0]\n",
    "                pred_next_step[0:ws, :] = x[0:ws, :]\n",
    "                pred_next_step[:, 0] = x[:, 0]\n",
    "            else:\n",
    "                pred[0, :] = x[0, :]\n",
    "                pred[:, 0] = x[:, 0]\n",
    "                pred_next_step[0, :] = x[0, :]\n",
    "                pred_next_step[:, 0] = x[:, 0]\n",
    "\n",
    "            for i in range(len(x) - ws):\n",
    "                out, _ = model(pred[i:i+ws, :])\n",
    "\n",
    "                pred[i+ws, 1:] = pred[i+ws-1, 1:] + out[-1, :]\n",
    "                pred_next_step[i+ws, 1:] = x[i+ws-1, 1:] + out[-1, :]\n",
    "\n",
    "\n",
    "            test_loss += loss_fn(pred[:, 1], x[:, 1]).detach().numpy()\n",
    "            test_loss_deriv += loss_fn(pred[:, 2], x[:, 2]).detach().numpy()\n",
    "            figure , axs = plt.subplots(3,1)\n",
    "            \n",
    "            axs[0].plot(np.linspace(0,1,steps), pred.detach().numpy()[:, 1], color=\"red\", label=\"pred\")\n",
    "            axs[0].plot(np.linspace(0,1,steps), pred_next_step.detach().numpy()[:, 1], color=\"green\", label=\"next step from data\")\n",
    "            axs[0].plot(np.linspace(0,1,steps), x.detach().numpy()[:, 1], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "\n",
    "            axs[0].grid()\n",
    "            axs[0].legend()\n",
    "\n",
    "            axs[1].plot(np.linspace(0,1,steps), pred.detach().numpy()[\n",
    "            :, 2], color=\"red\", label=\"pred\")\n",
    "            axs[1].plot(np.linspace(0,1,steps), pred_next_step.detach().numpy()[:, 2], color=\"green\", label=\"next step from data\")\n",
    "            axs[1].plot(np.linspace(0,1,steps), x.detach().numpy()[:, 2], color=\"blue\", label=\"true\", linestyle=\"dashed\")\n",
    "\n",
    "            axs[1].grid()\n",
    "            axs[1].legend()\n",
    "            axs[2].plot(np.linspace(0,1,steps), x.detach().numpy()[:,0], label=\"pressure\")\n",
    "\n",
    "            axs[2].grid()\n",
    "            axs[2].legend()\n",
    "            \n",
    "\n",
    "    return np.mean(test_loss), np.mean(test_loss_deriv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = get_data(path=\"save_data_test.csv\")\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(0.7 * len(input_data))\n",
    "test_size = len(input_data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(input_data, [train_size, test_size])\n",
    "\n",
    "# Take a slice of data for training (only slice_of_data many timesteps)\n",
    "slice_of_data = 60\n",
    "\n",
    "train_dataset = train_dataset[:][:, 0:slice_of_data, :]\n",
    "\n",
    "model = LSTMmodel(input_size=3, hidden_size=5, out_size=2, layers=1).to(\"cpu\")\n",
    "\n",
    "\n",
    "path = f\"Ventil_trained_NNs\\lstm_ws{16}.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "test(test_dataset, model, steps=600, ws=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

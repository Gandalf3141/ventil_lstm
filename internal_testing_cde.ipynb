{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# So you want to train a Neural CDE model?\n",
    "# Let's get started!\n",
    "\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torchcde\n",
    "from get_data import *\n",
    "from dataloader import *\n",
    "from test_function import *\n",
    "from tqdm import tqdm\n",
    "#from NN_classes import *\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# A CDE model looks like\n",
    "\n",
    "class CDEFunc(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, hidden_width=128):\n",
    "        ######################\n",
    "        # input_channels is the number of input channels in the data X. (Determined by the data.)\n",
    "        # hidden_channels is the number of channels for z_t. (Determined by you!)\n",
    "        ######################\n",
    "        super(CDEFunc, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.hidden_width  = hidden_width\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, self.hidden_width)\n",
    "        self.linear2 = torch.nn.Linear(self.hidden_width, input_channels * hidden_channels)\n",
    "\n",
    "    ######################\n",
    "    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n",
    "    # different times, which would be unusual. But it's there if you need it!\n",
    "    ######################\n",
    "    def forward(self, t, z):\n",
    "        # z has shape (batch, hidden_channels)\n",
    "        z = self.linear1(z)\n",
    "        z = z.relu()\n",
    "        z = self.linear2(z)\n",
    "        ######################\n",
    "        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n",
    "        ######################\n",
    "        # try without?        \n",
    "        z = z.tanh()\n",
    "        ######################\n",
    "        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n",
    "        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n",
    "        ######################\n",
    "        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n",
    "        return z\n",
    "\n",
    "\n",
    "######################\n",
    "# Next, we need to package CDEFunc up into a model that computes the integral.\n",
    "######################\n",
    "class NeuralCDE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, hidden_width, output_channels, interpolation=\"cubic\"):\n",
    "        super(NeuralCDE, self).__init__()\n",
    "\n",
    "        self.func = CDEFunc(input_channels, hidden_channels, hidden_width)\n",
    "        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        if self.interpolation == 'cubic':\n",
    "            X = torchcde.CubicSpline(coeffs)\n",
    "        elif self.interpolation == 'linear':\n",
    "            X = torchcde.LinearInterpolation(coeffs)\n",
    "        else:\n",
    "            raise ValueError(\"Only 'linear' and 'cubic' interpolation methods are implemented.\")\n",
    "\n",
    "        ######################\n",
    "        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n",
    "        ######################\n",
    "        X0 = X.evaluate(X.interval[0])\n",
    "        z0 = self.initial(X0)\n",
    "\n",
    "        ######################\n",
    "        # Actually solve the CDE.\n",
    "        ######################\n",
    "        z_T = torchcde.cdeint(X=X,\n",
    "                              z0=z0,\n",
    "                              func=self.func\n",
    "                              ,t=X.interval, adjoint=False, backend='torchdiffeq',atol = 1e-4, rtol = 1e-4)#, options=dict(jump_t=X.grid_points),)\n",
    "                                #method='rk4', \n",
    "                                #options=dict(step_size=2e-4),\n",
    "                                \n",
    "                                #adjoint=False, atol = 1e-4, rtol = 1e-4)\n",
    "\n",
    "        ######################\n",
    "        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n",
    "        # and then apply a linear map.\n",
    "        ######################\n",
    "        z_T = z_T[:, 1]\n",
    "        pred_y = self.readout(z_T)\n",
    "        return pred_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "path = r\"Ventil_trained_NNs\\cde0.pth\"\n",
    "\n",
    "paramsliste = [       \n",
    "                     {\n",
    "                        \"experiment_number\" : 0,\n",
    "                        \"window_size\" : 50,\n",
    "                        \"h_size\" : 16,\n",
    "                        \"h_width\" : 128,\n",
    "                        \"batch_size\" : 500,\n",
    "                        \"learning_rate\" : 0.000,\n",
    "                        \"part_of_data\" : 0, \n",
    "                        \"percentage_of_data\" : 0.7,\n",
    "                        \"batch_size\" : 2,\n",
    "                        \"cut_off_timesteps\" : 100,\n",
    "                        \"drop_half_timesteps\": True\n",
    "                      }\n",
    "                    ]\n",
    "\n",
    "for params in paramsliste:\n",
    "\n",
    "   # Generate input data (the data is normalized and some timesteps are cut off)\n",
    "    input_data1, PSW_max = get_data_cde(path = \"data/save_data_test_5xlonger_dyndyn.csv\", \n",
    "                            timesteps_from_data=0, \n",
    "                            skip_steps_start = 0,\n",
    "                            skip_steps_end = 0, \n",
    "                            drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                            normalise_s_w=\"minmax\",\n",
    "                            rescale_p=False,\n",
    "                            num_inits=params[\"part_of_data\"])\n",
    "    \n",
    "    input_data2, PSW_max = get_data_cde(path = \"data/save_data_test5.csv\", \n",
    "                            timesteps_from_data=0, \n",
    "                            skip_steps_start = 0,\n",
    "                            skip_steps_end = 0, \n",
    "                            drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                            normalise_s_w=\"minmax\",\n",
    "                            rescale_p=False,\n",
    "                            num_inits=params[\"part_of_data\"])\n",
    "    \n",
    "    input_data3, PSW_max = get_data_cde(path = \"data/Testruns_from_trajectory_generator_t2_t6_revised.csv\", \n",
    "                            timesteps_from_data=0, \n",
    "                            skip_steps_start = 0,\n",
    "                            skip_steps_end = 0, \n",
    "                            drop_half_timesteps = params[\"drop_half_timesteps\"],\n",
    "                            normalise_s_w=\"minmax\",\n",
    "                            rescale_p=False,\n",
    "                            num_inits=params[\"part_of_data\"])\n",
    "    \n",
    "    #input_data = torch.cat((input_data1, input_data2, input_data3)).to(device)\n",
    "    input_data = input_data1\n",
    "    #cols = time_cols, pb_cols, sb_cols, wb_cols\n",
    "    print(input_data.size())\n",
    "        #Split data into train and test sets\n",
    "    np.random.seed(1234)\n",
    "    num_of_inits_train = int(len(input_data)*params[\"percentage_of_data\"])\n",
    "    train_inits = np.random.choice(np.arange(len(input_data)),num_of_inits_train,replace=False)\n",
    "    test_inits = np.array([x for x in range(len(input_data)) if x not in train_inits])\n",
    "    np.random.shuffle(train_inits)\n",
    "    np.random.shuffle(test_inits)\n",
    "    train_data = input_data[train_inits,:input_data.size(dim=1)-params[\"cut_off_timesteps\"],:]\n",
    "    test_data = input_data[test_inits,:,:]\n",
    "    print(train_data.size())\n",
    "\n",
    "    train_set = CustomDataset_cde(train_data, window_size=params[\"window_size\"])\n",
    "    train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"])  \n",
    "    if device == \"cuda:0\":\n",
    "        train_loader = DataLoader(train_set, batch_size=params[\"batch_size\"], pin_memory=True)  \n",
    "\n",
    "    model = NeuralCDE(input_channels=4, hidden_channels=params[\"h_size\"], hidden_width = params[\"h_width\"], output_channels=2).to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "           \n",
    "    test_loss, test_loss_deriv, err_test = test(input_data2.to(device), model, model_type = \"neural_cde\", window_size=params[\"window_size\"], \n",
    "                                                display_plots=True, num_of_inits = 1, set_rand_seed=False, physics_rescaling = PSW_max)\n",
    "    print('Test loss (MSE over whole Traj.): {}'.format(err_test.item()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
